{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "concat_path = \"XTT22_train.fa\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "full_fasta_path = os.path.abspath(concat_path)\n",
        "output_dir = os.path.abspath(\"preprocessed_data\")\n",
        "output_yaml = f\"\"\"\n",
        "- datapaths: [\"{full_fasta_path}\"]\n",
        "  output_dir: \"{output_dir}\"\n",
        "  output_prefix: XTT22_train\n",
        "  train_split: 0.9\n",
        "  valid_split: 0.05\n",
        "  test_split: 0.05\n",
        "  overwrite: True\n",
        "  embed_reverse_complement: true\n",
        "  random_reverse_complement: 0.0\n",
        "  random_lineage_dropout: 0.0\n",
        "  include_sequence_id: false\n",
        "  transcribe: \"back_transcribe\"\n",
        "  force_uppercase: false\n",
        "  indexed_dataset_dtype: \"uint8\"\n",
        "  tokenizer_type: \"Byte-Level\"\n",
        "  vocab_file: null\n",
        "  vocab_size: null\n",
        "  merges_file: null\n",
        "  pretrained_tokenizer_model: null\n",
        "  special_tokens: null\n",
        "  fast_hf_tokenizer: true\n",
        "  append_eod: true\n",
        "  enforce_sample_length: null\n",
        "  ftfy: false\n",
        "  workers: 1\n",
        "  preproc_concurrency: 100000\n",
        "  chunksize: 25\n",
        "  drop_empty_sequences: true\n",
        "  nnn_filter: false  # If you split your fasta on NNN (in human these are contigs), then you should set this to true.\n",
        "  seed: 12342  # Not relevant because we are not using random reverse complement or lineage dropout.\n",
        "\"\"\"\n",
        "with open(\"preprocess_config.yaml\", \"w\") as f:\n",
        "    print(output_yaml, file=f)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!preprocess_evo2 --config preprocess_config.yaml\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!ls -lh preprocessed_data/\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!cp /workspace/hyena_modified.py /usr/local/lib/python3.12/dist-packages/nemo/collections/llm/gpt/model/hyena.py\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!evo2_convert_to_nemo2 \\\n",
        "  --model-path /workspace/savanna_evo2_7b/savanna_evo2_7b.pt \\\n",
        "  --model-size 7b --output-dir nemo2_evo2_7b\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ==================== NCCL超时问题解决方案 ====================\n",
        "import os\n",
        "import subprocess\n",
        "import time\n",
        "from datetime import datetime\n",
        "\n",
        "# 1. 备份和替换训练脚本\n",
        "print(\"🔧 备份并替换训练脚本...\")\n",
        "!cp /usr/local/lib/python3.12/dist-packages/bionemo/evo2/run/train.py /usr/local/lib/python3.12/dist-packages/bionemo/evo2/run/train.py.backup 2>/dev/null || echo \"备份文件已存在或路径不存在\"\n",
        "!cp /workspace/bionemo_train.py /usr/local/lib/python3.12/dist-packages/bionemo/evo2/run/train.py 2>/dev/null || echo \"自定义训练脚本不存在，使用默认版本\"\n",
        "\n",
        "# 2. 设置NCCL和分布式环境变量\n",
        "print(\"🔧 配置NCCL超时和优化参数...\")\n",
        "\n",
        "# NCCL超时设置 - 增加到2小时\n",
        "os.environ['NCCL_TIMEOUT'] = '7200'  # 2小时超时\n",
        "os.environ['TORCH_NCCL_BLOCKING_WAIT'] = '1'  # 使用新的环境变量名\n",
        "os.environ['TORCH_NCCL_ASYNC_ERROR_HANDLING'] = '1'  # 使用新的环境变量名\n",
        "os.environ['NCCL_DEBUG'] = 'INFO'  # 启用详细调试信息\n",
        "\n",
        "# PyTorch分布式超时设置\n",
        "os.environ['TORCH_DISTRIBUTED_TIMEOUT'] = '7200'  # PyTorch分布式超时\n",
        "os.environ['TORCH_NCCL_TRACE_BUFFER_SIZE'] = '1024'  # 启用NCCL跟踪\n",
        "\n",
        "# 数据加载和通信优化\n",
        "os.environ['NCCL_BUFFSIZE'] = '8388608'  # 增加缓冲区大小到8MB\n",
        "os.environ['NCCL_NTHREADS'] = '8'  # 增加NCCL线程数\n",
        "os.environ['NCCL_MIN_NTHREADS'] = '4'  # 最小线程数\n",
        "\n",
        "# 避免内存碎片和并行冲突\n",
        "os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'max_split_size_mb:512'\n",
        "os.environ['TOKENIZERS_PARALLELISM'] = 'false'  # 避免tokenizer并行冲突\n",
        "os.environ['OMP_NUM_THREADS'] = '4'  # 限制OpenMP线程数\n",
        "\n",
        "# 数据集准备优化\n",
        "os.environ['NCCL_P2P_DISABLE'] = '0'  # 确保P2P通信启用\n",
        "os.environ['NCCL_SHM_DISABLE'] = '0'  # 确保共享内存通信启用\n",
        "\n",
        "print(\"环境变量设置完成:\")\n",
        "for key in ['NCCL_TIMEOUT', 'TORCH_DISTRIBUTED_TIMEOUT', 'NCCL_DEBUG', 'NCCL_BUFFSIZE']:\n",
        "    print(f\"  {key}: {os.environ.get(key)}\")\n",
        "\n",
        "# 3. 定义带监控的训练函数\n",
        "def run_training_with_monitoring():\n",
        "    \"\"\"带实时监控的训练启动函数\"\"\"\n",
        "    \n",
        "    # 获取当前工作目录中的preprocessed_data路径\n",
        "    preprocessed_data = os.path.abspath(\"preprocessed_data\")\n",
        "    print(f\"📁 数据集目录: {preprocessed_data}\")\n",
        "    \n",
        "    # 训练配置参数\n",
        "    training_config = {\n",
        "        'data_config': 'training_data_config.yaml',\n",
        "        'dataset_dir': preprocessed_data,  # 使用实际路径\n",
        "        'model_size': '7b',\n",
        "        'devices': 2,\n",
        "        'num_nodes': 1,\n",
        "        'seq_length': 1,\n",
        "        'micro_batch_size': 1,\n",
        "        'lr': 0.0001,\n",
        "        'warmup_steps': 5,\n",
        "        'max_steps': 200000,\n",
        "        'ckpt_dir': 'nemo2_evo2_7b',\n",
        "        'clip_grad': 1,\n",
        "        'wd': 0.01,\n",
        "        'activation_checkpoint_recompute_num_layers': 1,\n",
        "        'val_check_interval': 1000\n",
        "    }\n",
        "    \n",
        "    # 构建训练命令 - 使用正确的格式\n",
        "    cmd_parts = [\n",
        "        'train_evo2',\n",
        "        '-d', training_config['data_config'],\n",
        "        '--dataset-dir', training_config['dataset_dir'],\n",
        "        '--model-size', training_config['model_size'],\n",
        "        '--devices', str(training_config['devices']),\n",
        "        '--num-nodes', str(training_config['num_nodes']),\n",
        "        '--seq-length', str(training_config['seq_length']),\n",
        "        '--micro-batch-size', str(training_config['micro_batch_size']),\n",
        "        '--lr', str(training_config['lr']),\n",
        "        '--warmup-steps', str(training_config['warmup_steps']),\n",
        "        '--max-steps', str(training_config['max_steps']),\n",
        "        '--ckpt-dir', training_config['ckpt_dir'],\n",
        "        '--clip-grad', str(training_config['clip_grad']),\n",
        "        '--wd', str(training_config['wd']),\n",
        "        '--activation-checkpoint-recompute-num-layers', str(training_config['activation_checkpoint_recompute_num_layers']),\n",
        "        '--val-check-interval', str(training_config['val_check_interval']),\n",
        "        '--ckpt-async-save'\n",
        "    ]\n",
        "    \n",
        "    cmd = ' '.join(cmd_parts)\n",
        "    \n",
        "    print(f\"🚀 开始训练时间: {datetime.now()}\")\n",
        "    print(f\"📋 训练命令: {cmd}\")\n",
        "    print(\"=\"*80)\n",
        "    \n",
        "    try:\n",
        "        # 启动训练进程\n",
        "        process = subprocess.Popen(\n",
        "            cmd_parts,  # 使用列表而不是字符串，避免shell解析问题\n",
        "            stdout=subprocess.PIPE,\n",
        "            stderr=subprocess.STDOUT,\n",
        "            universal_newlines=True,\n",
        "            bufsize=1\n",
        "        )\n",
        "        \n",
        "        # 实时监控输出\n",
        "        start_time = time.time()\n",
        "        last_output_time = start_time\n",
        "        dataset_preparation_detected = False\n",
        "        \n",
        "        for line in iter(process.stdout.readline, ''):\n",
        "            current_time = time.time()\n",
        "            elapsed = current_time - start_time\n",
        "            \n",
        "            # 打印带时间戳的输出\n",
        "            print(f\"[{elapsed:.1f}s] {line.rstrip()}\")\n",
        "            \n",
        "            # 检查关键信息\n",
        "            keywords = ['dataset', 'preparing', 'loading', 'barrier', 'build', 'index']\n",
        "            if any(keyword in line.lower() for keyword in keywords):\n",
        "                print(f\"📊 数据集准备阶段: {line.rstrip()}\")\n",
        "                dataset_preparation_detected = True\n",
        "                last_output_time = current_time\n",
        "            \n",
        "            # NCCL相关信息特别标记\n",
        "            if 'nccl' in line.lower():\n",
        "                print(f\"🔗 NCCL通信: {line.rstrip()}\")\n",
        "                last_output_time = current_time\n",
        "            \n",
        "            # 错误信息特别标记\n",
        "            if any(err in line.lower() for err in ['error', 'timeout', 'fail']):\n",
        "                print(f\"❌ 错误信息: {line.rstrip()}\")\n",
        "                last_output_time = current_time\n",
        "            \n",
        "            # 长时间无输出的警告\n",
        "            if current_time - last_output_time > 300:  # 5分钟无输出\n",
        "                elapsed_no_output = current_time - last_output_time\n",
        "                if dataset_preparation_detected:\n",
        "                    print(f\"\\n⏳ [数据集准备] 已有 {elapsed_no_output:.1f} 秒无输出，数据集构建中...\")\n",
        "                else:\n",
        "                    print(f\"\\n⏳ [等待中] 已有 {elapsed_no_output:.1f} 秒无输出...\")\n",
        "                last_output_time = current_time\n",
        "        \n",
        "        # 等待进程完成\n",
        "        return_code = process.wait()\n",
        "        \n",
        "        if return_code == 0:\n",
        "            print(f\"\\n✅ 训练成功完成! 总耗时: {time.time() - start_time:.1f} 秒\")\n",
        "        else:\n",
        "            print(f\"\\n❌ 训练失败，返回码: {return_code}\")\n",
        "            \n",
        "    except KeyboardInterrupt:\n",
        "        print(\"\\n🛑 用户中断训练\")\n",
        "        process.terminate()\n",
        "    except Exception as e:\n",
        "        print(f\"\\n💥 训练出错: {e}\")\n",
        "\n",
        "# 4. 启动训练\n",
        "print(\"🎯 启动带监控的训练...\")\n",
        "run_training_with_monitoring()\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
