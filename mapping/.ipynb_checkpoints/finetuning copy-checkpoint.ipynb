{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f1f816cb-6abb-4cf9-9a0b-d1382a4c9910",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "concat_path = \"XTT22_train.fa\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e5a015b5-fad5-4d11-adcd-2fb18c594536",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_fasta_path = os.path.abspath(concat_path)\n",
    "output_dir = os.path.abspath(\"preprocessed_data\")\n",
    "output_yaml = f\"\"\"\n",
    "- datapaths: [\"{full_fasta_path}\"]\n",
    "  output_dir: \"{output_dir}\"\n",
    "  output_prefix: XTT22_train\n",
    "  train_split: 0.9\n",
    "  valid_split: 0.05\n",
    "  test_split: 0.05\n",
    "  overwrite: True\n",
    "  embed_reverse_complement: true\n",
    "  random_reverse_complement: 0.0\n",
    "  random_lineage_dropout: 0.0\n",
    "  include_sequence_id: false\n",
    "  transcribe: \"back_transcribe\"\n",
    "  force_uppercase: false\n",
    "  indexed_dataset_dtype: \"uint8\"\n",
    "  tokenizer_type: \"Byte-Level\"\n",
    "  vocab_file: null\n",
    "  vocab_size: null\n",
    "  merges_file: null\n",
    "  pretrained_tokenizer_model: null\n",
    "  special_tokens: null\n",
    "  fast_hf_tokenizer: true\n",
    "  append_eod: true\n",
    "  enforce_sample_length: null\n",
    "  ftfy: false\n",
    "  workers: 1\n",
    "  preproc_concurrency: 100000\n",
    "  chunksize: 25\n",
    "  drop_empty_sequences: true\n",
    "  nnn_filter: false  # If you split your fasta on NNN (in human these are contigs), then you should set this to true.\n",
    "  seed: 12342  # Not relevant because we are not using random reverse complement or lineage dropout.\n",
    "\"\"\"\n",
    "with open(\"preprocess_config.yaml\", \"w\") as f:\n",
    "    print(output_yaml, file=f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aadbf5cb-03b5-4a20-96e5-7bb0a7e5b942",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2025-05-24 12:37:06 nemo_logging:393] Using byte-level tokenization\n",
      "[NeMo I 2025-05-24 12:37:06 nemo_logging:393] Created temporary binary datasets: /workspace/preprocessed_data/XTT22_train_byte-level_train.bin.tmp /workspace/preprocessed_data/XTT22_train_byte-level_val.bin.tmp /workspace/preprocessed_data/XTT22_train_byte-level_test.bin.tmp\n",
      "[NeMo I 2025-05-24 13:12:11 nemo_logging:393] Average preprocessing time per sequence: 0.04470627161196968\n",
      "[NeMo I 2025-05-24 13:12:11 nemo_logging:393] Average indexing time per sequence: 0.1463382052460373\n",
      "[NeMo I 2025-05-24 13:12:11 nemo_logging:393] Number of sequences processed: 12092\n",
      "[NeMo I 2025-05-24 13:12:11 nemo_logging:393] Finished preprocessing XTT22_train ([PosixPath('/workspace/XTT22_train.fa')]) in 2105.082 seconds with 1 workers.\n"
     ]
    }
   ],
   "source": [
    "!preprocess_evo2 --config preprocess_config.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3df5d34a-d5fe-4fa9-ac3d-65b9696a9045",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 14G\n",
      "-rw-r--r-- 1 root root 936M May 24 13:11 XTT22_train_byte-level_test.bin\n",
      "-rw-r--r-- 1 root root  12K May 24 13:12 XTT22_train_byte-level_test.idx\n",
      "-rw-r--r-- 1 root root  13G May 24 13:12 XTT22_train_byte-level_train.bin\n",
      "-rw-r--r-- 1 root root 213K May 24 13:12 XTT22_train_byte-level_train.idx\n",
      "-rw-r--r-- 1 root root 411M May 24 13:12 XTT22_train_byte-level_val.bin\n",
      "-rw-r--r-- 1 root root  12K May 24 13:12 XTT22_train_byte-level_val.idx\n"
     ]
    }
   ],
   "source": [
    "!ls -lh preprocessed_data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "240cf8a0-258b-424c-9e2a-55999a0c8a5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not find the bitsandbytes CUDA binary at PosixPath('/usr/local/lib/python3.12/dist-packages/bitsandbytes/libbitsandbytes_cuda129.so')\n",
      "The installed version of bitsandbytes was compiled without GPU support. 8-bit optimizers, 8-bit multiplication, and GPU quantization are unavailable.\n",
      "[NeMo I 2025-05-24 15:02:39 nemo_logging:393] Using byte-level tokenization\n",
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "[NeMo W 2025-05-24 15:02:39 nemo_logging:405] /usr/local/lib/python3.12/dist-packages/lightning/pytorch/trainer/setup.py:177: GPU available but not used. You can set it by doing `Trainer(accelerator='gpu')`.\n",
      "    \n",
      "[NeMo I 2025-05-24 15:02:39 nemo_logging:393] Fixing mis-match between ddp-config & mcore-optimizer config\n",
      "[NeMo I 2025-05-24 15:02:39 nemo_logging:393] Rank 0 has data parallel group : [0]\n",
      "[NeMo I 2025-05-24 15:02:39 nemo_logging:393] Rank 0 has combined group of data parallel and context parallel : [0]\n",
      "[NeMo I 2025-05-24 15:02:39 nemo_logging:393] All data parallel group ranks with context parallel combined: [[0]]\n",
      "[NeMo I 2025-05-24 15:02:39 nemo_logging:393] Ranks 0 has data parallel rank: 0\n",
      "[NeMo I 2025-05-24 15:02:39 nemo_logging:393] Rank 0 has context parallel group: [0]\n",
      "[NeMo I 2025-05-24 15:02:39 nemo_logging:393] All context parallel group ranks: [[0]]\n",
      "[NeMo I 2025-05-24 15:02:39 nemo_logging:393] Ranks 0 has context parallel rank: 0\n",
      "[NeMo I 2025-05-24 15:02:39 nemo_logging:393] Rank 0 has model parallel group: [0]\n",
      "[NeMo I 2025-05-24 15:02:39 nemo_logging:393] All model parallel group ranks: [[0]]\n",
      "[NeMo I 2025-05-24 15:02:39 nemo_logging:393] Rank 0 has tensor model parallel group: [0]\n",
      "[NeMo I 2025-05-24 15:02:39 nemo_logging:393] All tensor model parallel group ranks: [[0]]\n",
      "[NeMo I 2025-05-24 15:02:39 nemo_logging:393] Rank 0 has tensor model parallel rank: 0\n",
      "[NeMo I 2025-05-24 15:02:39 nemo_logging:393] Rank 0 has pipeline model parallel group: [0]\n",
      "[NeMo I 2025-05-24 15:02:39 nemo_logging:393] Rank 0 has embedding group: [0]\n",
      "[NeMo I 2025-05-24 15:02:39 nemo_logging:393] All pipeline model parallel group ranks: [[0]]\n",
      "[NeMo I 2025-05-24 15:02:39 nemo_logging:393] Rank 0 has pipeline model parallel rank 0\n",
      "[NeMo I 2025-05-24 15:02:39 nemo_logging:393] All embedding group ranks: [[0]]\n",
      "[NeMo I 2025-05-24 15:02:39 nemo_logging:393] Rank 0 has embedding rank: 0\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=gloo\n",
      "All distributed processes registered. Starting with 1 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[NeMo W 2025-05-24 15:02:39 nemo_logging:405] /usr/local/lib/python3.12/dist-packages/lightning/pytorch/trainer/trainer.py:1090: `trainer.init_module` cannot fully support proper instantiation of your model with the `MegatronStrategy` strategy. Please instantiate your model inside the`LightningModule.configure_model` hook instead\n",
      "    \n",
      "[NeMo I 2025-05-24 15:02:39 nemo_logging:393] Padded vocab_size: 512, original vocab_size: 512, dummy tokens: 0.\n",
      "CPU RNG state changed within GPU RNG context\n",
      "CPU RNG state changed within GPU RNG context\n",
      "CPU RNG state changed within GPU RNG context\n",
      "CPU RNG state changed within GPU RNG context\n",
      "CPU RNG state changed within GPU RNG context\n",
      "CPU RNG state changed within GPU RNG context\n",
      "CPU RNG state changed within GPU RNG context\n",
      "CPU RNG state changed within GPU RNG context\n",
      "CPU RNG state changed within GPU RNG context\n",
      "CPU RNG state changed within GPU RNG context\n",
      "CPU RNG state changed within GPU RNG context\n",
      "CPU RNG state changed within GPU RNG context\n",
      "CPU RNG state changed within GPU RNG context\n",
      "CPU RNG state changed within GPU RNG context\n",
      "[NeMo W 2025-05-24 15:02:43 nemo_logging:405] Could not copy Trainer's 'max_steps' to LR scheduler's 'max_steps'. If you are not using an LR scheduler, this warning can safely be ignored.\n",
      "[NeMo I 2025-05-24 15:02:43 nemo_logging:393] Using FullyParallelSaveStrategyWrapper(torch_dist, 1) dist-ckpt save strategy.\n",
      "[NeMo I 2025-05-24 15:02:48 nemo_logging:393] Global Checkpoint Save : Rank: 0 : Iteration: 0 : Start time: 1748098963.720s : Save duration: 4.825s\n",
      "[NeMo I 2025-05-24 15:02:48 nemo_logging:393] Converted Hyena model to Nemo, model saved to nemo2_evo2_1b_8k\n"
     ]
    }
   ],
   "source": [
    "!evo2_convert_to_nemo2 \\\n",
    "  --model-path /workspace/savanna_evo2_1b_base/savanna_evo2_1b_base.pt \\\n",
    "  --model-size 1b --output-dir nemo2_evo2_1b_8k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "56a10c51-4574-45a0-b1bc-94581798171b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "output_pfx = str(Path(os.path.abspath(\"preprocessed_data\"))/\"XTT22_train_byte-level\")\n",
    "output_yaml = f\"\"\"\n",
    "- dataset_prefix: {output_pfx}_train\n",
    "  dataset_split: train\n",
    "  dataset_weight: 1.0\n",
    "- dataset_prefix: {output_pfx}_val\n",
    "  dataset_split: validation\n",
    "  dataset_weight: 1.0\n",
    "- dataset_prefix: {output_pfx}_test\n",
    "  dataset_split: test\n",
    "  dataset_weight: 1.0\n",
    "\"\"\"\n",
    "with open(\"training_data_config.yaml\", \"w\") as f:\n",
    "    print(output_yaml, file=f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dff9f392-359a-4463-b435-54beadb4ea67",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not find the bitsandbytes CUDA binary at PosixPath('/usr/local/lib/python3.12/dist-packages/bitsandbytes/libbitsandbytes_cuda129.so')\n",
      "The installed version of bitsandbytes was compiled without GPU support. 8-bit optimizers, 8-bit multiplication, and GPU quantization are unavailable.\n",
      "[NeMo I 2025-05-24 15:03:17 nemo_logging:393] Using byte-level tokenization\n",
      "[NeMo W 2025-05-24 15:03:17 nemo_logging:405] WandB is currently turned off.\n",
      "[NeMo W 2025-05-24 15:03:17 nemo_logging:405] User-set tensorboard is currently turned off. Internally one may still be set by NeMo2.\n",
      "Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "[NeMo I 2025-05-24 15:03:17 nemo_logging:393] Experiments will be logged at results/evo2/dev\n",
      "[NeMo W 2025-05-24 15:03:17 nemo_logging:405] There were no checkpoints found in checkpoint_dir or no checkpoint folder at checkpoint_dir :results/evo2/checkpoints. Training from scratch.\n",
      "[NeMo I 2025-05-24 15:03:17 nemo_logging:393] Fixing mis-match between ddp-config & mcore-optimizer config\n",
      "[NeMo I 2025-05-24 15:03:17 nemo_logging:393] Rank 0 has data parallel group : [0]\n",
      "[NeMo I 2025-05-24 15:03:17 nemo_logging:393] Rank 0 has combined group of data parallel and context parallel : [0]\n",
      "[NeMo I 2025-05-24 15:03:17 nemo_logging:393] All data parallel group ranks with context parallel combined: [[0]]\n",
      "[NeMo I 2025-05-24 15:03:17 nemo_logging:393] Ranks 0 has data parallel rank: 0\n",
      "[NeMo I 2025-05-24 15:03:17 nemo_logging:393] Rank 0 has context parallel group: [0]\n",
      "[NeMo I 2025-05-24 15:03:17 nemo_logging:393] All context parallel group ranks: [[0]]\n",
      "[NeMo I 2025-05-24 15:03:17 nemo_logging:393] Ranks 0 has context parallel rank: 0\n",
      "[NeMo I 2025-05-24 15:03:17 nemo_logging:393] Rank 0 has model parallel group: [0]\n",
      "[NeMo I 2025-05-24 15:03:17 nemo_logging:393] All model parallel group ranks: [[0]]\n",
      "[NeMo I 2025-05-24 15:03:17 nemo_logging:393] Rank 0 has tensor model parallel group: [0]\n",
      "[NeMo I 2025-05-24 15:03:17 nemo_logging:393] All tensor model parallel group ranks: [[0]]\n",
      "[NeMo I 2025-05-24 15:03:17 nemo_logging:393] Rank 0 has tensor model parallel rank: 0\n",
      "[NeMo I 2025-05-24 15:03:17 nemo_logging:393] Rank 0 has pipeline model parallel group: [0]\n",
      "[NeMo I 2025-05-24 15:03:17 nemo_logging:393] Rank 0 has embedding group: [0]\n",
      "[NeMo I 2025-05-24 15:03:17 nemo_logging:393] All pipeline model parallel group ranks: [[0]]\n",
      "[NeMo I 2025-05-24 15:03:17 nemo_logging:393] Rank 0 has pipeline model parallel rank 0\n",
      "[NeMo I 2025-05-24 15:03:17 nemo_logging:393] All embedding group ranks: [[0]]\n",
      "[NeMo I 2025-05-24 15:03:17 nemo_logging:393] Rank 0 has embedding rank: 0\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 1 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[NeMo I 2025-05-24 15:03:18 utils:554] Building Evo2Dataset splits with sizes=[100, 60, 1] and config=GPTDatasetConfig(random_seed=1234, sequence_length=1, blend=None, blend_per_split=[(['/workspace/preprocessed_data/XTT22_train_byte-level_train'], [1.0]), (['/workspace/preprocessed_data/XTT22_train_byte-level_val'], [1.0]), (['/workspace/preprocessed_data/XTT22_train_byte-level_test'], [1.0])], split=None, split_matrix=None, num_dataset_builder_threads=1, path_to_cache=None, mmap_bin_files=True, mock=False, tokenizer=<nemo.collections.common.tokenizers.bytelevel_tokenizers.ByteLevelTokenizer object at 0x76022cea3a10>, mid_level_dataset_surplus=0.005, reset_position_ids=False, reset_attention_mask=False, eod_mask_loss=False, create_attention_mask=False, drop_last_partial_validation_sequence=True, add_extra_token_to_sequence=True, object_storage_cache_path=None)\n",
      "[NeMo I 2025-05-24 15:03:18 utils:554] Load the _IndexReader from /workspace/preprocessed_data/XTT22_train_byte-level_train.idx\n",
      "[NeMo I 2025-05-24 15:03:18 utils:554] \tExtract the sequence lengths\n",
      "[NeMo I 2025-05-24 15:03:18 utils:554] \tExtract the sequence pointers\n",
      "[NeMo I 2025-05-24 15:03:18 utils:554] \tExtract the document indices\n",
      "[NeMo I 2025-05-24 15:03:18 utils:554] > total number of sequences: 10896\n",
      "[NeMo I 2025-05-24 15:03:18 utils:554] > total number of documents: 10896\n",
      "[NeMo I 2025-05-24 15:03:18 utils:554] Build and save the Evo2Dataset train indices\n",
      "[NeMo I 2025-05-24 15:50:25 utils:554] > total number of samples: 13441714549\n",
      "[NeMo I 2025-05-24 15:50:25 utils:554] > total number of epochs: 1\n",
      "[NeMo I 2025-05-24 15:50:25 utils:554] Load the _IndexReader from /workspace/preprocessed_data/XTT22_train_byte-level_val.idx\n",
      "[NeMo I 2025-05-24 15:50:25 utils:554] \tExtract the sequence lengths\n",
      "[NeMo I 2025-05-24 15:50:25 utils:554] \tExtract the sequence pointers\n",
      "[NeMo I 2025-05-24 15:50:25 utils:554] \tExtract the document indices\n",
      "[NeMo I 2025-05-24 15:50:25 utils:554] > total number of sequences: 590\n",
      "[NeMo I 2025-05-24 15:50:25 utils:554] > total number of documents: 590\n",
      "[NeMo I 2025-05-24 15:50:25 utils:554] Build and save the Evo2Dataset valid indices\n",
      "[NeMo I 2025-05-24 15:51:08 utils:554] > total number of samples: 430752259\n",
      "[NeMo I 2025-05-24 15:51:08 utils:554] > total number of epochs: 1\n",
      "[NeMo I 2025-05-24 15:51:08 utils:554] Load the _IndexReader from /workspace/preprocessed_data/XTT22_train_byte-level_test.idx\n",
      "[NeMo I 2025-05-24 15:51:08 utils:554] \tExtract the sequence lengths\n",
      "[NeMo I 2025-05-24 15:51:08 utils:554] \tExtract the sequence pointers\n",
      "[NeMo I 2025-05-24 15:51:08 utils:554] \tExtract the document indices\n",
      "[NeMo I 2025-05-24 15:51:08 utils:554] > total number of sequences: 606\n",
      "[NeMo I 2025-05-24 15:51:08 utils:554] > total number of documents: 606\n",
      "[NeMo I 2025-05-24 15:51:08 utils:554] Build and save the Evo2Dataset test indices\n",
      "[NeMo I 2025-05-24 15:52:44 utils:554] > total number of samples: 981405895\n",
      "[NeMo I 2025-05-24 15:52:44 utils:554] > total number of epochs: 1\n",
      "[NeMo I 2025-05-24 15:52:45 nemo_logging:393] Padded vocab_size: 512, original vocab_size: 512, dummy tokens: 0.\n",
      "[NeMo W 2025-05-24 15:52:45 random:222] CPU RNG state changed within GPU RNG context\n",
      "[NeMo W 2025-05-24 15:52:45 random:222] CPU RNG state changed within GPU RNG context\n",
      "[NeMo W 2025-05-24 15:52:45 random:222] CPU RNG state changed within GPU RNG context\n",
      "[NeMo W 2025-05-24 15:52:45 random:222] CPU RNG state changed within GPU RNG context\n",
      "[NeMo W 2025-05-24 15:52:45 random:222] CPU RNG state changed within GPU RNG context\n",
      "[NeMo W 2025-05-24 15:52:45 random:222] CPU RNG state changed within GPU RNG context\n",
      "[NeMo W 2025-05-24 15:52:45 random:222] CPU RNG state changed within GPU RNG context\n",
      "[NeMo W 2025-05-24 15:52:45 random:222] CPU RNG state changed within GPU RNG context\n",
      "[NeMo W 2025-05-24 15:52:45 random:222] CPU RNG state changed within GPU RNG context\n",
      "[NeMo W 2025-05-24 15:52:45 random:222] CPU RNG state changed within GPU RNG context\n",
      "[NeMo W 2025-05-24 15:52:45 random:222] CPU RNG state changed within GPU RNG context\n",
      "[NeMo W 2025-05-24 15:52:45 random:222] CPU RNG state changed within GPU RNG context\n",
      "[NeMo W 2025-05-24 15:52:45 random:222] CPU RNG state changed within GPU RNG context\n",
      "[NeMo W 2025-05-24 15:52:45 random:222] CPU RNG state changed within GPU RNG context\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "[NeMo I 2025-05-24 15:52:45 nemo_logging:393] Copying Trainer's 'max_steps' (100) to LR scheduler's 'max_steps'.\n",
      "[NeMo I 2025-05-24 15:52:45 num_microbatches_calculator:228] setting number of microbatches to constant 1\n",
      "[NeMo I 2025-05-24 15:52:45 nemo_logging:393]  > number of parameters on (tensor, pipeline) model parallel rank (0 ,0): 1108204800\n",
      "[NeMo I 2025-05-24 15:52:45 utils:554] Setting up DistributedDataParallel with config DistributedDataParallelConfig(grad_reduce_in_fp32=False, overlap_grad_reduce=False, overlap_param_gather=False, align_param_gather=False, use_distributed_optimizer=True, num_distributed_optimizer_instances=1, check_for_nan_in_grad=True, check_for_large_grads=False, bucket_size=None, pad_buckets_for_high_nccl_busbw=False, average_in_collective=True, fp8_param_gather=False, use_custom_fsdp=False, data_parallel_sharding_strategy='no_shard', gradient_reduce_div_fusion=True, suggested_communication_unit_size=None, preserve_fp32_weights=True, keep_fp8_transpose_cache_when_using_custom_fsdp=False)\n",
      "[NeMo I 2025-05-24 15:52:45 utils:575] Number of buckets for gradient all-reduce / reduce-scatter: 1\n",
      "    Params for bucket 1 (1108204800 elements, 1108204800 padded size):\n",
      "    \tmodule.decoder.layers.22.mixer.dense_projection.layer_norm_weight\n",
      "    \tmodule.decoder.layers.19.mixer.dense.bias\n",
      "    \tmodule.decoder.layers.18.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.14.mixer.dense_projection.layer_norm_weight\n",
      "    \tmodule.decoder.layers.11.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.7.mixer.dense_projection.layer_norm_weight\n",
      "    \tmodule.decoder.layers.3.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.22.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.12.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.5.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.2.mixer.mixer.filter.p\n",
      "    \tmodule.decoder.layers.0.mixer.dense.weight\n",
      "    \tmodule.embedding.word_embeddings.weight\n",
      "    \tmodule.decoder.layers.23.mixer.dense.weight\n",
      "    \tmodule.decoder.layers.18.mixer.dense.weight\n",
      "    \tmodule.decoder.layers.16.mixer.dense_projection.layer_norm_weight\n",
      "    \tmodule.decoder.layers.15.mixer.mixer.conv_bias\n",
      "    \tmodule.decoder.layers.11.mixer.dense.weight\n",
      "    \tmodule.decoder.layers.9.mixer.dense_projection.layer_norm_weight\n",
      "    \tmodule.decoder.layers.8.mixer.mixer.conv_bias\n",
      "    \tmodule.decoder.layers.5.mixer.mixer.filter.h\n",
      "    \tmodule.decoder.layers.24.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.16.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.9.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.2.mixer.hyena_proj_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.17.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.21.mixer.dense_projection.layer_norm_weight\n",
      "    \tmodule.decoder.layers.18.mixer.dense.bias\n",
      "    \tmodule.decoder.layers.13.mixer.mixer.filter.R\n",
      "    \tmodule.decoder.layers.11.mixer.dense.bias\n",
      "    \tmodule.decoder.layers.10.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.6.mixer.mixer.filter.R\n",
      "    \tmodule.decoder.layers.2.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.0.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.19.mixer.dense_projection.layer_norm_weight\n",
      "    \tmodule.decoder.layers.14.mixer.mixer.short_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.12.mixer.dense_projection.layer_norm_weight\n",
      "    \tmodule.decoder.layers.7.mixer.mixer.short_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.4.mixer.dense_projection.layer_norm_weight\n",
      "    \tmodule.decoder.layers.2.mixer.mixer.conv_bias\n",
      "    \tmodule.decoder.layers.23.mixer.dense_projection.layer_norm_weight\n",
      "    \tmodule.decoder.layers.22.mixer.dense.bias\n",
      "    \tmodule.decoder.layers.19.mixer.mixer.conv_bias\n",
      "    \tmodule.decoder.layers.15.mixer.hyena_proj_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.12.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.12.mixer.dense.bias\n",
      "    \tmodule.decoder.layers.8.mixer.hyena_proj_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.5.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.2.mixer.dense.bias\n",
      "    \tmodule.decoder.layers.0.mixer.mixer.short_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.23.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.16.mixer.mixer.filter.gamma\n",
      "    \tmodule.decoder.layers.13.mixer.dense.weight\n",
      "    \tmodule.decoder.layers.10.self_attention.linear_proj.bias\n",
      "    \tmodule.decoder.layers.9.mixer.mixer.filter.gamma\n",
      "    \tmodule.decoder.layers.6.mixer.dense.weight\n",
      "    \tmodule.decoder.final_norm.weight\n",
      "    \tmodule.decoder.layers.24.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.20.mixer.mixer.filter.R\n",
      "    \tmodule.decoder.layers.17.self_attention.linear_proj.weight\n",
      "    \tmodule.decoder.layers.15.mixer.mixer.filter.h\n",
      "    \tmodule.decoder.layers.10.self_attention.linear_proj.weight\n",
      "    \tmodule.decoder.layers.8.mixer.mixer.filter.h\n",
      "    \tmodule.decoder.layers.5.mixer.dense.bias\n",
      "    \tmodule.decoder.layers.4.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.2.mixer.dense_projection.weight\n",
      "    \tmodule.decoder.layers.0.mixer.hyena_proj_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.21.mixer.mixer.short_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.18.mixer.dense_projection.layer_norm_weight\n",
      "    \tmodule.decoder.layers.15.mixer.dense.bias\n",
      "    \tmodule.decoder.layers.15.mixer.dense.weight\n",
      "    \tmodule.decoder.layers.11.mixer.dense_projection.layer_norm_weight\n",
      "    \tmodule.decoder.layers.8.mixer.dense.bias\n",
      "    \tmodule.decoder.layers.8.mixer.dense.weight\n",
      "    \tmodule.decoder.layers.2.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.1.mixer.dense_projection.layer_norm_weight\n",
      "    \tmodule.decoder.layers.22.mixer.hyena_proj_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.20.mixer.mixer.conv_bias\n",
      "    \tmodule.decoder.layers.16.mixer.mixer.filter.p\n",
      "    \tmodule.decoder.layers.14.mixer.hyena_proj_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.9.mixer.mixer.filter.p\n",
      "    \tmodule.decoder.layers.7.mixer.hyena_proj_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.5.mixer.dense_projection.layer_norm_weight\n",
      "    \tmodule.decoder.layers.4.mixer.mixer.short_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.1.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.23.mixer.mixer.filter.gamma\n",
      "    \tmodule.decoder.layers.20.mixer.dense.weight\n",
      "    \tmodule.decoder.layers.15.mixer.dense_projection.weight\n",
      "    \tmodule.decoder.layers.13.mixer.dense_projection.layer_norm_weight\n",
      "    \tmodule.decoder.layers.8.mixer.dense_projection.weight\n",
      "    \tmodule.decoder.layers.6.mixer.dense_projection.layer_norm_weight\n",
      "    \tmodule.decoder.layers.24.self_attention.linear_proj.weight\n",
      "    \tmodule.decoder.layers.22.mixer.mixer.filter.h\n",
      "    \tmodule.decoder.layers.16.mixer.hyena_proj_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.13.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.9.mixer.hyena_proj_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.6.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.3.self_attention.linear_qkv.weight\n",
      "    \tmodule.decoder.layers.3.self_attention.linear_proj.bias\n",
      "    \tmodule.decoder.layers.1.mixer.mixer.conv_bias\n",
      "    \tmodule.decoder.layers.22.mixer.dense.weight\n",
      "    \tmodule.decoder.layers.21.mixer.dense.bias\n",
      "    \tmodule.decoder.layers.16.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.14.mixer.dense.bias\n",
      "    \tmodule.decoder.layers.9.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.6.mixer.mixer.conv_bias\n",
      "    \tmodule.decoder.layers.4.mixer.dense.bias\n",
      "    \tmodule.decoder.layers.0.mixer.dense_projection.layer_norm_weight\n",
      "    \tmodule.decoder.layers.23.mixer.mixer.filter.p\n",
      "    \tmodule.decoder.layers.21.mixer.hyena_proj_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.18.mixer.mixer.short_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.17.self_attention.linear_proj.bias\n",
      "    \tmodule.decoder.layers.15.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.11.mixer.mixer.short_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.8.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.3.self_attention.linear_proj.weight\n",
      "    \tmodule.decoder.layers.22.mixer.dense_projection.weight\n",
      "    \tmodule.decoder.layers.20.mixer.dense_projection.layer_norm_weight\n",
      "    \tmodule.decoder.layers.19.mixer.hyena_proj_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.16.mixer.dense.bias\n",
      "    \tmodule.decoder.layers.14.mixer.dense_projection.weight\n",
      "    \tmodule.decoder.layers.12.mixer.hyena_proj_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.9.mixer.dense.bias\n",
      "    \tmodule.decoder.layers.7.mixer.dense_projection.weight\n",
      "    \tmodule.decoder.layers.4.mixer.hyena_proj_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.0.mixer.dense.bias\n",
      "    \tmodule.decoder.layers.23.mixer.hyena_proj_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.20.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.17.self_attention.linear_qkv.weight\n",
      "    \tmodule.decoder.layers.13.mixer.mixer.filter.gamma\n",
      "    \tmodule.decoder.layers.10.self_attention.linear_qkv.weight\n",
      "    \tmodule.decoder.layers.6.mixer.mixer.filter.gamma\n",
      "    \tmodule.decoder.layers.23.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.22.mixer.mixer.conv_bias\n",
      "    \tmodule.decoder.layers.19.mixer.mixer.filter.h\n",
      "    \tmodule.decoder.layers.16.mixer.dense_projection.weight\n",
      "    \tmodule.decoder.layers.12.mixer.mixer.filter.h\n",
      "    \tmodule.decoder.layers.9.mixer.dense_projection.weight\n",
      "    \tmodule.decoder.layers.3.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.22.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.19.mixer.dense.weight\n",
      "    \tmodule.decoder.layers.16.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.14.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.12.mixer.dense.weight\n",
      "    \tmodule.decoder.layers.9.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.7.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.5.mixer.dense.weight\n",
      "    \tmodule.decoder.layers.5.mixer.dense_projection.weight\n",
      "    \tmodule.decoder.layers.2.mixer.mixer.filter.R\n",
      "    \tmodule.decoder.layers.23.mixer.dense.bias\n",
      "    \tmodule.decoder.layers.21.mixer.dense_projection.weight\n",
      "    \tmodule.decoder.layers.18.mixer.hyena_proj_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.16.mixer.mixer.conv_bias\n",
      "    \tmodule.decoder.layers.13.mixer.mixer.filter.p\n",
      "    \tmodule.decoder.layers.11.mixer.hyena_proj_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.9.mixer.mixer.conv_bias\n",
      "    \tmodule.decoder.layers.6.mixer.mixer.filter.p\n",
      "    \tmodule.decoder.layers.1.mixer.hyena_proj_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.24.self_attention.linear_qkv.weight\n",
      "    \tmodule.decoder.layers.20.mixer.mixer.filter.gamma\n",
      "    \tmodule.decoder.layers.19.mixer.dense_projection.weight\n",
      "    \tmodule.decoder.layers.14.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.12.mixer.dense_projection.weight\n",
      "    \tmodule.decoder.layers.7.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.5.mixer.hyena_proj_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.4.mixer.dense_projection.weight\n",
      "    \tmodule.decoder.layers.1.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.0.mixer.dense_projection.weight\n",
      "    \tmodule.decoder.layers.23.mixer.dense_projection.weight\n",
      "    \tmodule.decoder.layers.17.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.13.mixer.hyena_proj_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.10.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.6.mixer.hyena_proj_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.2.mixer.dense.weight\n",
      "    \tmodule.decoder.layers.1.mixer.dense.bias\n",
      "    \tmodule.decoder.layers.23.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.21.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.13.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.12.mixer.mixer.conv_bias\n",
      "    \tmodule.decoder.layers.6.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.17.self_attention.linear_qkv.layer_norm_weight\n",
      "    \tmodule.decoder.layers.23.mixer.mixer.conv_bias\n",
      "    \tmodule.decoder.layers.20.mixer.mixer.filter.p\n",
      "    \tmodule.decoder.layers.19.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.14.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.12.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.10.self_attention.linear_qkv.layer_norm_weight\n",
      "    \tmodule.decoder.layers.7.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.5.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.4.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.21.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.18.mixer.dense_projection.weight\n",
      "    \tmodule.decoder.layers.15.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.13.mixer.dense.bias\n",
      "    \tmodule.decoder.layers.11.mixer.dense_projection.weight\n",
      "    \tmodule.decoder.layers.8.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.6.mixer.dense.bias\n",
      "    \tmodule.decoder.layers.3.self_attention.linear_qkv.layer_norm_weight\n",
      "    \tmodule.decoder.layers.1.mixer.dense_projection.weight\n",
      "    \tmodule.decoder.layers.24.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.24.self_attention.linear_proj.bias\n",
      "    \tmodule.decoder.layers.20.mixer.hyena_proj_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.19.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.14.mixer.dense.weight\n",
      "    \tmodule.decoder.layers.7.mixer.dense.weight\n",
      "    \tmodule.decoder.layers.5.mixer.mixer.conv_bias\n",
      "    \tmodule.decoder.layers.4.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.2.mixer.dense_projection.layer_norm_weight\n",
      "    \tmodule.decoder.layers.20.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.13.mixer.dense_projection.weight\n",
      "    \tmodule.decoder.layers.6.mixer.dense_projection.weight\n",
      "    \tmodule.decoder.layers.2.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.1.mixer.mixer.filter.h\n",
      "    \tmodule.decoder.layers.24.self_attention.linear_qkv.layer_norm_weight\n",
      "    \tmodule.decoder.layers.21.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.18.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.16.mixer.mixer.filter.R\n",
      "    \tmodule.decoder.layers.13.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.11.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.9.mixer.mixer.filter.R\n",
      "    \tmodule.decoder.layers.6.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.3.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.1.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.22.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.20.mixer.dense.bias\n",
      "    \tmodule.decoder.layers.19.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.15.mixer.dense_projection.layer_norm_weight\n",
      "    \tmodule.decoder.layers.13.mixer.mixer.conv_bias\n",
      "    \tmodule.decoder.layers.8.mixer.dense_projection.layer_norm_weight\n",
      "    \tmodule.decoder.layers.7.mixer.dense.bias\n",
      "    \tmodule.decoder.layers.0.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.21.mixer.dense.weight\n",
      "    \tmodule.decoder.layers.18.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.15.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.11.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.8.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.20.mixer.dense_projection.weight\n",
      "    \tmodule.decoder.layers.16.mixer.dense.weight\n",
      "    \tmodule.decoder.layers.9.mixer.dense.weight\n",
      "    \tmodule.decoder.layers.4.mixer.dense.weight\n",
      "    \tmodule.decoder.layers.2.mixer.mixer.filter.gamma\n",
      "    \tmodule.decoder.layers.23.mixer.mixer.filter.R\n",
      "    \tmodule.decoder.layers.20.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.17.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.10.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.0.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.1.mixer.dense.weight\n",
      "[NeMo I 2025-05-24 15:52:45 utils:554] Setting up optimizer with config OptimizerConfig(optimizer='adam', lr=0.0001, min_lr=None, decoupled_lr=None, decoupled_min_lr=None, weight_decay=0.01, fp16=False, bf16=True, params_dtype=torch.bfloat16, use_precision_aware_optimizer=False, store_param_remainders=True, main_grads_dtype=torch.float32, main_params_dtype=torch.float32, exp_avg_dtype=torch.float32, exp_avg_sq_dtype=torch.float32, loss_scale=None, initial_loss_scale=4294967296, min_loss_scale=1.0, loss_scale_window=1000, hysteresis=2, adam_beta1=0.9, adam_beta2=0.95, adam_eps=1e-08, sgd_momentum=0.9, use_distributed_optimizer=True, overlap_param_gather_with_optimizer_step=False, optimizer_cpu_offload=False, optimizer_offload_fraction=0.0, use_torch_optimizer_for_cpu_offload=False, overlap_cpu_optimizer_d2h_h2d=False, pin_cpu_grads=True, pin_cpu_params=True, clip_grad=1.0, log_num_zeros_in_grad=False, barrier_with_L1_time=False, timers=None, config_logger_dir='')\n",
      "[NeMo I 2025-05-24 15:52:45 nemo_logging:393] Doing selective restore from RestoreConfig(path='nemo2_evo2_1b_8k', adapter_path=None, load_model_state=True, load_optim_state=False, load_artifacts=True)\n",
      "[NeMo I 2025-05-24 15:52:45 nemo_logging:393] Using <megatron.core.dist_checkpointing.strategies.fully_parallel.FullyParallelLoadStrategyWrapper object at 0x76022cd99b80> dist-ckpt load strategy.\n",
      "[NeMo I 2025-05-24 15:52:47 nemo_logging:393] Global Checkpoint Load : Rank : 0 : Start time : 1748101965.565s : Time spent in load_checkpoint: 1.998s\n",
      "[NeMo I 2025-05-24 15:52:47 nemo_logging:393] Restoring model weights from RestoreConfig(path='nemo2_evo2_1b_8k', adapter_path=None, load_model_state=True, load_optim_state=False, load_artifacts=True)\n",
      "[NeMo I 2025-05-24 15:52:47 nemo_logging:393] Finished restoring from RestoreConfig(path='nemo2_evo2_1b_8k', adapter_path=None, load_model_state=True, load_optim_state=False, load_artifacts=True), cleaning up.\n",
      "┏━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━┓\n",
      "┃\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mName                               \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mType             \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mParams\u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mMode \u001b[0m\u001b[1;35m \u001b[0m┃\n",
      "┡━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━┩\n",
      "│\u001b[2m \u001b[0m\u001b[2m0\u001b[0m\u001b[2m \u001b[0m│ module                              │ DDP               │  1.1 B │ train │\n",
      "│\u001b[2m \u001b[0m\u001b[2m1\u001b[0m\u001b[2m \u001b[0m│ module.module                       │ Float16Module     │  1.1 B │ train │\n",
      "│\u001b[2m \u001b[0m\u001b[2m2\u001b[0m\u001b[2m \u001b[0m│ module.module.module                │ HyenaModel        │  1.1 B │ train │\n",
      "│\u001b[2m \u001b[0m\u001b[2m3\u001b[0m\u001b[2m \u001b[0m│ module.module.module.embedding      │ LanguageModelEmb… │  983 K │ train │\n",
      "│\u001b[2m \u001b[0m\u001b[2m4\u001b[0m\u001b[2m \u001b[0m│ module.module.module.rotary_pos_emb │ RotaryEmbedding   │      0 │ train │\n",
      "│\u001b[2m \u001b[0m\u001b[2m5\u001b[0m\u001b[2m \u001b[0m│ module.module.module.decoder        │ HyenaStack        │  1.1 B │ train │\n",
      "│\u001b[2m \u001b[0m\u001b[2m6\u001b[0m\u001b[2m \u001b[0m│ module.module.module.output_layer   │ ColumnParallelLi… │      0 │ train │\n",
      "└───┴─────────────────────────────────────┴───────────────────┴────────┴───────┘\n",
      "\u001b[1mTrainable params\u001b[0m: 1.1 B                                                         \n",
      "\u001b[1mNon-trainable params\u001b[0m: 0                                                         \n",
      "\u001b[1mTotal params\u001b[0m: 1.1 B                                                             \n",
      "\u001b[1mTotal estimated model params size (MB)\u001b[0m: 4.4 K                                   \n",
      "\u001b[1mModules in train mode\u001b[0m: 356                                                      \n",
      "\u001b[1mModules in eval mode\u001b[0m: 0                                                         \n",
      "[NeMo W 2025-05-24 15:53:47 rerun_state_machine:1264] Implicit initialization of Rerun State Machine!\n",
      "[NeMo W 2025-05-24 15:53:47 rerun_state_machine:239] RerunStateMachine initialized in mode RerunMode.DISABLED\n",
      "Training epoch 0, iteration 0/99 | lr: 0 | global_batch_size: 1 | global_step: 0 | reduced_train_loss: 1.46 | train_step_timing in s: 23.05\n",
      "Training epoch 0, iteration 1/99 | lr: 2e-05 | global_batch_size: 1 | global_step: 1 | reduced_train_loss: 1.472 | train_step_timing in s: 2.461 | consumed_samples: 2\n",
      "Training epoch 0, iteration 2/99 | lr: 4e-05 | global_batch_size: 1 | global_step: 2 | reduced_train_loss: 1.823 | train_step_timing in s: 0.3414 | consumed_samples: 3\n",
      "Training epoch 0, iteration 3/99 | lr: 6e-05 | global_batch_size: 1 | global_step: 3 | reduced_train_loss: 1.331 | train_step_timing in s: 0.3744 | consumed_samples: 4\n",
      "Training epoch 0, iteration 4/99 | lr: 8e-05 | global_batch_size: 1 | global_step: 4 | reduced_train_loss: 1.337 | train_step_timing in s: 0.3341 | consumed_samples: 5\n",
      "Training epoch 0, iteration 5/99 | lr: 0.0001 | global_batch_size: 1 | global_step: 5 | reduced_train_loss: 2.111 | train_step_timing in s: 0.3964 | consumed_samples: 6\n",
      "Training epoch 0, iteration 6/99 | lr: 3e-05 | global_batch_size: 1 | global_step: 6 | reduced_train_loss: 0.5181 | train_step_timing in s: 0.3797 | consumed_samples: 7\n",
      "Training epoch 0, iteration 7/99 | lr: 3e-05 | global_batch_size: 1 | global_step: 7 | reduced_train_loss: 5.48 | train_step_timing in s: 0.3783 | consumed_samples: 8\n",
      "Training epoch 0, iteration 8/99 | lr: 3e-05 | global_batch_size: 1 | global_step: 8 | reduced_train_loss: 0.5512 | train_step_timing in s: 0.323 | consumed_samples: 9\n",
      "Training epoch 0, iteration 9/99 | lr: 3e-05 | global_batch_size: 1 | global_step: 9 | reduced_train_loss: 2.03 | train_step_timing in s: 0.3056 | consumed_samples: 10\n",
      "Training epoch 0, iteration 10/99 | lr: 3e-05 | global_batch_size: 1 | global_step: 10 | reduced_train_loss: 1.445 | train_step_timing in s: 0.4078 | consumed_samples: 11\n",
      "Training epoch 0, iteration 11/99 | lr: 3e-05 | global_batch_size: 1 | global_step: 11 | reduced_train_loss: 2.197 | train_step_timing in s: 0.389 | consumed_samples: 12\n",
      "Training epoch 0, iteration 12/99 | lr: 3e-05 | global_batch_size: 1 | global_step: 12 | reduced_train_loss: 0.93 | train_step_timing in s: 0.3769 | consumed_samples: 13\n",
      "Training epoch 0, iteration 13/99 | lr: 3e-05 | global_batch_size: 1 | global_step: 13 | reduced_train_loss: 0.7602 | train_step_timing in s: 0.3256 | consumed_samples: 14\n",
      "Training epoch 0, iteration 14/99 | lr: 3e-05 | global_batch_size: 1 | global_step: 14 | reduced_train_loss: 0.5082 | train_step_timing in s: 0.3603 | consumed_samples: 15\n",
      "Training epoch 0, iteration 15/99 | lr: 3e-05 | global_batch_size: 1 | global_step: 15 | reduced_train_loss: 0.3451 | train_step_timing in s: 0.3301 | consumed_samples: 16\n",
      "Training epoch 0, iteration 16/99 | lr: 3e-05 | global_batch_size: 1 | global_step: 16 | reduced_train_loss: 2.594 | train_step_timing in s: 0.3269 | consumed_samples: 17\n",
      "Training epoch 0, iteration 17/99 | lr: 3e-05 | global_batch_size: 1 | global_step: 17 | reduced_train_loss: 5.31 | train_step_timing in s: 0.3985 | consumed_samples: 18\n",
      "Training epoch 0, iteration 18/99 | lr: 3e-05 | global_batch_size: 1 | global_step: 18 | reduced_train_loss: 3.781 | train_step_timing in s: 0.4087 | consumed_samples: 19\n",
      "Training epoch 0, iteration 19/99 | lr: 3e-05 | global_batch_size: 1 | global_step: 19 | reduced_train_loss: 0.2096 | train_step_timing in s: 0.3847 | consumed_samples: 20\n",
      "Training epoch 0, iteration 20/99 | lr: 3e-05 | global_batch_size: 1 | global_step: 20 | reduced_train_loss: 3.309 | train_step_timing in s: 0.3851 | consumed_samples: 21\n",
      "Training epoch 0, iteration 21/99 | lr: 3e-05 | global_batch_size: 1 | global_step: 21 | reduced_train_loss: 0.2375 | train_step_timing in s: 0.3793 | consumed_samples: 22\n",
      "Training epoch 0, iteration 22/99 | lr: 3e-05 | global_batch_size: 1 | global_step: 22 | reduced_train_loss: 2.854 | train_step_timing in s: 0.2789 | consumed_samples: 23\n",
      "Training epoch 0, iteration 23/99 | lr: 3e-05 | global_batch_size: 1 | global_step: 23 | reduced_train_loss: 2.665 | train_step_timing in s: 0.2611 | consumed_samples: 24\n",
      "Training epoch 0, iteration 24/99 | lr: 3e-05 | global_batch_size: 1 | global_step: 24 | reduced_train_loss: 0.2788 | train_step_timing in s: 0.3081 | consumed_samples: 25\n",
      "Training epoch 0, iteration 25/99 | lr: 3e-05 | global_batch_size: 1 | global_step: 25 | reduced_train_loss: 2.379 | train_step_timing in s: 0.3379 | consumed_samples: 26\n",
      "Training epoch 0, iteration 26/99 | lr: 3e-05 | global_batch_size: 1 | global_step: 26 | reduced_train_loss: 0.2992 | train_step_timing in s: 0.352 | consumed_samples: 27\n",
      "Training epoch 0, iteration 27/99 | lr: 3e-05 | global_batch_size: 1 | global_step: 27 | reduced_train_loss: 2.151 | train_step_timing in s: 0.362 | consumed_samples: 28\n",
      "Training epoch 0, iteration 28/99 | lr: 3e-05 | global_batch_size: 1 | global_step: 28 | reduced_train_loss: 2.96 | train_step_timing in s: 0.3525 | consumed_samples: 29\n",
      "Training epoch 0, iteration 29/99 | lr: 3e-05 | global_batch_size: 1 | global_step: 29 | reduced_train_loss: 1.898 | train_step_timing in s: 0.3427 | consumed_samples: 30\n",
      "Training epoch 0, iteration 30/99 | lr: 3e-05 | global_batch_size: 1 | global_step: 30 | reduced_train_loss: 0.3907 | train_step_timing in s: 0.3136 | consumed_samples: 31\n",
      "Training epoch 0, iteration 31/99 | lr: 3e-05 | global_batch_size: 1 | global_step: 31 | reduced_train_loss: 0.4098 | train_step_timing in s: 0.43 | consumed_samples: 32\n",
      "Training epoch 0, iteration 32/99 | lr: 3e-05 | global_batch_size: 1 | global_step: 32 | reduced_train_loss: 2.892 | train_step_timing in s: 0.414 | consumed_samples: 33\n",
      "Training epoch 0, iteration 33/99 | lr: 3e-05 | global_batch_size: 1 | global_step: 33 | reduced_train_loss: 0.4136 | train_step_timing in s: 0.3915 | consumed_samples: 34\n",
      "Training epoch 0, iteration 34/99 | lr: 3e-05 | global_batch_size: 1 | global_step: 34 | reduced_train_loss: 2.76 | train_step_timing in s: 0.366 | consumed_samples: 35\n",
      "Training epoch 0, iteration 35/99 | lr: 3e-05 | global_batch_size: 1 | global_step: 35 | reduced_train_loss: 0.3878 | train_step_timing in s: 0.3867 | consumed_samples: 36\n",
      "Training epoch 0, iteration 36/99 | lr: 3e-05 | global_batch_size: 1 | global_step: 36 | reduced_train_loss: 1.742 | train_step_timing in s: 0.3439 | consumed_samples: 37\n",
      "Training epoch 0, iteration 37/99 | lr: 3e-05 | global_batch_size: 1 | global_step: 37 | reduced_train_loss: 0.3666 | train_step_timing in s: 0.3009 | consumed_samples: 38\n",
      "Training epoch 0, iteration 38/99 | lr: 3e-05 | global_batch_size: 1 | global_step: 38 | reduced_train_loss: 2.89 | train_step_timing in s: 0.3271 | consumed_samples: 39\n",
      "Training epoch 0, iteration 39/99 | lr: 3e-05 | global_batch_size: 1 | global_step: 39 | reduced_train_loss: 2.478 | train_step_timing in s: 0.3971 | consumed_samples: 40\n",
      "Training epoch 0, iteration 40/99 | lr: 3e-05 | global_batch_size: 1 | global_step: 40 | reduced_train_loss: 0.3569 | train_step_timing in s: 0.3514 | consumed_samples: 41\n",
      "Training epoch 0, iteration 41/99 | lr: 3e-05 | global_batch_size: 1 | global_step: 41 | reduced_train_loss: 1.986 | train_step_timing in s: 0.3553 | consumed_samples: 42\n",
      "Training epoch 0, iteration 42/99 | lr: 3e-05 | global_batch_size: 1 | global_step: 42 | reduced_train_loss: 2.336 | train_step_timing in s: 0.3706 | consumed_samples: 43\n",
      "Training epoch 0, iteration 43/99 | lr: 3e-05 | global_batch_size: 1 | global_step: 43 | reduced_train_loss: 0.3645 | train_step_timing in s: 0.3656 | consumed_samples: 44\n",
      "Training epoch 0, iteration 44/99 | lr: 3e-05 | global_batch_size: 1 | global_step: 44 | reduced_train_loss: 1.997 | train_step_timing in s: 0.306 | consumed_samples: 45\n",
      "Training epoch 0, iteration 45/99 | lr: 3e-05 | global_batch_size: 1 | global_step: 45 | reduced_train_loss: 0.3719 | train_step_timing in s: 0.3315 | consumed_samples: 46\n",
      "Training epoch 0, iteration 46/99 | lr: 3e-05 | global_batch_size: 1 | global_step: 46 | reduced_train_loss: 2.167 | train_step_timing in s: 0.396 | consumed_samples: 47\n",
      "Training epoch 0, iteration 47/99 | lr: 3e-05 | global_batch_size: 1 | global_step: 47 | reduced_train_loss: 2.89 | train_step_timing in s: 0.3722 | consumed_samples: 48\n",
      "Training epoch 0, iteration 48/99 | lr: 3e-05 | global_batch_size: 1 | global_step: 48 | reduced_train_loss: 0.3852 | train_step_timing in s: 0.3828 | consumed_samples: 49\n",
      "Training epoch 0, iteration 49/99 | lr: 3e-05 | global_batch_size: 1 | global_step: 49 | reduced_train_loss: 2.048 | train_step_timing in s: 0.4227 | consumed_samples: 50\n",
      "Epoch 0, global step 49: 'val_loss' was not in top 5\n",
      "[NeMo I 2025-05-24 15:54:07 nemo_logging:393] Using FullyParallelSaveStrategyWrapper(torch_dist, 1) dist-ckpt save strategy.\n",
      "[NeMo I 2025-05-24 15:54:13 nemo_logging:393] Global Checkpoint Save : Rank: 0 : Iteration: 49 : Start time: 1748102047.680s : Save duration: 6.254s\n",
      "[NeMo I 2025-05-24 15:54:37 nemo_logging:393] Scheduled async checkpoint save for /workspace/results/evo2/checkpoints/evo2--val_loss=0.0000-epoch=0-consumed_samples=50.0-last.ckpt\n",
      "[NeMo I 2025-05-24 15:54:37 nemo_logging:393] Async finalization time took 0.004 s\n",
      "Validation: iteration 1/20\n",
      "Validation: iteration 2/20\n",
      "Validation: iteration 3/20\n",
      "Validation: iteration 4/20\n",
      "Validation: iteration 5/20\n",
      "Validation: iteration 6/20\n",
      "Validation: iteration 7/20\n",
      "Validation: iteration 8/20\n",
      "Validation: iteration 9/20\n",
      "Validation: iteration 10/20\n",
      "Validation: iteration 11/20\n",
      "Validation: iteration 12/20\n",
      "Validation: iteration 13/20\n",
      "Validation: iteration 14/20\n",
      "Validation: iteration 15/20\n",
      "Validation: iteration 16/20\n",
      "Validation: iteration 17/20\n",
      "Validation: iteration 18/20\n",
      "Validation: iteration 19/20\n",
      "Validation: iteration 20/20\n",
      "[NeMo W 2025-05-24 15:55:27 nemo_logging:405] /usr/local/lib/python3.12/dist-packages/lightning/pytorch/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('global_batch_size', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "    \n",
      "[NeMo W 2025-05-24 15:55:27 nemo_logging:405] /usr/local/lib/python3.12/dist-packages/lightning/pytorch/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "    \n",
      "Training epoch 0, iteration 50/99 | lr: 3e-05 | global_batch_size: 1 | global_step: 50 | reduced_train_loss: 2.037 | train_step_timing in s: 0.3171 | consumed_samples: 51 | val_loss: 1.454\n",
      "[NeMo I 2025-05-24 15:55:27 nemo_logging:393] Successfully saved checkpoint from iteration      49 to /workspace/results/evo2/checkpoints/evo2--val_loss=0.0000-epoch=0-consumed_samples=50.0-last.ckpt\n",
      "[NeMo I 2025-05-24 15:55:27 nemo_logging:393] Async checkpoint save for step 50 (/workspace/results/evo2/checkpoints/evo2--val_loss=0.0000-epoch=0-consumed_samples=50.0-last.ckpt) finalized successfully.\n",
      "[NeMo I 2025-05-24 15:55:27 nemo_logging:393] Async finalization time took 0.102 s\n",
      "Training epoch 0, iteration 51/99 | lr: 3e-05 | global_batch_size: 1 | global_step: 51 | reduced_train_loss: 2.779 | train_step_timing in s: 0.3318 | consumed_samples: 52 | val_loss: 1.454\n",
      "Training epoch 0, iteration 52/99 | lr: 3e-05 | global_batch_size: 1 | global_step: 52 | reduced_train_loss: 1.957 | train_step_timing in s: 0.3909 | consumed_samples: 53 | val_loss: 1.454\n",
      "Training epoch 0, iteration 53/99 | lr: 3e-05 | global_batch_size: 1 | global_step: 53 | reduced_train_loss: 1.992 | train_step_timing in s: 0.3908 | consumed_samples: 54 | val_loss: 1.454\n",
      "Training epoch 0, iteration 54/99 | lr: 3e-05 | global_batch_size: 1 | global_step: 54 | reduced_train_loss: 1.826 | train_step_timing in s: 0.3985 | consumed_samples: 55 | val_loss: 1.454\n",
      "Training epoch 0, iteration 55/99 | lr: 3e-05 | global_batch_size: 1 | global_step: 55 | reduced_train_loss: 0.5121 | train_step_timing in s: 0.3803 | consumed_samples: 56 | val_loss: 1.454\n",
      "Training epoch 0, iteration 56/99 | lr: 3e-05 | global_batch_size: 1 | global_step: 56 | reduced_train_loss: 1.675 | train_step_timing in s: 0.3961 | consumed_samples: 57 | val_loss: 1.454\n",
      "Training epoch 0, iteration 57/99 | lr: 3e-05 | global_batch_size: 1 | global_step: 57 | reduced_train_loss: 0.5731 | train_step_timing in s: 0.3165 | consumed_samples: 58 | val_loss: 1.454\n",
      "Training epoch 0, iteration 58/99 | lr: 3e-05 | global_batch_size: 1 | global_step: 58 | reduced_train_loss: 2.553 | train_step_timing in s: 0.3276 | consumed_samples: 59 | val_loss: 1.454\n",
      "Training epoch 0, iteration 59/99 | lr: 3e-05 | global_batch_size: 1 | global_step: 59 | reduced_train_loss: 0.6041 | train_step_timing in s: 0.4099 | consumed_samples: 60 | val_loss: 1.454\n",
      "Training epoch 0, iteration 60/99 | lr: 3e-05 | global_batch_size: 1 | global_step: 60 | reduced_train_loss: 0.6049 | train_step_timing in s: 0.389 | consumed_samples: 61 | val_loss: 1.454\n",
      "Training epoch 0, iteration 61/99 | lr: 3e-05 | global_batch_size: 1 | global_step: 61 | reduced_train_loss: 1.534 | train_step_timing in s: 0.3813 | consumed_samples: 62 | val_loss: 1.454\n",
      "Training epoch 0, iteration 62/99 | lr: 3e-05 | global_batch_size: 1 | global_step: 62 | reduced_train_loss: 2.382 | train_step_timing in s: 0.3868 | consumed_samples: 63 | val_loss: 1.454\n",
      "Training epoch 0, iteration 63/99 | lr: 3e-05 | global_batch_size: 1 | global_step: 63 | reduced_train_loss: 1.516 | train_step_timing in s: 0.4028 | consumed_samples: 64 | val_loss: 1.454\n",
      "Training epoch 0, iteration 64/99 | lr: 3e-05 | global_batch_size: 1 | global_step: 64 | reduced_train_loss: 0.6058 | train_step_timing in s: 0.3237 | consumed_samples: 65 | val_loss: 1.454\n",
      "Training epoch 0, iteration 65/99 | lr: 3e-05 | global_batch_size: 1 | global_step: 65 | reduced_train_loss: 2.254 | train_step_timing in s: 0.3438 | consumed_samples: 66 | val_loss: 1.454\n",
      "Training epoch 0, iteration 66/99 | lr: 3e-05 | global_batch_size: 1 | global_step: 66 | reduced_train_loss: 2.19 | train_step_timing in s: 0.3902 | consumed_samples: 67 | val_loss: 1.454\n",
      "Training epoch 0, iteration 67/99 | lr: 3e-05 | global_batch_size: 1 | global_step: 67 | reduced_train_loss: 0.6077 | train_step_timing in s: 0.3972 | consumed_samples: 68 | val_loss: 1.454\n",
      "Training epoch 0, iteration 68/99 | lr: 3e-05 | global_batch_size: 1 | global_step: 68 | reduced_train_loss: 0.6014 | train_step_timing in s: 0.384 | consumed_samples: 69 | val_loss: 1.454\n",
      "Training epoch 0, iteration 69/99 | lr: 3e-05 | global_batch_size: 1 | global_step: 69 | reduced_train_loss: 1.969 | train_step_timing in s: 0.3916 | consumed_samples: 70 | val_loss: 1.454\n",
      "Training epoch 0, iteration 70/99 | lr: 3e-05 | global_batch_size: 1 | global_step: 70 | reduced_train_loss: 1.596 | train_step_timing in s: 0.4204 | consumed_samples: 71 | val_loss: 1.454\n",
      "Training epoch 0, iteration 71/99 | lr: 3e-05 | global_batch_size: 1 | global_step: 71 | reduced_train_loss: 1.617 | train_step_timing in s: 0.3241 | consumed_samples: 72 | val_loss: 1.454\n",
      "Training epoch 0, iteration 72/99 | lr: 3e-05 | global_batch_size: 1 | global_step: 72 | reduced_train_loss: 2.525 | train_step_timing in s: 0.3687 | consumed_samples: 73 | val_loss: 1.454\n",
      "Training epoch 0, iteration 73/99 | lr: 3e-05 | global_batch_size: 1 | global_step: 73 | reduced_train_loss: 1.594 | train_step_timing in s: 0.3814 | consumed_samples: 74 | val_loss: 1.454\n",
      "Training epoch 0, iteration 74/99 | lr: 3e-05 | global_batch_size: 1 | global_step: 74 | reduced_train_loss: 0.6356 | train_step_timing in s: 0.3816 | consumed_samples: 75 | val_loss: 1.454\n",
      "Training epoch 0, iteration 75/99 | lr: 3e-05 | global_batch_size: 1 | global_step: 75 | reduced_train_loss: 1.529 | train_step_timing in s: 0.3908 | consumed_samples: 76 | val_loss: 1.454\n",
      "Training epoch 0, iteration 76/99 | lr: 3e-05 | global_batch_size: 1 | global_step: 76 | reduced_train_loss: 1.497 | train_step_timing in s: 0.3984 | consumed_samples: 77 | val_loss: 1.454\n",
      "Training epoch 0, iteration 77/99 | lr: 3e-05 | global_batch_size: 1 | global_step: 77 | reduced_train_loss: 0.6858 | train_step_timing in s: 0.331 | consumed_samples: 78 | val_loss: 1.454\n",
      "Training epoch 0, iteration 78/99 | lr: 3e-05 | global_batch_size: 1 | global_step: 78 | reduced_train_loss: 2.566 | train_step_timing in s: 0.3092 | consumed_samples: 79 | val_loss: 1.454\n",
      "Training epoch 0, iteration 79/99 | lr: 3e-05 | global_batch_size: 1 | global_step: 79 | reduced_train_loss: 1.367 | train_step_timing in s: 0.3405 | consumed_samples: 80 | val_loss: 1.454\n",
      "Training epoch 0, iteration 80/99 | lr: 3e-05 | global_batch_size: 1 | global_step: 80 | reduced_train_loss: 0.734 | train_step_timing in s: 0.3988 | consumed_samples: 81 | val_loss: 1.454\n",
      "Training epoch 0, iteration 81/99 | lr: 3e-05 | global_batch_size: 1 | global_step: 81 | reduced_train_loss: 1.81 | train_step_timing in s: 0.3874 | consumed_samples: 82 | val_loss: 1.454\n",
      "Training epoch 0, iteration 82/99 | lr: 3e-05 | global_batch_size: 1 | global_step: 82 | reduced_train_loss: 0.7574 | train_step_timing in s: 0.4045 | consumed_samples: 83 | val_loss: 1.454\n",
      "Training epoch 0, iteration 83/99 | lr: 3e-05 | global_batch_size: 1 | global_step: 83 | reduced_train_loss: 2.499 | train_step_timing in s: 0.4003 | consumed_samples: 84 | val_loss: 1.454\n",
      "Training epoch 0, iteration 84/99 | lr: 3e-05 | global_batch_size: 1 | global_step: 84 | reduced_train_loss: 2.47 | train_step_timing in s: 0.3715 | consumed_samples: 85 | val_loss: 1.454\n",
      "Training epoch 0, iteration 85/99 | lr: 3e-05 | global_batch_size: 1 | global_step: 85 | reduced_train_loss: 1.813 | train_step_timing in s: 0.3236 | consumed_samples: 86 | val_loss: 1.454\n",
      "Training epoch 0, iteration 86/99 | lr: 3e-05 | global_batch_size: 1 | global_step: 86 | reduced_train_loss: 1.276 | train_step_timing in s: 0.3799 | consumed_samples: 87 | val_loss: 1.454\n",
      "Training epoch 0, iteration 87/99 | lr: 3e-05 | global_batch_size: 1 | global_step: 87 | reduced_train_loss: 0.7981 | train_step_timing in s: 0.3897 | consumed_samples: 88 | val_loss: 1.454\n",
      "Training epoch 0, iteration 88/99 | lr: 3e-05 | global_batch_size: 1 | global_step: 88 | reduced_train_loss: 1.784 | train_step_timing in s: 0.3883 | consumed_samples: 89 | val_loss: 1.454\n",
      "Training epoch 0, iteration 89/99 | lr: 3e-05 | global_batch_size: 1 | global_step: 89 | reduced_train_loss: 1.757 | train_step_timing in s: 0.3889 | consumed_samples: 90 | val_loss: 1.454\n",
      "Training epoch 0, iteration 90/99 | lr: 3e-05 | global_batch_size: 1 | global_step: 90 | reduced_train_loss: 1.706 | train_step_timing in s: 0.3836 | consumed_samples: 91 | val_loss: 1.454\n",
      "Training epoch 0, iteration 91/99 | lr: 3e-05 | global_batch_size: 1 | global_step: 91 | reduced_train_loss: 0.8544 | train_step_timing in s: 0.3742 | consumed_samples: 92 | val_loss: 1.454\n",
      "Training epoch 0, iteration 92/99 | lr: 3e-05 | global_batch_size: 1 | global_step: 92 | reduced_train_loss: 1.351 | train_step_timing in s: 0.3215 | consumed_samples: 93 | val_loss: 1.454\n",
      "Training epoch 0, iteration 93/99 | lr: 3e-05 | global_batch_size: 1 | global_step: 93 | reduced_train_loss: 2.148 | train_step_timing in s: 0.3792 | consumed_samples: 94 | val_loss: 1.454\n",
      "Training epoch 0, iteration 94/99 | lr: 3e-05 | global_batch_size: 1 | global_step: 94 | reduced_train_loss: 0.891 | train_step_timing in s: 0.3855 | consumed_samples: 95 | val_loss: 1.454\n",
      "Training epoch 0, iteration 95/99 | lr: 3e-05 | global_batch_size: 1 | global_step: 95 | reduced_train_loss: 0.8889 | train_step_timing in s: 0.3739 | consumed_samples: 96 | val_loss: 1.454\n",
      "Training epoch 0, iteration 96/99 | lr: 3e-05 | global_batch_size: 1 | global_step: 96 | reduced_train_loss: 0.882 | train_step_timing in s: 0.3967 | consumed_samples: 97 | val_loss: 1.454\n",
      "Training epoch 0, iteration 97/99 | lr: 3e-05 | global_batch_size: 1 | global_step: 97 | reduced_train_loss: 1.506 | train_step_timing in s: 0.3965 | consumed_samples: 98 | val_loss: 1.454\n",
      "Training epoch 0, iteration 98/99 | lr: 3e-05 | global_batch_size: 1 | global_step: 98 | reduced_train_loss: 1.494 | train_step_timing in s: 0.3747 | consumed_samples: 99 | val_loss: 1.454\n",
      "Training epoch 0, iteration 99/99 | lr: 3e-05 | global_batch_size: 1 | global_step: 99 | reduced_train_loss: 1.544 | train_step_timing in s: 0.3161 | consumed_samples: 100 | val_loss: 1.454\n",
      "Epoch 0, global step 99: 'val_loss' reached 1.45366 (best 1.45366), saving model to '/workspace/results/evo2/checkpoints/evo2--val_loss=1.4537-epoch=0-consumed_samples=100.0.ckpt' as top 5\n",
      "[NeMo I 2025-05-24 15:55:46 nemo_logging:393] Global Checkpoint Save : Rank: 0 : Iteration: 99 : Start time: 1748102146.465s : Save duration: 0.504s\n",
      "[NeMo I 2025-05-24 15:55:52 nemo_logging:393] Scheduled async checkpoint save for /workspace/results/evo2/checkpoints/evo2--val_loss=1.4537-epoch=0-consumed_samples=100.0.ckpt\n",
      "[NeMo I 2025-05-24 15:55:53 nemo_logging:393] Global Checkpoint Save : Rank: 0 : Iteration: 99 : Start time: 1748102152.870s : Save duration: 0.788s\n",
      "[NeMo I 2025-05-24 15:56:00 nemo_logging:393] Scheduled async checkpoint save for /workspace/results/evo2/checkpoints/evo2--val_loss=1.4537-epoch=0-consumed_samples=100.0-last.ckpt\n",
      "[NeMo I 2025-05-24 15:56:00 nemo_logging:393] Async finalization time took 0.003 s\n",
      "Validation: iteration 1/20\n",
      "Validation: iteration 2/20\n",
      "Validation: iteration 3/20\n",
      "Validation: iteration 4/20\n",
      "Validation: iteration 5/20\n",
      "Validation: iteration 6/20\n",
      "Validation: iteration 7/20\n",
      "Validation: iteration 8/20\n",
      "Validation: iteration 9/20\n",
      "Validation: iteration 10/20\n",
      "Validation: iteration 11/20\n",
      "Validation: iteration 12/20\n",
      "Validation: iteration 13/20\n",
      "Validation: iteration 14/20\n",
      "Validation: iteration 15/20\n",
      "Validation: iteration 16/20\n",
      "Validation: iteration 17/20\n",
      "Validation: iteration 18/20\n",
      "Validation: iteration 19/20\n",
      "Validation: iteration 20/20\n",
      "[NeMo I 2025-05-24 15:56:55 nemo_logging:393] Successfully saved checkpoint from iteration      99 to /workspace/results/evo2/checkpoints/evo2--val_loss=1.4537-epoch=0-consumed_samples=100.0.ckpt\n",
      "[NeMo I 2025-05-24 15:56:55 nemo_logging:393] Async checkpoint save for step 100 (/workspace/results/evo2/checkpoints/evo2--val_loss=1.4537-epoch=0-consumed_samples=100.0.ckpt) finalized successfully.\n",
      "[NeMo I 2025-05-24 15:56:56 nemo_logging:393] Successfully saved checkpoint from iteration      99 to /workspace/results/evo2/checkpoints/evo2--val_loss=1.4537-epoch=0-consumed_samples=100.0-last.ckpt\n",
      "[NeMo I 2025-05-24 15:56:56 nemo_logging:393] Async checkpoint save for step 100 (/workspace/results/evo2/checkpoints/evo2--val_loss=1.4537-epoch=0-consumed_samples=100.0-last.ckpt) finalized successfully.\n",
      "[NeMo I 2025-05-24 15:56:56 nemo_logging:393] Async finalization time took 1.020 s\n",
      "`Trainer.fit` stopped: `max_steps=100` reached.\n"
     ]
    }
   ],
   "source": [
    "!train_evo2 \\\n",
    "    -d training_data_config.yaml \\\n",
    "    --dataset-dir {preprocessed_data} \\\n",
    "    --model-size 1b \\\n",
    "    --devices 1 \\\n",
    "    --num-nodes 1 \\\n",
    "    --seq-length 1 \\\n",
    "    --micro-batch-size 1 \\\n",
    "    --lr 0.0001 \\\n",
    "    --warmup-steps 5 \\\n",
    "    --max-steps 100 \\\n",
    "    --ckpt-dir nemo2_evo2_1b_8k \\\n",
    "    --clip-grad 1 \\\n",
    "    --wd 0.01 \\\n",
    "    --activation-checkpoint-recompute-num-layers 1 \\\n",
    "    --val-check-interval 50 \\\n",
    "    --ckpt-async-save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "eb824a00-ea7c-4ef2-8e0b-66e6189876c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mDEPRECATION: Loading egg at /usr/local/lib/python3.12/dist-packages/looseversion-1.3.0-py3.12.egg is deprecated. pip 25.1 will enforce this behaviour change. A possible replacement is to use pip for package installation. Discussion can be found at https://github.com/pypa/pip/issues/12330\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mDEPRECATION: Loading egg at /usr/local/lib/python3.12/dist-packages/lightning_utilities-0.12.0.dev0-py3.12.egg is deprecated. pip 25.1 will enforce this behaviour change. A possible replacement is to use pip for package installation. Discussion can be found at https://github.com/pypa/pip/issues/12330\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mDEPRECATION: Loading egg at /usr/local/lib/python3.12/dist-packages/dill-0.3.9-py3.12.egg is deprecated. pip 25.1 will enforce this behaviour change. A possible replacement is to use pip for package installation. Discussion can be found at https://github.com/pypa/pip/issues/12330\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mDEPRECATION: Loading egg at /usr/local/lib/python3.12/dist-packages/opt_einsum-3.4.0-py3.12.egg is deprecated. pip 25.1 will enforce this behaviour change. A possible replacement is to use pip for package installation. Discussion can be found at https://github.com/pypa/pip/issues/12330\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mDEPRECATION: Loading egg at /usr/local/lib/python3.12/dist-packages/nvfuser-0.2.23a0+6627725-py3.12-linux-x86_64.egg is deprecated. pip 25.1 will enforce this behaviour change. A possible replacement is to use pip for package installation. Discussion can be found at https://github.com/pypa/pip/issues/12330\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mDEPRECATION: Loading egg at /usr/local/lib/python3.12/dist-packages/lightning_thunder-0.2.0.dev0-py3.12.egg is deprecated. pip 25.1 will enforce this behaviour change. A possible replacement is to use pip for package installation. Discussion can be found at https://github.com/pypa/pip/issues/12330\u001b[0m\u001b[33m\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install -q peft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e4f1a484-0a58-4fe2-bb80-b344eeba271e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cp /workspace/bionemo_train.py /usr/local/lib/python3.12/dist-packages/bionemo/evo2/run/train.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7f72369-7e12-4796-a18c-3822b4598e03",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not find the bitsandbytes CUDA binary at PosixPath('/usr/local/lib/python3.12/dist-packages/bitsandbytes/libbitsandbytes_cuda129.so')\n",
      "The installed version of bitsandbytes was compiled without GPU support. 8-bit optimizers, 8-bit multiplication, and GPU quantization are unavailable.\n",
      "[NeMo I 2025-06-01 15:37:07 nemo_logging:393] Using byte-level tokenization\n",
      "[NeMo W 2025-06-01 15:37:07 nemo_logging:405] WandB is currently turned off.\n",
      "[NeMo W 2025-06-01 15:37:07 nemo_logging:405] User-set tensorboard is currently turned off. Internally one may still be set by NeMo2.\n",
      "Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "[NeMo I 2025-06-01 15:37:07 nemo_logging:393] Experiments will be logged at results/evo2/dev\n",
      "[NeMo W 2025-06-01 15:37:07 nemo_logging:405] There were no checkpoints found in checkpoint_dir or no checkpoint folder at checkpoint_dir :results/evo2/checkpoints. Training from scratch.\n",
      "[NeMo I 2025-06-01 15:37:07 nemo_logging:393] Fixing mis-match between ddp-config & mcore-optimizer config\n",
      "[NeMo I 2025-06-01 15:37:07 nemo_logging:393] Rank 0 has data parallel group : [0]\n",
      "[NeMo I 2025-06-01 15:37:07 nemo_logging:393] Rank 0 has combined group of data parallel and context parallel : [0]\n",
      "[NeMo I 2025-06-01 15:37:07 nemo_logging:393] All data parallel group ranks with context parallel combined: [[0]]\n",
      "[NeMo I 2025-06-01 15:37:07 nemo_logging:393] Ranks 0 has data parallel rank: 0\n",
      "[NeMo I 2025-06-01 15:37:07 nemo_logging:393] Rank 0 has context parallel group: [0]\n",
      "[NeMo I 2025-06-01 15:37:07 nemo_logging:393] All context parallel group ranks: [[0]]\n",
      "[NeMo I 2025-06-01 15:37:07 nemo_logging:393] Ranks 0 has context parallel rank: 0\n",
      "[NeMo I 2025-06-01 15:37:07 nemo_logging:393] Rank 0 has model parallel group: [0]\n",
      "[NeMo I 2025-06-01 15:37:07 nemo_logging:393] All model parallel group ranks: [[0]]\n",
      "[NeMo I 2025-06-01 15:37:07 nemo_logging:393] Rank 0 has tensor model parallel group: [0]\n",
      "[NeMo I 2025-06-01 15:37:07 nemo_logging:393] All tensor model parallel group ranks: [[0]]\n",
      "[NeMo I 2025-06-01 15:37:07 nemo_logging:393] Rank 0 has tensor model parallel rank: 0\n",
      "[NeMo I 2025-06-01 15:37:07 nemo_logging:393] Rank 0 has pipeline model parallel group: [0]\n",
      "[NeMo I 2025-06-01 15:37:07 nemo_logging:393] Rank 0 has embedding group: [0]\n",
      "[NeMo I 2025-06-01 15:37:07 nemo_logging:393] All pipeline model parallel group ranks: [[0]]\n",
      "[NeMo I 2025-06-01 15:37:07 nemo_logging:393] Rank 0 has pipeline model parallel rank 0\n",
      "[NeMo I 2025-06-01 15:37:07 nemo_logging:393] All embedding group ranks: [[0]]\n",
      "[NeMo I 2025-06-01 15:37:07 nemo_logging:393] Rank 0 has embedding rank: 0\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 1 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[NeMo I 2025-06-01 15:37:08 utils:554] Building Evo2Dataset splits with sizes=[300000, 6020, 1] and config=GPTDatasetConfig(random_seed=1234, sequence_length=1, blend=None, blend_per_split=[(['/workspace/preprocessed_data/XTT22_train_byte-level_train'], [1.0]), (['/workspace/preprocessed_data/XTT22_train_byte-level_val'], [1.0]), (['/workspace/preprocessed_data/XTT22_train_byte-level_test'], [1.0])], split=None, split_matrix=None, num_dataset_builder_threads=1, path_to_cache=None, mmap_bin_files=True, mock=False, tokenizer=<nemo.collections.common.tokenizers.bytelevel_tokenizers.ByteLevelTokenizer object at 0x77e4f623ba40>, mid_level_dataset_surplus=0.005, reset_position_ids=False, reset_attention_mask=False, eod_mask_loss=False, create_attention_mask=False, drop_last_partial_validation_sequence=True, add_extra_token_to_sequence=True, object_storage_cache_path=None)\n",
      "[NeMo I 2025-06-01 15:37:08 utils:554] Load the _IndexReader from /workspace/preprocessed_data/XTT22_train_byte-level_train.idx\n",
      "[NeMo I 2025-06-01 15:37:08 utils:554] \tExtract the sequence lengths\n",
      "[NeMo I 2025-06-01 15:37:08 utils:554] \tExtract the sequence pointers\n",
      "[NeMo I 2025-06-01 15:37:08 utils:554] \tExtract the document indices\n",
      "[NeMo I 2025-06-01 15:37:08 utils:554] > total number of sequences: 10896\n",
      "[NeMo I 2025-06-01 15:37:08 utils:554] > total number of documents: 10896\n",
      "[NeMo I 2025-06-01 15:37:08 utils:554] Build and save the Evo2Dataset train indices\n"
     ]
    }
   ],
   "source": [
    "\n",
    "!train_evo2 \\\n",
    "    -d training_data_config.yaml \\\n",
    "    --dataset-dir {preprocessed_data} \\\n",
    "    --model-size 1b \\\n",
    "    --devices 1 \\\n",
    "    --num-nodes 1 \\\n",
    "    --seq-length 1 \\\n",
    "    --micro-batch-size 1 \\\n",
    "    --lr 0.0001 \\\n",
    "    --warmup-steps 5 \\\n",
    "    --max-steps 300000 \\\n",
    "    --ckpt-dir nemo2_evo2_1b_8k \\\n",
    "    --clip-grad 1 \\\n",
    "    --wd 0.01 \\\n",
    "    --activation-checkpoint-recompute-num-layers 1 \\\n",
    "    --val-check-interval 1000 \\\n",
    "    --ckpt-async-save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ad8f9c7-55d5-4876-9a7b-ab7720eb8c85",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import stat\n",
    "\n",
    "# 检查文件路径\n",
    "file_path = \"/usr/local/bin/train_evo2\"\n",
    "\n",
    "# 首先检查文件是否存在\n",
    "if os.path.exists(file_path):\n",
    "    print(f\"文件存在: {file_path}\")\n",
    "    \n",
    "    # 获取文件信息\n",
    "    file_stat = os.stat(file_path)\n",
    "    print(f\"文件大小: {file_stat.st_size} 字节\")\n",
    "    print(f\"文件权限: {stat.filemode(file_stat.st_mode)}\")\n",
    "    print(f\"是否可执行: {os.access(file_path, os.X_OK)}\")\n",
    "    \n",
    "    # 检查文件类型\n",
    "    with open(file_path, 'rb') as f:\n",
    "        first_bytes = f.read(100)\n",
    "        print(f\"文件开头字节: {first_bytes[:50]}\")\n",
    "        \n",
    "        # 检查是否是文本文件\n",
    "        try:\n",
    "            first_text = first_bytes.decode('utf-8')\n",
    "            print(\"这是一个文本文件\")\n",
    "            print(f\"文件开头内容: {first_text[:100]}...\")\n",
    "        except UnicodeDecodeError:\n",
    "            print(\"这是一个二进制文件\")\n",
    "    \n",
    "    # 如果是Python脚本，显示基本信息（不显示完整内容）\n",
    "    if file_path.endswith('.py') or 'python' in first_text.lower():\n",
    "        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            lines = f.readlines()\n",
    "            print(f\"\\n总行数: {len(lines)}\")\n",
    "            print(\"文件头部信息（前5行）:\")\n",
    "            for i, line in enumerate(lines[:100]):\n",
    "                print(f\"{i+1}: {line.rstrip()}\")\n",
    "else:\n",
    "    print(f\"文件不存在: {file_path}\")\n",
    "    \n",
    "    # 检查可能的替代路径\n",
    "    possible_paths = [\n",
    "        \"/usr/local/bin/train_evo2\",\n",
    "        \"/usr/local/lib/python3.12/dist-packages/bionemo/evo2/run/train.py\",\n",
    "        \"/usr/local/lib/python3.12/dist-packages/bionemo/evo2/train.py\"\n",
    "    ]\n",
    "    \n",
    "    print(\"\\n检查其他可能的路径:\")\n",
    "    for path in possible_paths:\n",
    "        if os.path.exists(path):\n",
    "            print(f\"✓ 找到: {path}\")\n",
    "        else:\n",
    "            print(f\"✗ 不存在: {path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b51390c9-cb5e-4016-b79a-80effcc109da",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "打印 BioNeMo Evo2 训练脚本内容\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "def print_file_content():\n",
    "    \"\"\"打印指定文件的内容\"\"\"\n",
    "    \n",
    "    file_path = \"/usr/local/lib/python3.12/dist-packages/bionemo/evo2/run/train.py\"\n",
    "    \n",
    "    print(\"=\" * 80)\n",
    "    print(f\"文件路径: {file_path}\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    try:\n",
    "        # 检查文件是否存在\n",
    "        if not os.path.exists(file_path):\n",
    "            print(f\"❌ 文件不存在: {file_path}\")\n",
    "            \n",
    "            # 尝试查找类似的文件\n",
    "            print(\"\\n正在搜索相关文件...\")\n",
    "            base_dir = \"/usr/local/lib/python3.12/dist-packages/\"\n",
    "            \n",
    "            if os.path.exists(base_dir):\n",
    "                print(f\"✓ 基础目录存在: {base_dir}\")\n",
    "                \n",
    "                # 搜索 bionemo 相关目录\n",
    "                for root, dirs, files in os.walk(base_dir):\n",
    "                    if \"bionemo\" in root.lower():\n",
    "                        print(f\"找到相关目录: {root}\")\n",
    "                        if \"train.py\" in files:\n",
    "                            print(f\"  -> 包含 train.py: {os.path.join(root, 'train.py')}\")\n",
    "            else:\n",
    "                print(f\"❌ 基础目录不存在: {base_dir}\")\n",
    "            \n",
    "            return False\n",
    "        \n",
    "        # 读取并打印文件内容\n",
    "        print(f\"✓ 文件存在，正在读取内容...\\n\")\n",
    "        \n",
    "        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            content = f.read()\n",
    "        \n",
    "        # 打印文件信息\n",
    "        lines = content.split('\\n')\n",
    "        print(f\"文件大小: {len(content)} 字符\")\n",
    "        print(f\"行数: {len(lines)}\")\n",
    "        print(\"-\" * 80)\n",
    "        \n",
    "        # 打印内容（带行号）\n",
    "        for i, line in enumerate(lines, 1):\n",
    "            print(f\"{i:4d}: {line}\")\n",
    "        \n",
    "        print(\"-\" * 80)\n",
    "        print(\"✓ 文件内容已打印完成\")\n",
    "        return True\n",
    "        \n",
    "    except PermissionError:\n",
    "        print(f\"❌ 权限不足，无法读取文件: {file_path}\")\n",
    "        print(\"请尝试使用 sudo 运行此脚本\")\n",
    "        return False\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ 读取文件时发生错误: {e}\")\n",
    "        return False\n",
    "\n",
    "def search_alternative_paths():\n",
    "    \"\"\"搜索可能的替代路径\"\"\"\n",
    "    \n",
    "    potential_paths = [\n",
    "        \"/usr/local/lib/python3.12/dist-packages/bionemo/evo2/run/train.py\",\n",
    "        \"/usr/local/lib/python3.11/dist-packages/bionemo/evo2/run/train.py\",\n",
    "        \"/usr/lib/python3.12/dist-packages/bionemo/evo2/run/train.py\",\n",
    "        \"/usr/lib/python3.11/dist-packages/bionemo/evo2/run/train.py\",\n",
    "    ]\n",
    "    \n",
    "    # 也检查当前用户的site-packages\n",
    "    import site\n",
    "    user_site = site.getusersitepackages()\n",
    "    if user_site:\n",
    "        potential_paths.append(f\"{user_site}/bionemo/evo2/run/train.py\")\n",
    "    \n",
    "    print(\"\\n搜索可能的路径:\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    found_files = []\n",
    "    for path in potential_paths:\n",
    "        if os.path.exists(path):\n",
    "            print(f\"✓ 找到: {path}\")\n",
    "            found_files.append(path)\n",
    "        else:\n",
    "            print(f\"✗ 不存在: {path}\")\n",
    "    \n",
    "    return found_files\n",
    "\n",
    "def main():\n",
    "    \"\"\"主函数\"\"\"\n",
    "    print(\"BioNeMo Evo2 训练脚本内容查看器\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    # 首先尝试打印目标文件\n",
    "    success = print_file_content()\n",
    "    \n",
    "    if not success:\n",
    "        # 如果失败，搜索替代路径\n",
    "        found_files = search_alternative_paths()\n",
    "        \n",
    "        if found_files:\n",
    "            print(f\"\\n找到 {len(found_files)} 个相关文件。\")\n",
    "            for i, file_path in enumerate(found_files, 1):\n",
    "                print(f\"\\n{i}. 正在打印: {file_path}\")\n",
    "                print(\"=\" * 80)\n",
    "                \n",
    "                try:\n",
    "                    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "                        content = f.read()\n",
    "                    \n",
    "                    lines = content.split('\\n')\n",
    "                    print(f\"文件大小: {len(content)} 字符\")\n",
    "                    print(f\"行数: {len(lines)}\")\n",
    "                    print(\"-\" * 80)\n",
    "                    \n",
    "                    for line_num, line in enumerate(lines, 1):\n",
    "                        print(f\"{line_num:4d}: {line}\")\n",
    "                    \n",
    "                    print(\"-\" * 80)\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    print(f\"❌ 读取文件 {file_path} 时发生错误: {e}\")\n",
    "        else:\n",
    "            print(\"\\n❌ 未找到任何相关的训练脚本文件\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a20f4f4-8c19-44b7-94b5-db53eff61976",
   "metadata": {},
   "outputs": [],
   "source": [
    "!evo2_convert_to_nemo2 \\\n",
    "  --model-path /workspace/savanna_evo2_7b/savanna_evo2_7b.pt \\\n",
    "  --model-size 7b --output-dir nemo2_evo2_7b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "026ce977-d70f-40b8-90e3-8eba91cd315d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!train_evo2 \\\n",
    "    -d training_data_config.yaml \\\n",
    "    --dataset-dir {preprocessed_data} \\\n",
    "    --model-size 7b \\\n",
    "    --devices 4 \\\n",
    "    --num-nodes 1 \\\n",
    "    --seq-length 1 \\\n",
    "    --micro-batch-size 1 \\\n",
    "    --lr 0.0001 \\\n",
    "    --warmup-steps 5 \\\n",
    "    --max-steps 200000 \\\n",
    "    --ckpt-dir nemo2_evo2_7b \\\n",
    "    --clip-grad 1 \\\n",
    "    --wd 0.01 \\\n",
    "    --activation-checkpoint-recompute-num-layers 1 \\\n",
    "    --val-check-interval 1000 \\\n",
    "    --ckpt-async-save"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
