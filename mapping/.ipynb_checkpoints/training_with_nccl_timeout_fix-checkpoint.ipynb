{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "# Evo2 训练脚本 - NCCL超时问题解决方案\n",
        "\n",
        "此脚本解决了在数据集构建阶段发生的NCCL超时问题。主要策略包括：\n",
        "1. 增加NCCL和分布式通信超时时间\n",
        "2. 启用详细的调试日志\n",
        "3. 优化数据加载配置\n",
        "4. 添加进度监控\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "## 1. 替换训练脚本\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 备份原始训练脚本\n",
        "!cp /usr/local/lib/python3.12/dist-packages/bionemo/evo2/run/train.py /usr/local/lib/python3.12/dist-packages/bionemo/evo2/run/train.py.backup\n",
        "\n",
        "# 替换为修改后的训练脚本\n",
        "!cp /workspace/bionemo_train.py /usr/local/lib/python3.12/dist-packages/bionemo/evo2/run/train.py\n",
        "\n",
        "print(\"训练脚本已替换完成\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## 2. 设置环境变量解决NCCL超时问题\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "# NCCL超时设置 - 增加到2小时\n",
        "os.environ['NCCL_TIMEOUT'] = '7200'  # 2小时超时\n",
        "os.environ['NCCL_BLOCKING_WAIT'] = '1'  # 阻塞等待，避免竞争条件\n",
        "os.environ['NCCL_DEBUG'] = 'INFO'  # 启用详细调试信息\n",
        "\n",
        "# PyTorch分布式超时设置\n",
        "os.environ['TORCH_DISTRIBUTED_TIMEOUT'] = '7200'  # PyTorch分布式超时\n",
        "os.environ['TORCH_NCCL_TRACE_BUFFER_SIZE'] = '1024'  # 启用NCCL跟踪\n",
        "\n",
        "# 数据加载优化\n",
        "os.environ['NCCL_ASYNC_ERROR_HANDLING'] = '1'  # 异步错误处理\n",
        "os.environ['NCCL_BUFFSIZE'] = '8388608'  # 增加缓冲区大小\n",
        "os.environ['NCCL_NTHREADS'] = '8'  # 增加NCCL线程数\n",
        "\n",
        "# 避免内存碎片\n",
        "os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'max_split_size_mb:512'\n",
        "\n",
        "# 数据集准备相关设置\n",
        "os.environ['TOKENIZERS_PARALLELISM'] = 'false'  # 避免tokenizer并行冲突\n",
        "os.environ['OMP_NUM_THREADS'] = '4'  # 限制OpenMP线程数\n",
        "\n",
        "print(\"环境变量设置完成:\")\n",
        "for key in ['NCCL_TIMEOUT', 'TORCH_DISTRIBUTED_TIMEOUT', 'NCCL_DEBUG']:\n",
        "    print(f\"{key}: {os.environ.get(key)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## 3. 检查系统资源和GPU状态\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 检查GPU状态\n",
        "!nvidia-smi\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "\n",
        "# 检查内存使用\n",
        "!free -h\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "\n",
        "# 检查磁盘空间\n",
        "!df -h | head -10\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## 4. 设置训练参数\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 训练配置参数\n",
        "training_config = {\n",
        "    'data_config': 'training_data_config.yaml',\n",
        "    'dataset_dir': 'preprocessed_data',  # 需要根据实际路径修改\n",
        "    'model_size': '7b',\n",
        "    'devices': 2,\n",
        "    'num_nodes': 1,\n",
        "    'seq_length': 1,\n",
        "    'micro_batch_size': 1,\n",
        "    'lr': 0.0001,\n",
        "    'warmup_steps': 5,\n",
        "    'max_steps': 200000,\n",
        "    'ckpt_dir': 'nemo2_evo2_7b',\n",
        "    'clip_grad': 1,\n",
        "    'wd': 0.01,\n",
        "    'activation_checkpoint_recompute_num_layers': 1,\n",
        "    'val_check_interval': 1000,\n",
        "    'ckpt_async_save': True\n",
        "}\n",
        "\n",
        "print(\"训练配置:\")\n",
        "for key, value in training_config.items():\n",
        "    print(f\"{key}: {value}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## 5. 启动训练（带超时监控）\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import subprocess\n",
        "import time\n",
        "from datetime import datetime\n",
        "\n",
        "def run_training_with_monitoring():\n",
        "    # 构建训练命令\n",
        "    cmd = f\"\"\"\n",
        "    train_evo2 \\\\\n",
        "        -d {training_config['data_config']} \\\\\n",
        "        --dataset-dir {training_config['dataset_dir']} \\\\\n",
        "        --model-size {training_config['model_size']} \\\\\n",
        "        --devices {training_config['devices']} \\\\\n",
        "        --num-nodes {training_config['num_nodes']} \\\\\n",
        "        --seq-length {training_config['seq_length']} \\\\\n",
        "        --micro-batch-size {training_config['micro_batch_size']} \\\\\n",
        "        --lr {training_config['lr']} \\\\\n",
        "        --warmup-steps {training_config['warmup_steps']} \\\\\n",
        "        --max-steps {training_config['max_steps']} \\\\\n",
        "        --ckpt-dir {training_config['ckpt_dir']} \\\\\n",
        "        --clip-grad {training_config['clip_grad']} \\\\\n",
        "        --wd {training_config['wd']} \\\\\n",
        "        --activation-checkpoint-recompute-num-layers {training_config['activation_checkpoint_recompute_num_layers']} \\\\\n",
        "        --val-check-interval {training_config['val_check_interval']} \\\\\n",
        "        --ckpt-async-save\n",
        "    \"\"\".strip().replace('\\n', ' ').replace('  ', ' ')\n",
        "    \n",
        "    print(f\"开始训练时间: {datetime.now()}\")\n",
        "    print(f\"训练命令: {cmd}\")\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    \n",
        "    try:\n",
        "        # 启动训练进程\n",
        "        process = subprocess.Popen(\n",
        "            cmd,\n",
        "            shell=True,\n",
        "            stdout=subprocess.PIPE,\n",
        "            stderr=subprocess.STDOUT,\n",
        "            universal_newlines=True,\n",
        "            bufsize=1\n",
        "        )\n",
        "        \n",
        "        # 实时监控输出\n",
        "        start_time = time.time()\n",
        "        last_output_time = start_time\n",
        "        \n",
        "        for line in iter(process.stdout.readline, ''):\n",
        "            current_time = time.time()\n",
        "            elapsed = current_time - start_time\n",
        "            \n",
        "            # 打印带时间戳的输出\n",
        "            print(f\"[{elapsed:.1f}s] {line.rstrip()}\")\n",
        "            \n",
        "            # 检查关键信息\n",
        "            if any(keyword in line.lower() for keyword in ['dataset', 'preparing', 'loading', 'barrier']):\n",
        "                print(f\"*** 数据集准备阶段: {line.rstrip()} ***\")\n",
        "                last_output_time = current_time\n",
        "            \n",
        "            # 如果太长时间没有输出，给出提示\n",
        "            if current_time - last_output_time > 300:  # 5分钟无输出\n",
        "                print(f\"\\n[警告] 已有 {(current_time - last_output_time):.1f} 秒无输出，可能在准备数据集...\")\n",
        "                last_output_time = current_time\n",
        "        \n",
        "        # 等待进程完成\n",
        "        return_code = process.wait()\n",
        "        \n",
        "        if return_code == 0:\n",
        "            print(f\"\\n训练成功完成! 总耗时: {time.time() - start_time:.1f} 秒\")\n",
        "        else:\n",
        "            print(f\"\\n训练失败，返回码: {return_code}\")\n",
        "            \n",
        "    except KeyboardInterrupt:\n",
        "        print(\"\\n用户中断训练\")\n",
        "        process.terminate()\n",
        "    except Exception as e:\n",
        "        print(f\"\\n训练出错: {e}\")\n",
        "\n",
        "# 启动训练\n",
        "run_training_with_monitoring()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## 6. 替代方案：分步骤训练（如果仍有超时问题）\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 如果上面的方法仍然超时，可以尝试分步骤方法\n",
        "\n",
        "def run_training_with_dataset_warmup():\n",
        "    \"\"\"先预热数据集，再开始正式训练\"\"\"\n",
        "    \n",
        "    print(\"步骤1: 数据集预热（单进程）\")\n",
        "    warmup_cmd = f\"\"\"\n",
        "    train_evo2 \\\\\n",
        "        -d {training_config['data_config']} \\\\\n",
        "        --dataset-dir {training_config['dataset_dir']} \\\\\n",
        "        --model-size {training_config['model_size']} \\\\\n",
        "        --devices 1 \\\\\n",
        "        --num-nodes 1 \\\\\n",
        "        --seq-length {training_config['seq_length']} \\\\\n",
        "        --micro-batch-size 1 \\\\\n",
        "        --max-steps 1 \\\\\n",
        "        --ckpt-dir warmup_ckpt\n",
        "    \"\"\".strip().replace('\\n', ' ').replace('  ', ' ')\n",
        "    \n",
        "    print(f\"预热命令: {warmup_cmd}\")\n",
        "    \n",
        "    # 执行预热\n",
        "    result = subprocess.run(warmup_cmd, shell=True, capture_output=True, text=True)\n",
        "    \n",
        "    if result.returncode == 0:\n",
        "        print(\"数据集预热成功！\")\n",
        "        \n",
        "        print(\"\\n步骤2: 开始正式多GPU训练\")\n",
        "        # 现在运行正常的多GPU训练\n",
        "        run_training_with_monitoring()\n",
        "    else:\n",
        "        print(f\"数据集预热失败: {result.stderr}\")\n",
        "\n",
        "# 取消注释下面的行来使用分步骤方法\n",
        "# run_training_with_dataset_warmup()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## 7. 故障排除和日志分析\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 检查NCCL相关进程\n",
        "!ps aux | grep -E '(train_evo2|python.*train)' | grep -v grep\n",
        "\n",
        "print(\"\\n检查NCCL环境变量:\")\n",
        "!env | grep NCCL\n",
        "\n",
        "print(\"\\n检查PyTorch版本和CUDA:\")\n",
        "import torch\n",
        "print(f\"PyTorch版本: {torch.__version__}\")\n",
        "print(f\"CUDA可用: {torch.cuda.is_available()}\")\n",
        "print(f\"CUDA设备数: {torch.cuda.device_count()}\")\n",
        "if torch.cuda.is_available():\n",
        "    for i in range(torch.cuda.device_count()):\n",
        "        print(f\"GPU {i}: {torch.cuda.get_device_name(i)}\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
