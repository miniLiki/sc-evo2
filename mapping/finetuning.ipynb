{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1f816cb-6abb-4cf9-9a0b-d1382a4c9910",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "concat_path = \"XTT22_train.fa\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e5a015b5-fad5-4d11-adcd-2fb18c594536",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_fasta_path = os.path.abspath(concat_path)\n",
    "output_dir = os.path.abspath(\"preprocessed_data\")\n",
    "output_yaml = f\"\"\"\n",
    "- datapaths: [\"{full_fasta_path}\"]\n",
    "  output_dir: \"{output_dir}\"\n",
    "  output_prefix: XTT22_train\n",
    "  train_split: 0.9\n",
    "  valid_split: 0.05\n",
    "  test_split: 0.05\n",
    "  overwrite: True\n",
    "  embed_reverse_complement: true\n",
    "  random_reverse_complement: 0.0\n",
    "  random_lineage_dropout: 0.0\n",
    "  include_sequence_id: false\n",
    "  transcribe: \"back_transcribe\"\n",
    "  force_uppercase: false\n",
    "  indexed_dataset_dtype: \"uint8\"\n",
    "  tokenizer_type: \"Byte-Level\"\n",
    "  vocab_file: null\n",
    "  vocab_size: null\n",
    "  merges_file: null\n",
    "  pretrained_tokenizer_model: null\n",
    "  special_tokens: null\n",
    "  fast_hf_tokenizer: true\n",
    "  append_eod: true\n",
    "  enforce_sample_length: null\n",
    "  ftfy: false\n",
    "  workers: 1\n",
    "  preproc_concurrency: 100000\n",
    "  chunksize: 25\n",
    "  drop_empty_sequences: true\n",
    "  nnn_filter: false  # If you split your fasta on NNN (in human these are contigs), then you should set this to true.\n",
    "  seed: 12342  # Not relevant because we are not using random reverse complement or lineage dropout.\n",
    "\"\"\"\n",
    "with open(\"preprocess_config.yaml\", \"w\") as f:\n",
    "    print(output_yaml, file=f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aadbf5cb-03b5-4a20-96e5-7bb0a7e5b942",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2025-05-24 12:37:06 nemo_logging:393] Using byte-level tokenization\n",
      "[NeMo I 2025-05-24 12:37:06 nemo_logging:393] Created temporary binary datasets: /workspace/preprocessed_data/XTT22_train_byte-level_train.bin.tmp /workspace/preprocessed_data/XTT22_train_byte-level_val.bin.tmp /workspace/preprocessed_data/XTT22_train_byte-level_test.bin.tmp\n",
      "[NeMo I 2025-05-24 13:12:11 nemo_logging:393] Average preprocessing time per sequence: 0.04470627161196968\n",
      "[NeMo I 2025-05-24 13:12:11 nemo_logging:393] Average indexing time per sequence: 0.1463382052460373\n",
      "[NeMo I 2025-05-24 13:12:11 nemo_logging:393] Number of sequences processed: 12092\n",
      "[NeMo I 2025-05-24 13:12:11 nemo_logging:393] Finished preprocessing XTT22_train ([PosixPath('/workspace/XTT22_train.fa')]) in 2105.082 seconds with 1 workers.\n"
     ]
    }
   ],
   "source": [
    "!preprocess_evo2 --config preprocess_config.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3df5d34a-d5fe-4fa9-ac3d-65b9696a9045",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 14G\n",
      "-rw-r--r-- 1 root root 936M May 24 13:11 XTT22_train_byte-level_test.bin\n",
      "-rw-r--r-- 1 root root  12K May 24 13:12 XTT22_train_byte-level_test.idx\n",
      "-rw-r--r-- 1 root root  13G May 24 13:12 XTT22_train_byte-level_train.bin\n",
      "-rw-r--r-- 1 root root 213K May 24 13:12 XTT22_train_byte-level_train.idx\n",
      "-rw-r--r-- 1 root root 411M May 24 13:12 XTT22_train_byte-level_val.bin\n",
      "-rw-r--r-- 1 root root  12K May 24 13:12 XTT22_train_byte-level_val.idx\n"
     ]
    }
   ],
   "source": [
    "!ls -lh preprocessed_data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "240cf8a0-258b-424c-9e2a-55999a0c8a5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not find the bitsandbytes CUDA binary at PosixPath('/usr/local/lib/python3.12/dist-packages/bitsandbytes/libbitsandbytes_cuda129.so')\n",
      "The installed version of bitsandbytes was compiled without GPU support. 8-bit optimizers, 8-bit multiplication, and GPU quantization are unavailable.\n",
      "[NeMo I 2025-05-24 15:02:39 nemo_logging:393] Using byte-level tokenization\n",
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "[NeMo W 2025-05-24 15:02:39 nemo_logging:405] /usr/local/lib/python3.12/dist-packages/lightning/pytorch/trainer/setup.py:177: GPU available but not used. You can set it by doing `Trainer(accelerator='gpu')`.\n",
      "    \n",
      "[NeMo I 2025-05-24 15:02:39 nemo_logging:393] Fixing mis-match between ddp-config & mcore-optimizer config\n",
      "[NeMo I 2025-05-24 15:02:39 nemo_logging:393] Rank 0 has data parallel group : [0]\n",
      "[NeMo I 2025-05-24 15:02:39 nemo_logging:393] Rank 0 has combined group of data parallel and context parallel : [0]\n",
      "[NeMo I 2025-05-24 15:02:39 nemo_logging:393] All data parallel group ranks with context parallel combined: [[0]]\n",
      "[NeMo I 2025-05-24 15:02:39 nemo_logging:393] Ranks 0 has data parallel rank: 0\n",
      "[NeMo I 2025-05-24 15:02:39 nemo_logging:393] Rank 0 has context parallel group: [0]\n",
      "[NeMo I 2025-05-24 15:02:39 nemo_logging:393] All context parallel group ranks: [[0]]\n",
      "[NeMo I 2025-05-24 15:02:39 nemo_logging:393] Ranks 0 has context parallel rank: 0\n",
      "[NeMo I 2025-05-24 15:02:39 nemo_logging:393] Rank 0 has model parallel group: [0]\n",
      "[NeMo I 2025-05-24 15:02:39 nemo_logging:393] All model parallel group ranks: [[0]]\n",
      "[NeMo I 2025-05-24 15:02:39 nemo_logging:393] Rank 0 has tensor model parallel group: [0]\n",
      "[NeMo I 2025-05-24 15:02:39 nemo_logging:393] All tensor model parallel group ranks: [[0]]\n",
      "[NeMo I 2025-05-24 15:02:39 nemo_logging:393] Rank 0 has tensor model parallel rank: 0\n",
      "[NeMo I 2025-05-24 15:02:39 nemo_logging:393] Rank 0 has pipeline model parallel group: [0]\n",
      "[NeMo I 2025-05-24 15:02:39 nemo_logging:393] Rank 0 has embedding group: [0]\n",
      "[NeMo I 2025-05-24 15:02:39 nemo_logging:393] All pipeline model parallel group ranks: [[0]]\n",
      "[NeMo I 2025-05-24 15:02:39 nemo_logging:393] Rank 0 has pipeline model parallel rank 0\n",
      "[NeMo I 2025-05-24 15:02:39 nemo_logging:393] All embedding group ranks: [[0]]\n",
      "[NeMo I 2025-05-24 15:02:39 nemo_logging:393] Rank 0 has embedding rank: 0\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=gloo\n",
      "All distributed processes registered. Starting with 1 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[NeMo W 2025-05-24 15:02:39 nemo_logging:405] /usr/local/lib/python3.12/dist-packages/lightning/pytorch/trainer/trainer.py:1090: `trainer.init_module` cannot fully support proper instantiation of your model with the `MegatronStrategy` strategy. Please instantiate your model inside the`LightningModule.configure_model` hook instead\n",
      "    \n",
      "[NeMo I 2025-05-24 15:02:39 nemo_logging:393] Padded vocab_size: 512, original vocab_size: 512, dummy tokens: 0.\n",
      "CPU RNG state changed within GPU RNG context\n",
      "CPU RNG state changed within GPU RNG context\n",
      "CPU RNG state changed within GPU RNG context\n",
      "CPU RNG state changed within GPU RNG context\n",
      "CPU RNG state changed within GPU RNG context\n",
      "CPU RNG state changed within GPU RNG context\n",
      "CPU RNG state changed within GPU RNG context\n",
      "CPU RNG state changed within GPU RNG context\n",
      "CPU RNG state changed within GPU RNG context\n",
      "CPU RNG state changed within GPU RNG context\n",
      "CPU RNG state changed within GPU RNG context\n",
      "CPU RNG state changed within GPU RNG context\n",
      "CPU RNG state changed within GPU RNG context\n",
      "CPU RNG state changed within GPU RNG context\n",
      "[NeMo W 2025-05-24 15:02:43 nemo_logging:405] Could not copy Trainer's 'max_steps' to LR scheduler's 'max_steps'. If you are not using an LR scheduler, this warning can safely be ignored.\n",
      "[NeMo I 2025-05-24 15:02:43 nemo_logging:393] Using FullyParallelSaveStrategyWrapper(torch_dist, 1) dist-ckpt save strategy.\n",
      "[NeMo I 2025-05-24 15:02:48 nemo_logging:393] Global Checkpoint Save : Rank: 0 : Iteration: 0 : Start time: 1748098963.720s : Save duration: 4.825s\n",
      "[NeMo I 2025-05-24 15:02:48 nemo_logging:393] Converted Hyena model to Nemo, model saved to nemo2_evo2_1b_8k\n"
     ]
    }
   ],
   "source": [
    "!evo2_convert_to_nemo2 \\\n",
    "  --model-path /workspace/savanna_evo2_1b_base/savanna_evo2_1b_base.pt \\\n",
    "  --model-size 1b --output-dir nemo2_evo2_1b_8k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "56a10c51-4574-45a0-b1bc-94581798171b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "output_pfx = str(Path(os.path.abspath(\"preprocessed_data\"))/\"XTT22_train_byte-level\")\n",
    "output_yaml = f\"\"\"\n",
    "- dataset_prefix: {output_pfx}_train\n",
    "  dataset_split: train\n",
    "  dataset_weight: 1.0\n",
    "- dataset_prefix: {output_pfx}_val\n",
    "  dataset_split: validation\n",
    "  dataset_weight: 1.0\n",
    "- dataset_prefix: {output_pfx}_test\n",
    "  dataset_split: test\n",
    "  dataset_weight: 1.0\n",
    "\"\"\"\n",
    "with open(\"training_data_config.yaml\", \"w\") as f:\n",
    "    print(output_yaml, file=f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dff9f392-359a-4463-b435-54beadb4ea67",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not find the bitsandbytes CUDA binary at PosixPath('/usr/local/lib/python3.12/dist-packages/bitsandbytes/libbitsandbytes_cuda129.so')\n",
      "The installed version of bitsandbytes was compiled without GPU support. 8-bit optimizers, 8-bit multiplication, and GPU quantization are unavailable.\n",
      "[NeMo I 2025-05-24 15:03:17 nemo_logging:393] Using byte-level tokenization\n",
      "[NeMo W 2025-05-24 15:03:17 nemo_logging:405] WandB is currently turned off.\n",
      "[NeMo W 2025-05-24 15:03:17 nemo_logging:405] User-set tensorboard is currently turned off. Internally one may still be set by NeMo2.\n",
      "Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "[NeMo I 2025-05-24 15:03:17 nemo_logging:393] Experiments will be logged at results/evo2/dev\n",
      "[NeMo W 2025-05-24 15:03:17 nemo_logging:405] There were no checkpoints found in checkpoint_dir or no checkpoint folder at checkpoint_dir :results/evo2/checkpoints. Training from scratch.\n",
      "[NeMo I 2025-05-24 15:03:17 nemo_logging:393] Fixing mis-match between ddp-config & mcore-optimizer config\n",
      "[NeMo I 2025-05-24 15:03:17 nemo_logging:393] Rank 0 has data parallel group : [0]\n",
      "[NeMo I 2025-05-24 15:03:17 nemo_logging:393] Rank 0 has combined group of data parallel and context parallel : [0]\n",
      "[NeMo I 2025-05-24 15:03:17 nemo_logging:393] All data parallel group ranks with context parallel combined: [[0]]\n",
      "[NeMo I 2025-05-24 15:03:17 nemo_logging:393] Ranks 0 has data parallel rank: 0\n",
      "[NeMo I 2025-05-24 15:03:17 nemo_logging:393] Rank 0 has context parallel group: [0]\n",
      "[NeMo I 2025-05-24 15:03:17 nemo_logging:393] All context parallel group ranks: [[0]]\n",
      "[NeMo I 2025-05-24 15:03:17 nemo_logging:393] Ranks 0 has context parallel rank: 0\n",
      "[NeMo I 2025-05-24 15:03:17 nemo_logging:393] Rank 0 has model parallel group: [0]\n",
      "[NeMo I 2025-05-24 15:03:17 nemo_logging:393] All model parallel group ranks: [[0]]\n",
      "[NeMo I 2025-05-24 15:03:17 nemo_logging:393] Rank 0 has tensor model parallel group: [0]\n",
      "[NeMo I 2025-05-24 15:03:17 nemo_logging:393] All tensor model parallel group ranks: [[0]]\n",
      "[NeMo I 2025-05-24 15:03:17 nemo_logging:393] Rank 0 has tensor model parallel rank: 0\n",
      "[NeMo I 2025-05-24 15:03:17 nemo_logging:393] Rank 0 has pipeline model parallel group: [0]\n",
      "[NeMo I 2025-05-24 15:03:17 nemo_logging:393] Rank 0 has embedding group: [0]\n",
      "[NeMo I 2025-05-24 15:03:17 nemo_logging:393] All pipeline model parallel group ranks: [[0]]\n",
      "[NeMo I 2025-05-24 15:03:17 nemo_logging:393] Rank 0 has pipeline model parallel rank 0\n",
      "[NeMo I 2025-05-24 15:03:17 nemo_logging:393] All embedding group ranks: [[0]]\n",
      "[NeMo I 2025-05-24 15:03:17 nemo_logging:393] Rank 0 has embedding rank: 0\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 1 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[NeMo I 2025-05-24 15:03:18 utils:554] Building Evo2Dataset splits with sizes=[100, 60, 1] and config=GPTDatasetConfig(random_seed=1234, sequence_length=1, blend=None, blend_per_split=[(['/workspace/preprocessed_data/XTT22_train_byte-level_train'], [1.0]), (['/workspace/preprocessed_data/XTT22_train_byte-level_val'], [1.0]), (['/workspace/preprocessed_data/XTT22_train_byte-level_test'], [1.0])], split=None, split_matrix=None, num_dataset_builder_threads=1, path_to_cache=None, mmap_bin_files=True, mock=False, tokenizer=<nemo.collections.common.tokenizers.bytelevel_tokenizers.ByteLevelTokenizer object at 0x76022cea3a10>, mid_level_dataset_surplus=0.005, reset_position_ids=False, reset_attention_mask=False, eod_mask_loss=False, create_attention_mask=False, drop_last_partial_validation_sequence=True, add_extra_token_to_sequence=True, object_storage_cache_path=None)\n",
      "[NeMo I 2025-05-24 15:03:18 utils:554] Load the _IndexReader from /workspace/preprocessed_data/XTT22_train_byte-level_train.idx\n",
      "[NeMo I 2025-05-24 15:03:18 utils:554] \tExtract the sequence lengths\n",
      "[NeMo I 2025-05-24 15:03:18 utils:554] \tExtract the sequence pointers\n",
      "[NeMo I 2025-05-24 15:03:18 utils:554] \tExtract the document indices\n",
      "[NeMo I 2025-05-24 15:03:18 utils:554] > total number of sequences: 10896\n",
      "[NeMo I 2025-05-24 15:03:18 utils:554] > total number of documents: 10896\n",
      "[NeMo I 2025-05-24 15:03:18 utils:554] Build and save the Evo2Dataset train indices\n",
      "[NeMo I 2025-05-24 15:50:25 utils:554] > total number of samples: 13441714549\n",
      "[NeMo I 2025-05-24 15:50:25 utils:554] > total number of epochs: 1\n",
      "[NeMo I 2025-05-24 15:50:25 utils:554] Load the _IndexReader from /workspace/preprocessed_data/XTT22_train_byte-level_val.idx\n",
      "[NeMo I 2025-05-24 15:50:25 utils:554] \tExtract the sequence lengths\n",
      "[NeMo I 2025-05-24 15:50:25 utils:554] \tExtract the sequence pointers\n",
      "[NeMo I 2025-05-24 15:50:25 utils:554] \tExtract the document indices\n",
      "[NeMo I 2025-05-24 15:50:25 utils:554] > total number of sequences: 590\n",
      "[NeMo I 2025-05-24 15:50:25 utils:554] > total number of documents: 590\n",
      "[NeMo I 2025-05-24 15:50:25 utils:554] Build and save the Evo2Dataset valid indices\n",
      "[NeMo I 2025-05-24 15:51:08 utils:554] > total number of samples: 430752259\n",
      "[NeMo I 2025-05-24 15:51:08 utils:554] > total number of epochs: 1\n",
      "[NeMo I 2025-05-24 15:51:08 utils:554] Load the _IndexReader from /workspace/preprocessed_data/XTT22_train_byte-level_test.idx\n",
      "[NeMo I 2025-05-24 15:51:08 utils:554] \tExtract the sequence lengths\n",
      "[NeMo I 2025-05-24 15:51:08 utils:554] \tExtract the sequence pointers\n",
      "[NeMo I 2025-05-24 15:51:08 utils:554] \tExtract the document indices\n",
      "[NeMo I 2025-05-24 15:51:08 utils:554] > total number of sequences: 606\n",
      "[NeMo I 2025-05-24 15:51:08 utils:554] > total number of documents: 606\n",
      "[NeMo I 2025-05-24 15:51:08 utils:554] Build and save the Evo2Dataset test indices\n",
      "[NeMo I 2025-05-24 15:52:44 utils:554] > total number of samples: 981405895\n",
      "[NeMo I 2025-05-24 15:52:44 utils:554] > total number of epochs: 1\n",
      "[NeMo I 2025-05-24 15:52:45 nemo_logging:393] Padded vocab_size: 512, original vocab_size: 512, dummy tokens: 0.\n",
      "[NeMo W 2025-05-24 15:52:45 random:222] CPU RNG state changed within GPU RNG context\n",
      "[NeMo W 2025-05-24 15:52:45 random:222] CPU RNG state changed within GPU RNG context\n",
      "[NeMo W 2025-05-24 15:52:45 random:222] CPU RNG state changed within GPU RNG context\n",
      "[NeMo W 2025-05-24 15:52:45 random:222] CPU RNG state changed within GPU RNG context\n",
      "[NeMo W 2025-05-24 15:52:45 random:222] CPU RNG state changed within GPU RNG context\n",
      "[NeMo W 2025-05-24 15:52:45 random:222] CPU RNG state changed within GPU RNG context\n",
      "[NeMo W 2025-05-24 15:52:45 random:222] CPU RNG state changed within GPU RNG context\n",
      "[NeMo W 2025-05-24 15:52:45 random:222] CPU RNG state changed within GPU RNG context\n",
      "[NeMo W 2025-05-24 15:52:45 random:222] CPU RNG state changed within GPU RNG context\n",
      "[NeMo W 2025-05-24 15:52:45 random:222] CPU RNG state changed within GPU RNG context\n",
      "[NeMo W 2025-05-24 15:52:45 random:222] CPU RNG state changed within GPU RNG context\n",
      "[NeMo W 2025-05-24 15:52:45 random:222] CPU RNG state changed within GPU RNG context\n",
      "[NeMo W 2025-05-24 15:52:45 random:222] CPU RNG state changed within GPU RNG context\n",
      "[NeMo W 2025-05-24 15:52:45 random:222] CPU RNG state changed within GPU RNG context\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "[NeMo I 2025-05-24 15:52:45 nemo_logging:393] Copying Trainer's 'max_steps' (100) to LR scheduler's 'max_steps'.\n",
      "[NeMo I 2025-05-24 15:52:45 num_microbatches_calculator:228] setting number of microbatches to constant 1\n",
      "[NeMo I 2025-05-24 15:52:45 nemo_logging:393]  > number of parameters on (tensor, pipeline) model parallel rank (0 ,0): 1108204800\n",
      "[NeMo I 2025-05-24 15:52:45 utils:554] Setting up DistributedDataParallel with config DistributedDataParallelConfig(grad_reduce_in_fp32=False, overlap_grad_reduce=False, overlap_param_gather=False, align_param_gather=False, use_distributed_optimizer=True, num_distributed_optimizer_instances=1, check_for_nan_in_grad=True, check_for_large_grads=False, bucket_size=None, pad_buckets_for_high_nccl_busbw=False, average_in_collective=True, fp8_param_gather=False, use_custom_fsdp=False, data_parallel_sharding_strategy='no_shard', gradient_reduce_div_fusion=True, suggested_communication_unit_size=None, preserve_fp32_weights=True, keep_fp8_transpose_cache_when_using_custom_fsdp=False)\n",
      "[NeMo I 2025-05-24 15:52:45 utils:575] Number of buckets for gradient all-reduce / reduce-scatter: 1\n",
      "    Params for bucket 1 (1108204800 elements, 1108204800 padded size):\n",
      "    \tmodule.decoder.layers.22.mixer.dense_projection.layer_norm_weight\n",
      "    \tmodule.decoder.layers.19.mixer.dense.bias\n",
      "    \tmodule.decoder.layers.18.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.14.mixer.dense_projection.layer_norm_weight\n",
      "    \tmodule.decoder.layers.11.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.7.mixer.dense_projection.layer_norm_weight\n",
      "    \tmodule.decoder.layers.3.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.22.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.12.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.5.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.2.mixer.mixer.filter.p\n",
      "    \tmodule.decoder.layers.0.mixer.dense.weight\n",
      "    \tmodule.embedding.word_embeddings.weight\n",
      "    \tmodule.decoder.layers.23.mixer.dense.weight\n",
      "    \tmodule.decoder.layers.18.mixer.dense.weight\n",
      "    \tmodule.decoder.layers.16.mixer.dense_projection.layer_norm_weight\n",
      "    \tmodule.decoder.layers.15.mixer.mixer.conv_bias\n",
      "    \tmodule.decoder.layers.11.mixer.dense.weight\n",
      "    \tmodule.decoder.layers.9.mixer.dense_projection.layer_norm_weight\n",
      "    \tmodule.decoder.layers.8.mixer.mixer.conv_bias\n",
      "    \tmodule.decoder.layers.5.mixer.mixer.filter.h\n",
      "    \tmodule.decoder.layers.24.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.16.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.9.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.2.mixer.hyena_proj_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.17.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.21.mixer.dense_projection.layer_norm_weight\n",
      "    \tmodule.decoder.layers.18.mixer.dense.bias\n",
      "    \tmodule.decoder.layers.13.mixer.mixer.filter.R\n",
      "    \tmodule.decoder.layers.11.mixer.dense.bias\n",
      "    \tmodule.decoder.layers.10.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.6.mixer.mixer.filter.R\n",
      "    \tmodule.decoder.layers.2.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.0.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.19.mixer.dense_projection.layer_norm_weight\n",
      "    \tmodule.decoder.layers.14.mixer.mixer.short_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.12.mixer.dense_projection.layer_norm_weight\n",
      "    \tmodule.decoder.layers.7.mixer.mixer.short_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.4.mixer.dense_projection.layer_norm_weight\n",
      "    \tmodule.decoder.layers.2.mixer.mixer.conv_bias\n",
      "    \tmodule.decoder.layers.23.mixer.dense_projection.layer_norm_weight\n",
      "    \tmodule.decoder.layers.22.mixer.dense.bias\n",
      "    \tmodule.decoder.layers.19.mixer.mixer.conv_bias\n",
      "    \tmodule.decoder.layers.15.mixer.hyena_proj_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.12.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.12.mixer.dense.bias\n",
      "    \tmodule.decoder.layers.8.mixer.hyena_proj_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.5.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.2.mixer.dense.bias\n",
      "    \tmodule.decoder.layers.0.mixer.mixer.short_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.23.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.16.mixer.mixer.filter.gamma\n",
      "    \tmodule.decoder.layers.13.mixer.dense.weight\n",
      "    \tmodule.decoder.layers.10.self_attention.linear_proj.bias\n",
      "    \tmodule.decoder.layers.9.mixer.mixer.filter.gamma\n",
      "    \tmodule.decoder.layers.6.mixer.dense.weight\n",
      "    \tmodule.decoder.final_norm.weight\n",
      "    \tmodule.decoder.layers.24.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.20.mixer.mixer.filter.R\n",
      "    \tmodule.decoder.layers.17.self_attention.linear_proj.weight\n",
      "    \tmodule.decoder.layers.15.mixer.mixer.filter.h\n",
      "    \tmodule.decoder.layers.10.self_attention.linear_proj.weight\n",
      "    \tmodule.decoder.layers.8.mixer.mixer.filter.h\n",
      "    \tmodule.decoder.layers.5.mixer.dense.bias\n",
      "    \tmodule.decoder.layers.4.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.2.mixer.dense_projection.weight\n",
      "    \tmodule.decoder.layers.0.mixer.hyena_proj_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.21.mixer.mixer.short_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.18.mixer.dense_projection.layer_norm_weight\n",
      "    \tmodule.decoder.layers.15.mixer.dense.bias\n",
      "    \tmodule.decoder.layers.15.mixer.dense.weight\n",
      "    \tmodule.decoder.layers.11.mixer.dense_projection.layer_norm_weight\n",
      "    \tmodule.decoder.layers.8.mixer.dense.bias\n",
      "    \tmodule.decoder.layers.8.mixer.dense.weight\n",
      "    \tmodule.decoder.layers.2.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.1.mixer.dense_projection.layer_norm_weight\n",
      "    \tmodule.decoder.layers.22.mixer.hyena_proj_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.20.mixer.mixer.conv_bias\n",
      "    \tmodule.decoder.layers.16.mixer.mixer.filter.p\n",
      "    \tmodule.decoder.layers.14.mixer.hyena_proj_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.9.mixer.mixer.filter.p\n",
      "    \tmodule.decoder.layers.7.mixer.hyena_proj_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.5.mixer.dense_projection.layer_norm_weight\n",
      "    \tmodule.decoder.layers.4.mixer.mixer.short_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.1.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.23.mixer.mixer.filter.gamma\n",
      "    \tmodule.decoder.layers.20.mixer.dense.weight\n",
      "    \tmodule.decoder.layers.15.mixer.dense_projection.weight\n",
      "    \tmodule.decoder.layers.13.mixer.dense_projection.layer_norm_weight\n",
      "    \tmodule.decoder.layers.8.mixer.dense_projection.weight\n",
      "    \tmodule.decoder.layers.6.mixer.dense_projection.layer_norm_weight\n",
      "    \tmodule.decoder.layers.24.self_attention.linear_proj.weight\n",
      "    \tmodule.decoder.layers.22.mixer.mixer.filter.h\n",
      "    \tmodule.decoder.layers.16.mixer.hyena_proj_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.13.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.9.mixer.hyena_proj_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.6.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.3.self_attention.linear_qkv.weight\n",
      "    \tmodule.decoder.layers.3.self_attention.linear_proj.bias\n",
      "    \tmodule.decoder.layers.1.mixer.mixer.conv_bias\n",
      "    \tmodule.decoder.layers.22.mixer.dense.weight\n",
      "    \tmodule.decoder.layers.21.mixer.dense.bias\n",
      "    \tmodule.decoder.layers.16.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.14.mixer.dense.bias\n",
      "    \tmodule.decoder.layers.9.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.6.mixer.mixer.conv_bias\n",
      "    \tmodule.decoder.layers.4.mixer.dense.bias\n",
      "    \tmodule.decoder.layers.0.mixer.dense_projection.layer_norm_weight\n",
      "    \tmodule.decoder.layers.23.mixer.mixer.filter.p\n",
      "    \tmodule.decoder.layers.21.mixer.hyena_proj_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.18.mixer.mixer.short_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.17.self_attention.linear_proj.bias\n",
      "    \tmodule.decoder.layers.15.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.11.mixer.mixer.short_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.8.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.3.self_attention.linear_proj.weight\n",
      "    \tmodule.decoder.layers.22.mixer.dense_projection.weight\n",
      "    \tmodule.decoder.layers.20.mixer.dense_projection.layer_norm_weight\n",
      "    \tmodule.decoder.layers.19.mixer.hyena_proj_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.16.mixer.dense.bias\n",
      "    \tmodule.decoder.layers.14.mixer.dense_projection.weight\n",
      "    \tmodule.decoder.layers.12.mixer.hyena_proj_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.9.mixer.dense.bias\n",
      "    \tmodule.decoder.layers.7.mixer.dense_projection.weight\n",
      "    \tmodule.decoder.layers.4.mixer.hyena_proj_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.0.mixer.dense.bias\n",
      "    \tmodule.decoder.layers.23.mixer.hyena_proj_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.20.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.17.self_attention.linear_qkv.weight\n",
      "    \tmodule.decoder.layers.13.mixer.mixer.filter.gamma\n",
      "    \tmodule.decoder.layers.10.self_attention.linear_qkv.weight\n",
      "    \tmodule.decoder.layers.6.mixer.mixer.filter.gamma\n",
      "    \tmodule.decoder.layers.23.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.22.mixer.mixer.conv_bias\n",
      "    \tmodule.decoder.layers.19.mixer.mixer.filter.h\n",
      "    \tmodule.decoder.layers.16.mixer.dense_projection.weight\n",
      "    \tmodule.decoder.layers.12.mixer.mixer.filter.h\n",
      "    \tmodule.decoder.layers.9.mixer.dense_projection.weight\n",
      "    \tmodule.decoder.layers.3.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.22.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.19.mixer.dense.weight\n",
      "    \tmodule.decoder.layers.16.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.14.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.12.mixer.dense.weight\n",
      "    \tmodule.decoder.layers.9.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.7.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.5.mixer.dense.weight\n",
      "    \tmodule.decoder.layers.5.mixer.dense_projection.weight\n",
      "    \tmodule.decoder.layers.2.mixer.mixer.filter.R\n",
      "    \tmodule.decoder.layers.23.mixer.dense.bias\n",
      "    \tmodule.decoder.layers.21.mixer.dense_projection.weight\n",
      "    \tmodule.decoder.layers.18.mixer.hyena_proj_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.16.mixer.mixer.conv_bias\n",
      "    \tmodule.decoder.layers.13.mixer.mixer.filter.p\n",
      "    \tmodule.decoder.layers.11.mixer.hyena_proj_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.9.mixer.mixer.conv_bias\n",
      "    \tmodule.decoder.layers.6.mixer.mixer.filter.p\n",
      "    \tmodule.decoder.layers.1.mixer.hyena_proj_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.24.self_attention.linear_qkv.weight\n",
      "    \tmodule.decoder.layers.20.mixer.mixer.filter.gamma\n",
      "    \tmodule.decoder.layers.19.mixer.dense_projection.weight\n",
      "    \tmodule.decoder.layers.14.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.12.mixer.dense_projection.weight\n",
      "    \tmodule.decoder.layers.7.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.5.mixer.hyena_proj_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.4.mixer.dense_projection.weight\n",
      "    \tmodule.decoder.layers.1.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.0.mixer.dense_projection.weight\n",
      "    \tmodule.decoder.layers.23.mixer.dense_projection.weight\n",
      "    \tmodule.decoder.layers.17.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.13.mixer.hyena_proj_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.10.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.6.mixer.hyena_proj_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.2.mixer.dense.weight\n",
      "    \tmodule.decoder.layers.1.mixer.dense.bias\n",
      "    \tmodule.decoder.layers.23.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.21.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.13.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.12.mixer.mixer.conv_bias\n",
      "    \tmodule.decoder.layers.6.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.17.self_attention.linear_qkv.layer_norm_weight\n",
      "    \tmodule.decoder.layers.23.mixer.mixer.conv_bias\n",
      "    \tmodule.decoder.layers.20.mixer.mixer.filter.p\n",
      "    \tmodule.decoder.layers.19.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.14.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.12.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.10.self_attention.linear_qkv.layer_norm_weight\n",
      "    \tmodule.decoder.layers.7.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.5.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.4.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.21.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.18.mixer.dense_projection.weight\n",
      "    \tmodule.decoder.layers.15.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.13.mixer.dense.bias\n",
      "    \tmodule.decoder.layers.11.mixer.dense_projection.weight\n",
      "    \tmodule.decoder.layers.8.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.6.mixer.dense.bias\n",
      "    \tmodule.decoder.layers.3.self_attention.linear_qkv.layer_norm_weight\n",
      "    \tmodule.decoder.layers.1.mixer.dense_projection.weight\n",
      "    \tmodule.decoder.layers.24.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.24.self_attention.linear_proj.bias\n",
      "    \tmodule.decoder.layers.20.mixer.hyena_proj_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.19.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.14.mixer.dense.weight\n",
      "    \tmodule.decoder.layers.7.mixer.dense.weight\n",
      "    \tmodule.decoder.layers.5.mixer.mixer.conv_bias\n",
      "    \tmodule.decoder.layers.4.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.2.mixer.dense_projection.layer_norm_weight\n",
      "    \tmodule.decoder.layers.20.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.13.mixer.dense_projection.weight\n",
      "    \tmodule.decoder.layers.6.mixer.dense_projection.weight\n",
      "    \tmodule.decoder.layers.2.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.1.mixer.mixer.filter.h\n",
      "    \tmodule.decoder.layers.24.self_attention.linear_qkv.layer_norm_weight\n",
      "    \tmodule.decoder.layers.21.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.18.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.16.mixer.mixer.filter.R\n",
      "    \tmodule.decoder.layers.13.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.11.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.9.mixer.mixer.filter.R\n",
      "    \tmodule.decoder.layers.6.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.3.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.1.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.22.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.20.mixer.dense.bias\n",
      "    \tmodule.decoder.layers.19.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.15.mixer.dense_projection.layer_norm_weight\n",
      "    \tmodule.decoder.layers.13.mixer.mixer.conv_bias\n",
      "    \tmodule.decoder.layers.8.mixer.dense_projection.layer_norm_weight\n",
      "    \tmodule.decoder.layers.7.mixer.dense.bias\n",
      "    \tmodule.decoder.layers.0.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.21.mixer.dense.weight\n",
      "    \tmodule.decoder.layers.18.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.15.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.11.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.8.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.20.mixer.dense_projection.weight\n",
      "    \tmodule.decoder.layers.16.mixer.dense.weight\n",
      "    \tmodule.decoder.layers.9.mixer.dense.weight\n",
      "    \tmodule.decoder.layers.4.mixer.dense.weight\n",
      "    \tmodule.decoder.layers.2.mixer.mixer.filter.gamma\n",
      "    \tmodule.decoder.layers.23.mixer.mixer.filter.R\n",
      "    \tmodule.decoder.layers.20.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.17.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.10.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.0.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.1.mixer.dense.weight\n",
      "[NeMo I 2025-05-24 15:52:45 utils:554] Setting up optimizer with config OptimizerConfig(optimizer='adam', lr=0.0001, min_lr=None, decoupled_lr=None, decoupled_min_lr=None, weight_decay=0.01, fp16=False, bf16=True, params_dtype=torch.bfloat16, use_precision_aware_optimizer=False, store_param_remainders=True, main_grads_dtype=torch.float32, main_params_dtype=torch.float32, exp_avg_dtype=torch.float32, exp_avg_sq_dtype=torch.float32, loss_scale=None, initial_loss_scale=4294967296, min_loss_scale=1.0, loss_scale_window=1000, hysteresis=2, adam_beta1=0.9, adam_beta2=0.95, adam_eps=1e-08, sgd_momentum=0.9, use_distributed_optimizer=True, overlap_param_gather_with_optimizer_step=False, optimizer_cpu_offload=False, optimizer_offload_fraction=0.0, use_torch_optimizer_for_cpu_offload=False, overlap_cpu_optimizer_d2h_h2d=False, pin_cpu_grads=True, pin_cpu_params=True, clip_grad=1.0, log_num_zeros_in_grad=False, barrier_with_L1_time=False, timers=None, config_logger_dir='')\n",
      "[NeMo I 2025-05-24 15:52:45 nemo_logging:393] Doing selective restore from RestoreConfig(path='nemo2_evo2_1b_8k', adapter_path=None, load_model_state=True, load_optim_state=False, load_artifacts=True)\n",
      "[NeMo I 2025-05-24 15:52:45 nemo_logging:393] Using <megatron.core.dist_checkpointing.strategies.fully_parallel.FullyParallelLoadStrategyWrapper object at 0x76022cd99b80> dist-ckpt load strategy.\n",
      "[NeMo I 2025-05-24 15:52:47 nemo_logging:393] Global Checkpoint Load : Rank : 0 : Start time : 1748101965.565s : Time spent in load_checkpoint: 1.998s\n",
      "[NeMo I 2025-05-24 15:52:47 nemo_logging:393] Restoring model weights from RestoreConfig(path='nemo2_evo2_1b_8k', adapter_path=None, load_model_state=True, load_optim_state=False, load_artifacts=True)\n",
      "[NeMo I 2025-05-24 15:52:47 nemo_logging:393] Finished restoring from RestoreConfig(path='nemo2_evo2_1b_8k', adapter_path=None, load_model_state=True, load_optim_state=False, load_artifacts=True), cleaning up.\n",
      "┏━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━┓\n",
      "┃\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mName                               \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mType             \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mParams\u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mMode \u001b[0m\u001b[1;35m \u001b[0m┃\n",
      "┡━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━┩\n",
      "│\u001b[2m \u001b[0m\u001b[2m0\u001b[0m\u001b[2m \u001b[0m│ module                              │ DDP               │  1.1 B │ train │\n",
      "│\u001b[2m \u001b[0m\u001b[2m1\u001b[0m\u001b[2m \u001b[0m│ module.module                       │ Float16Module     │  1.1 B │ train │\n",
      "│\u001b[2m \u001b[0m\u001b[2m2\u001b[0m\u001b[2m \u001b[0m│ module.module.module                │ HyenaModel        │  1.1 B │ train │\n",
      "│\u001b[2m \u001b[0m\u001b[2m3\u001b[0m\u001b[2m \u001b[0m│ module.module.module.embedding      │ LanguageModelEmb… │  983 K │ train │\n",
      "│\u001b[2m \u001b[0m\u001b[2m4\u001b[0m\u001b[2m \u001b[0m│ module.module.module.rotary_pos_emb │ RotaryEmbedding   │      0 │ train │\n",
      "│\u001b[2m \u001b[0m\u001b[2m5\u001b[0m\u001b[2m \u001b[0m│ module.module.module.decoder        │ HyenaStack        │  1.1 B │ train │\n",
      "│\u001b[2m \u001b[0m\u001b[2m6\u001b[0m\u001b[2m \u001b[0m│ module.module.module.output_layer   │ ColumnParallelLi… │      0 │ train │\n",
      "└───┴─────────────────────────────────────┴───────────────────┴────────┴───────┘\n",
      "\u001b[1mTrainable params\u001b[0m: 1.1 B                                                         \n",
      "\u001b[1mNon-trainable params\u001b[0m: 0                                                         \n",
      "\u001b[1mTotal params\u001b[0m: 1.1 B                                                             \n",
      "\u001b[1mTotal estimated model params size (MB)\u001b[0m: 4.4 K                                   \n",
      "\u001b[1mModules in train mode\u001b[0m: 356                                                      \n",
      "\u001b[1mModules in eval mode\u001b[0m: 0                                                         \n",
      "[NeMo W 2025-05-24 15:53:47 rerun_state_machine:1264] Implicit initialization of Rerun State Machine!\n",
      "[NeMo W 2025-05-24 15:53:47 rerun_state_machine:239] RerunStateMachine initialized in mode RerunMode.DISABLED\n",
      "Training epoch 0, iteration 0/99 | lr: 0 | global_batch_size: 1 | global_step: 0 | reduced_train_loss: 1.46 | train_step_timing in s: 23.05\n",
      "Training epoch 0, iteration 1/99 | lr: 2e-05 | global_batch_size: 1 | global_step: 1 | reduced_train_loss: 1.472 | train_step_timing in s: 2.461 | consumed_samples: 2\n",
      "Training epoch 0, iteration 2/99 | lr: 4e-05 | global_batch_size: 1 | global_step: 2 | reduced_train_loss: 1.823 | train_step_timing in s: 0.3414 | consumed_samples: 3\n",
      "Training epoch 0, iteration 3/99 | lr: 6e-05 | global_batch_size: 1 | global_step: 3 | reduced_train_loss: 1.331 | train_step_timing in s: 0.3744 | consumed_samples: 4\n",
      "Training epoch 0, iteration 4/99 | lr: 8e-05 | global_batch_size: 1 | global_step: 4 | reduced_train_loss: 1.337 | train_step_timing in s: 0.3341 | consumed_samples: 5\n",
      "Training epoch 0, iteration 5/99 | lr: 0.0001 | global_batch_size: 1 | global_step: 5 | reduced_train_loss: 2.111 | train_step_timing in s: 0.3964 | consumed_samples: 6\n",
      "Training epoch 0, iteration 6/99 | lr: 3e-05 | global_batch_size: 1 | global_step: 6 | reduced_train_loss: 0.5181 | train_step_timing in s: 0.3797 | consumed_samples: 7\n",
      "Training epoch 0, iteration 7/99 | lr: 3e-05 | global_batch_size: 1 | global_step: 7 | reduced_train_loss: 5.48 | train_step_timing in s: 0.3783 | consumed_samples: 8\n",
      "Training epoch 0, iteration 8/99 | lr: 3e-05 | global_batch_size: 1 | global_step: 8 | reduced_train_loss: 0.5512 | train_step_timing in s: 0.323 | consumed_samples: 9\n",
      "Training epoch 0, iteration 9/99 | lr: 3e-05 | global_batch_size: 1 | global_step: 9 | reduced_train_loss: 2.03 | train_step_timing in s: 0.3056 | consumed_samples: 10\n",
      "Training epoch 0, iteration 10/99 | lr: 3e-05 | global_batch_size: 1 | global_step: 10 | reduced_train_loss: 1.445 | train_step_timing in s: 0.4078 | consumed_samples: 11\n",
      "Training epoch 0, iteration 11/99 | lr: 3e-05 | global_batch_size: 1 | global_step: 11 | reduced_train_loss: 2.197 | train_step_timing in s: 0.389 | consumed_samples: 12\n",
      "Training epoch 0, iteration 12/99 | lr: 3e-05 | global_batch_size: 1 | global_step: 12 | reduced_train_loss: 0.93 | train_step_timing in s: 0.3769 | consumed_samples: 13\n",
      "Training epoch 0, iteration 13/99 | lr: 3e-05 | global_batch_size: 1 | global_step: 13 | reduced_train_loss: 0.7602 | train_step_timing in s: 0.3256 | consumed_samples: 14\n",
      "Training epoch 0, iteration 14/99 | lr: 3e-05 | global_batch_size: 1 | global_step: 14 | reduced_train_loss: 0.5082 | train_step_timing in s: 0.3603 | consumed_samples: 15\n",
      "Training epoch 0, iteration 15/99 | lr: 3e-05 | global_batch_size: 1 | global_step: 15 | reduced_train_loss: 0.3451 | train_step_timing in s: 0.3301 | consumed_samples: 16\n",
      "Training epoch 0, iteration 16/99 | lr: 3e-05 | global_batch_size: 1 | global_step: 16 | reduced_train_loss: 2.594 | train_step_timing in s: 0.3269 | consumed_samples: 17\n",
      "Training epoch 0, iteration 17/99 | lr: 3e-05 | global_batch_size: 1 | global_step: 17 | reduced_train_loss: 5.31 | train_step_timing in s: 0.3985 | consumed_samples: 18\n",
      "Training epoch 0, iteration 18/99 | lr: 3e-05 | global_batch_size: 1 | global_step: 18 | reduced_train_loss: 3.781 | train_step_timing in s: 0.4087 | consumed_samples: 19\n",
      "Training epoch 0, iteration 19/99 | lr: 3e-05 | global_batch_size: 1 | global_step: 19 | reduced_train_loss: 0.2096 | train_step_timing in s: 0.3847 | consumed_samples: 20\n",
      "Training epoch 0, iteration 20/99 | lr: 3e-05 | global_batch_size: 1 | global_step: 20 | reduced_train_loss: 3.309 | train_step_timing in s: 0.3851 | consumed_samples: 21\n",
      "Training epoch 0, iteration 21/99 | lr: 3e-05 | global_batch_size: 1 | global_step: 21 | reduced_train_loss: 0.2375 | train_step_timing in s: 0.3793 | consumed_samples: 22\n",
      "Training epoch 0, iteration 22/99 | lr: 3e-05 | global_batch_size: 1 | global_step: 22 | reduced_train_loss: 2.854 | train_step_timing in s: 0.2789 | consumed_samples: 23\n",
      "Training epoch 0, iteration 23/99 | lr: 3e-05 | global_batch_size: 1 | global_step: 23 | reduced_train_loss: 2.665 | train_step_timing in s: 0.2611 | consumed_samples: 24\n",
      "Training epoch 0, iteration 24/99 | lr: 3e-05 | global_batch_size: 1 | global_step: 24 | reduced_train_loss: 0.2788 | train_step_timing in s: 0.3081 | consumed_samples: 25\n",
      "Training epoch 0, iteration 25/99 | lr: 3e-05 | global_batch_size: 1 | global_step: 25 | reduced_train_loss: 2.379 | train_step_timing in s: 0.3379 | consumed_samples: 26\n",
      "Training epoch 0, iteration 26/99 | lr: 3e-05 | global_batch_size: 1 | global_step: 26 | reduced_train_loss: 0.2992 | train_step_timing in s: 0.352 | consumed_samples: 27\n",
      "Training epoch 0, iteration 27/99 | lr: 3e-05 | global_batch_size: 1 | global_step: 27 | reduced_train_loss: 2.151 | train_step_timing in s: 0.362 | consumed_samples: 28\n",
      "Training epoch 0, iteration 28/99 | lr: 3e-05 | global_batch_size: 1 | global_step: 28 | reduced_train_loss: 2.96 | train_step_timing in s: 0.3525 | consumed_samples: 29\n",
      "Training epoch 0, iteration 29/99 | lr: 3e-05 | global_batch_size: 1 | global_step: 29 | reduced_train_loss: 1.898 | train_step_timing in s: 0.3427 | consumed_samples: 30\n",
      "Training epoch 0, iteration 30/99 | lr: 3e-05 | global_batch_size: 1 | global_step: 30 | reduced_train_loss: 0.3907 | train_step_timing in s: 0.3136 | consumed_samples: 31\n",
      "Training epoch 0, iteration 31/99 | lr: 3e-05 | global_batch_size: 1 | global_step: 31 | reduced_train_loss: 0.4098 | train_step_timing in s: 0.43 | consumed_samples: 32\n",
      "Training epoch 0, iteration 32/99 | lr: 3e-05 | global_batch_size: 1 | global_step: 32 | reduced_train_loss: 2.892 | train_step_timing in s: 0.414 | consumed_samples: 33\n",
      "Training epoch 0, iteration 33/99 | lr: 3e-05 | global_batch_size: 1 | global_step: 33 | reduced_train_loss: 0.4136 | train_step_timing in s: 0.3915 | consumed_samples: 34\n",
      "Training epoch 0, iteration 34/99 | lr: 3e-05 | global_batch_size: 1 | global_step: 34 | reduced_train_loss: 2.76 | train_step_timing in s: 0.366 | consumed_samples: 35\n",
      "Training epoch 0, iteration 35/99 | lr: 3e-05 | global_batch_size: 1 | global_step: 35 | reduced_train_loss: 0.3878 | train_step_timing in s: 0.3867 | consumed_samples: 36\n",
      "Training epoch 0, iteration 36/99 | lr: 3e-05 | global_batch_size: 1 | global_step: 36 | reduced_train_loss: 1.742 | train_step_timing in s: 0.3439 | consumed_samples: 37\n",
      "Training epoch 0, iteration 37/99 | lr: 3e-05 | global_batch_size: 1 | global_step: 37 | reduced_train_loss: 0.3666 | train_step_timing in s: 0.3009 | consumed_samples: 38\n",
      "Training epoch 0, iteration 38/99 | lr: 3e-05 | global_batch_size: 1 | global_step: 38 | reduced_train_loss: 2.89 | train_step_timing in s: 0.3271 | consumed_samples: 39\n",
      "Training epoch 0, iteration 39/99 | lr: 3e-05 | global_batch_size: 1 | global_step: 39 | reduced_train_loss: 2.478 | train_step_timing in s: 0.3971 | consumed_samples: 40\n",
      "Training epoch 0, iteration 40/99 | lr: 3e-05 | global_batch_size: 1 | global_step: 40 | reduced_train_loss: 0.3569 | train_step_timing in s: 0.3514 | consumed_samples: 41\n",
      "Training epoch 0, iteration 41/99 | lr: 3e-05 | global_batch_size: 1 | global_step: 41 | reduced_train_loss: 1.986 | train_step_timing in s: 0.3553 | consumed_samples: 42\n",
      "Training epoch 0, iteration 42/99 | lr: 3e-05 | global_batch_size: 1 | global_step: 42 | reduced_train_loss: 2.336 | train_step_timing in s: 0.3706 | consumed_samples: 43\n",
      "Training epoch 0, iteration 43/99 | lr: 3e-05 | global_batch_size: 1 | global_step: 43 | reduced_train_loss: 0.3645 | train_step_timing in s: 0.3656 | consumed_samples: 44\n",
      "Training epoch 0, iteration 44/99 | lr: 3e-05 | global_batch_size: 1 | global_step: 44 | reduced_train_loss: 1.997 | train_step_timing in s: 0.306 | consumed_samples: 45\n",
      "Training epoch 0, iteration 45/99 | lr: 3e-05 | global_batch_size: 1 | global_step: 45 | reduced_train_loss: 0.3719 | train_step_timing in s: 0.3315 | consumed_samples: 46\n",
      "Training epoch 0, iteration 46/99 | lr: 3e-05 | global_batch_size: 1 | global_step: 46 | reduced_train_loss: 2.167 | train_step_timing in s: 0.396 | consumed_samples: 47\n",
      "Training epoch 0, iteration 47/99 | lr: 3e-05 | global_batch_size: 1 | global_step: 47 | reduced_train_loss: 2.89 | train_step_timing in s: 0.3722 | consumed_samples: 48\n",
      "Training epoch 0, iteration 48/99 | lr: 3e-05 | global_batch_size: 1 | global_step: 48 | reduced_train_loss: 0.3852 | train_step_timing in s: 0.3828 | consumed_samples: 49\n",
      "Training epoch 0, iteration 49/99 | lr: 3e-05 | global_batch_size: 1 | global_step: 49 | reduced_train_loss: 2.048 | train_step_timing in s: 0.4227 | consumed_samples: 50\n",
      "Epoch 0, global step 49: 'val_loss' was not in top 5\n",
      "[NeMo I 2025-05-24 15:54:07 nemo_logging:393] Using FullyParallelSaveStrategyWrapper(torch_dist, 1) dist-ckpt save strategy.\n",
      "[NeMo I 2025-05-24 15:54:13 nemo_logging:393] Global Checkpoint Save : Rank: 0 : Iteration: 49 : Start time: 1748102047.680s : Save duration: 6.254s\n",
      "[NeMo I 2025-05-24 15:54:37 nemo_logging:393] Scheduled async checkpoint save for /workspace/results/evo2/checkpoints/evo2--val_loss=0.0000-epoch=0-consumed_samples=50.0-last.ckpt\n",
      "[NeMo I 2025-05-24 15:54:37 nemo_logging:393] Async finalization time took 0.004 s\n",
      "Validation: iteration 1/20\n",
      "Validation: iteration 2/20\n",
      "Validation: iteration 3/20\n",
      "Validation: iteration 4/20\n",
      "Validation: iteration 5/20\n",
      "Validation: iteration 6/20\n",
      "Validation: iteration 7/20\n",
      "Validation: iteration 8/20\n",
      "Validation: iteration 9/20\n",
      "Validation: iteration 10/20\n",
      "Validation: iteration 11/20\n",
      "Validation: iteration 12/20\n",
      "Validation: iteration 13/20\n",
      "Validation: iteration 14/20\n",
      "Validation: iteration 15/20\n",
      "Validation: iteration 16/20\n",
      "Validation: iteration 17/20\n",
      "Validation: iteration 18/20\n",
      "Validation: iteration 19/20\n",
      "Validation: iteration 20/20\n",
      "[NeMo W 2025-05-24 15:55:27 nemo_logging:405] /usr/local/lib/python3.12/dist-packages/lightning/pytorch/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('global_batch_size', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "    \n",
      "[NeMo W 2025-05-24 15:55:27 nemo_logging:405] /usr/local/lib/python3.12/dist-packages/lightning/pytorch/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "    \n",
      "Training epoch 0, iteration 50/99 | lr: 3e-05 | global_batch_size: 1 | global_step: 50 | reduced_train_loss: 2.037 | train_step_timing in s: 0.3171 | consumed_samples: 51 | val_loss: 1.454\n",
      "[NeMo I 2025-05-24 15:55:27 nemo_logging:393] Successfully saved checkpoint from iteration      49 to /workspace/results/evo2/checkpoints/evo2--val_loss=0.0000-epoch=0-consumed_samples=50.0-last.ckpt\n",
      "[NeMo I 2025-05-24 15:55:27 nemo_logging:393] Async checkpoint save for step 50 (/workspace/results/evo2/checkpoints/evo2--val_loss=0.0000-epoch=0-consumed_samples=50.0-last.ckpt) finalized successfully.\n",
      "[NeMo I 2025-05-24 15:55:27 nemo_logging:393] Async finalization time took 0.102 s\n",
      "Training epoch 0, iteration 51/99 | lr: 3e-05 | global_batch_size: 1 | global_step: 51 | reduced_train_loss: 2.779 | train_step_timing in s: 0.3318 | consumed_samples: 52 | val_loss: 1.454\n",
      "Training epoch 0, iteration 52/99 | lr: 3e-05 | global_batch_size: 1 | global_step: 52 | reduced_train_loss: 1.957 | train_step_timing in s: 0.3909 | consumed_samples: 53 | val_loss: 1.454\n",
      "Training epoch 0, iteration 53/99 | lr: 3e-05 | global_batch_size: 1 | global_step: 53 | reduced_train_loss: 1.992 | train_step_timing in s: 0.3908 | consumed_samples: 54 | val_loss: 1.454\n",
      "Training epoch 0, iteration 54/99 | lr: 3e-05 | global_batch_size: 1 | global_step: 54 | reduced_train_loss: 1.826 | train_step_timing in s: 0.3985 | consumed_samples: 55 | val_loss: 1.454\n",
      "Training epoch 0, iteration 55/99 | lr: 3e-05 | global_batch_size: 1 | global_step: 55 | reduced_train_loss: 0.5121 | train_step_timing in s: 0.3803 | consumed_samples: 56 | val_loss: 1.454\n",
      "Training epoch 0, iteration 56/99 | lr: 3e-05 | global_batch_size: 1 | global_step: 56 | reduced_train_loss: 1.675 | train_step_timing in s: 0.3961 | consumed_samples: 57 | val_loss: 1.454\n",
      "Training epoch 0, iteration 57/99 | lr: 3e-05 | global_batch_size: 1 | global_step: 57 | reduced_train_loss: 0.5731 | train_step_timing in s: 0.3165 | consumed_samples: 58 | val_loss: 1.454\n",
      "Training epoch 0, iteration 58/99 | lr: 3e-05 | global_batch_size: 1 | global_step: 58 | reduced_train_loss: 2.553 | train_step_timing in s: 0.3276 | consumed_samples: 59 | val_loss: 1.454\n",
      "Training epoch 0, iteration 59/99 | lr: 3e-05 | global_batch_size: 1 | global_step: 59 | reduced_train_loss: 0.6041 | train_step_timing in s: 0.4099 | consumed_samples: 60 | val_loss: 1.454\n",
      "Training epoch 0, iteration 60/99 | lr: 3e-05 | global_batch_size: 1 | global_step: 60 | reduced_train_loss: 0.6049 | train_step_timing in s: 0.389 | consumed_samples: 61 | val_loss: 1.454\n",
      "Training epoch 0, iteration 61/99 | lr: 3e-05 | global_batch_size: 1 | global_step: 61 | reduced_train_loss: 1.534 | train_step_timing in s: 0.3813 | consumed_samples: 62 | val_loss: 1.454\n",
      "Training epoch 0, iteration 62/99 | lr: 3e-05 | global_batch_size: 1 | global_step: 62 | reduced_train_loss: 2.382 | train_step_timing in s: 0.3868 | consumed_samples: 63 | val_loss: 1.454\n",
      "Training epoch 0, iteration 63/99 | lr: 3e-05 | global_batch_size: 1 | global_step: 63 | reduced_train_loss: 1.516 | train_step_timing in s: 0.4028 | consumed_samples: 64 | val_loss: 1.454\n",
      "Training epoch 0, iteration 64/99 | lr: 3e-05 | global_batch_size: 1 | global_step: 64 | reduced_train_loss: 0.6058 | train_step_timing in s: 0.3237 | consumed_samples: 65 | val_loss: 1.454\n",
      "Training epoch 0, iteration 65/99 | lr: 3e-05 | global_batch_size: 1 | global_step: 65 | reduced_train_loss: 2.254 | train_step_timing in s: 0.3438 | consumed_samples: 66 | val_loss: 1.454\n",
      "Training epoch 0, iteration 66/99 | lr: 3e-05 | global_batch_size: 1 | global_step: 66 | reduced_train_loss: 2.19 | train_step_timing in s: 0.3902 | consumed_samples: 67 | val_loss: 1.454\n",
      "Training epoch 0, iteration 67/99 | lr: 3e-05 | global_batch_size: 1 | global_step: 67 | reduced_train_loss: 0.6077 | train_step_timing in s: 0.3972 | consumed_samples: 68 | val_loss: 1.454\n",
      "Training epoch 0, iteration 68/99 | lr: 3e-05 | global_batch_size: 1 | global_step: 68 | reduced_train_loss: 0.6014 | train_step_timing in s: 0.384 | consumed_samples: 69 | val_loss: 1.454\n",
      "Training epoch 0, iteration 69/99 | lr: 3e-05 | global_batch_size: 1 | global_step: 69 | reduced_train_loss: 1.969 | train_step_timing in s: 0.3916 | consumed_samples: 70 | val_loss: 1.454\n",
      "Training epoch 0, iteration 70/99 | lr: 3e-05 | global_batch_size: 1 | global_step: 70 | reduced_train_loss: 1.596 | train_step_timing in s: 0.4204 | consumed_samples: 71 | val_loss: 1.454\n",
      "Training epoch 0, iteration 71/99 | lr: 3e-05 | global_batch_size: 1 | global_step: 71 | reduced_train_loss: 1.617 | train_step_timing in s: 0.3241 | consumed_samples: 72 | val_loss: 1.454\n",
      "Training epoch 0, iteration 72/99 | lr: 3e-05 | global_batch_size: 1 | global_step: 72 | reduced_train_loss: 2.525 | train_step_timing in s: 0.3687 | consumed_samples: 73 | val_loss: 1.454\n",
      "Training epoch 0, iteration 73/99 | lr: 3e-05 | global_batch_size: 1 | global_step: 73 | reduced_train_loss: 1.594 | train_step_timing in s: 0.3814 | consumed_samples: 74 | val_loss: 1.454\n",
      "Training epoch 0, iteration 74/99 | lr: 3e-05 | global_batch_size: 1 | global_step: 74 | reduced_train_loss: 0.6356 | train_step_timing in s: 0.3816 | consumed_samples: 75 | val_loss: 1.454\n",
      "Training epoch 0, iteration 75/99 | lr: 3e-05 | global_batch_size: 1 | global_step: 75 | reduced_train_loss: 1.529 | train_step_timing in s: 0.3908 | consumed_samples: 76 | val_loss: 1.454\n",
      "Training epoch 0, iteration 76/99 | lr: 3e-05 | global_batch_size: 1 | global_step: 76 | reduced_train_loss: 1.497 | train_step_timing in s: 0.3984 | consumed_samples: 77 | val_loss: 1.454\n",
      "Training epoch 0, iteration 77/99 | lr: 3e-05 | global_batch_size: 1 | global_step: 77 | reduced_train_loss: 0.6858 | train_step_timing in s: 0.331 | consumed_samples: 78 | val_loss: 1.454\n",
      "Training epoch 0, iteration 78/99 | lr: 3e-05 | global_batch_size: 1 | global_step: 78 | reduced_train_loss: 2.566 | train_step_timing in s: 0.3092 | consumed_samples: 79 | val_loss: 1.454\n",
      "Training epoch 0, iteration 79/99 | lr: 3e-05 | global_batch_size: 1 | global_step: 79 | reduced_train_loss: 1.367 | train_step_timing in s: 0.3405 | consumed_samples: 80 | val_loss: 1.454\n",
      "Training epoch 0, iteration 80/99 | lr: 3e-05 | global_batch_size: 1 | global_step: 80 | reduced_train_loss: 0.734 | train_step_timing in s: 0.3988 | consumed_samples: 81 | val_loss: 1.454\n",
      "Training epoch 0, iteration 81/99 | lr: 3e-05 | global_batch_size: 1 | global_step: 81 | reduced_train_loss: 1.81 | train_step_timing in s: 0.3874 | consumed_samples: 82 | val_loss: 1.454\n",
      "Training epoch 0, iteration 82/99 | lr: 3e-05 | global_batch_size: 1 | global_step: 82 | reduced_train_loss: 0.7574 | train_step_timing in s: 0.4045 | consumed_samples: 83 | val_loss: 1.454\n",
      "Training epoch 0, iteration 83/99 | lr: 3e-05 | global_batch_size: 1 | global_step: 83 | reduced_train_loss: 2.499 | train_step_timing in s: 0.4003 | consumed_samples: 84 | val_loss: 1.454\n",
      "Training epoch 0, iteration 84/99 | lr: 3e-05 | global_batch_size: 1 | global_step: 84 | reduced_train_loss: 2.47 | train_step_timing in s: 0.3715 | consumed_samples: 85 | val_loss: 1.454\n",
      "Training epoch 0, iteration 85/99 | lr: 3e-05 | global_batch_size: 1 | global_step: 85 | reduced_train_loss: 1.813 | train_step_timing in s: 0.3236 | consumed_samples: 86 | val_loss: 1.454\n",
      "Training epoch 0, iteration 86/99 | lr: 3e-05 | global_batch_size: 1 | global_step: 86 | reduced_train_loss: 1.276 | train_step_timing in s: 0.3799 | consumed_samples: 87 | val_loss: 1.454\n",
      "Training epoch 0, iteration 87/99 | lr: 3e-05 | global_batch_size: 1 | global_step: 87 | reduced_train_loss: 0.7981 | train_step_timing in s: 0.3897 | consumed_samples: 88 | val_loss: 1.454\n",
      "Training epoch 0, iteration 88/99 | lr: 3e-05 | global_batch_size: 1 | global_step: 88 | reduced_train_loss: 1.784 | train_step_timing in s: 0.3883 | consumed_samples: 89 | val_loss: 1.454\n",
      "Training epoch 0, iteration 89/99 | lr: 3e-05 | global_batch_size: 1 | global_step: 89 | reduced_train_loss: 1.757 | train_step_timing in s: 0.3889 | consumed_samples: 90 | val_loss: 1.454\n",
      "Training epoch 0, iteration 90/99 | lr: 3e-05 | global_batch_size: 1 | global_step: 90 | reduced_train_loss: 1.706 | train_step_timing in s: 0.3836 | consumed_samples: 91 | val_loss: 1.454\n",
      "Training epoch 0, iteration 91/99 | lr: 3e-05 | global_batch_size: 1 | global_step: 91 | reduced_train_loss: 0.8544 | train_step_timing in s: 0.3742 | consumed_samples: 92 | val_loss: 1.454\n",
      "Training epoch 0, iteration 92/99 | lr: 3e-05 | global_batch_size: 1 | global_step: 92 | reduced_train_loss: 1.351 | train_step_timing in s: 0.3215 | consumed_samples: 93 | val_loss: 1.454\n",
      "Training epoch 0, iteration 93/99 | lr: 3e-05 | global_batch_size: 1 | global_step: 93 | reduced_train_loss: 2.148 | train_step_timing in s: 0.3792 | consumed_samples: 94 | val_loss: 1.454\n",
      "Training epoch 0, iteration 94/99 | lr: 3e-05 | global_batch_size: 1 | global_step: 94 | reduced_train_loss: 0.891 | train_step_timing in s: 0.3855 | consumed_samples: 95 | val_loss: 1.454\n",
      "Training epoch 0, iteration 95/99 | lr: 3e-05 | global_batch_size: 1 | global_step: 95 | reduced_train_loss: 0.8889 | train_step_timing in s: 0.3739 | consumed_samples: 96 | val_loss: 1.454\n",
      "Training epoch 0, iteration 96/99 | lr: 3e-05 | global_batch_size: 1 | global_step: 96 | reduced_train_loss: 0.882 | train_step_timing in s: 0.3967 | consumed_samples: 97 | val_loss: 1.454\n",
      "Training epoch 0, iteration 97/99 | lr: 3e-05 | global_batch_size: 1 | global_step: 97 | reduced_train_loss: 1.506 | train_step_timing in s: 0.3965 | consumed_samples: 98 | val_loss: 1.454\n",
      "Training epoch 0, iteration 98/99 | lr: 3e-05 | global_batch_size: 1 | global_step: 98 | reduced_train_loss: 1.494 | train_step_timing in s: 0.3747 | consumed_samples: 99 | val_loss: 1.454\n",
      "Training epoch 0, iteration 99/99 | lr: 3e-05 | global_batch_size: 1 | global_step: 99 | reduced_train_loss: 1.544 | train_step_timing in s: 0.3161 | consumed_samples: 100 | val_loss: 1.454\n",
      "Epoch 0, global step 99: 'val_loss' reached 1.45366 (best 1.45366), saving model to '/workspace/results/evo2/checkpoints/evo2--val_loss=1.4537-epoch=0-consumed_samples=100.0.ckpt' as top 5\n",
      "[NeMo I 2025-05-24 15:55:46 nemo_logging:393] Global Checkpoint Save : Rank: 0 : Iteration: 99 : Start time: 1748102146.465s : Save duration: 0.504s\n",
      "[NeMo I 2025-05-24 15:55:52 nemo_logging:393] Scheduled async checkpoint save for /workspace/results/evo2/checkpoints/evo2--val_loss=1.4537-epoch=0-consumed_samples=100.0.ckpt\n",
      "[NeMo I 2025-05-24 15:55:53 nemo_logging:393] Global Checkpoint Save : Rank: 0 : Iteration: 99 : Start time: 1748102152.870s : Save duration: 0.788s\n",
      "[NeMo I 2025-05-24 15:56:00 nemo_logging:393] Scheduled async checkpoint save for /workspace/results/evo2/checkpoints/evo2--val_loss=1.4537-epoch=0-consumed_samples=100.0-last.ckpt\n",
      "[NeMo I 2025-05-24 15:56:00 nemo_logging:393] Async finalization time took 0.003 s\n",
      "Validation: iteration 1/20\n",
      "Validation: iteration 2/20\n",
      "Validation: iteration 3/20\n",
      "Validation: iteration 4/20\n",
      "Validation: iteration 5/20\n",
      "Validation: iteration 6/20\n",
      "Validation: iteration 7/20\n",
      "Validation: iteration 8/20\n",
      "Validation: iteration 9/20\n",
      "Validation: iteration 10/20\n",
      "Validation: iteration 11/20\n",
      "Validation: iteration 12/20\n",
      "Validation: iteration 13/20\n",
      "Validation: iteration 14/20\n",
      "Validation: iteration 15/20\n",
      "Validation: iteration 16/20\n",
      "Validation: iteration 17/20\n",
      "Validation: iteration 18/20\n",
      "Validation: iteration 19/20\n",
      "Validation: iteration 20/20\n",
      "[NeMo I 2025-05-24 15:56:55 nemo_logging:393] Successfully saved checkpoint from iteration      99 to /workspace/results/evo2/checkpoints/evo2--val_loss=1.4537-epoch=0-consumed_samples=100.0.ckpt\n",
      "[NeMo I 2025-05-24 15:56:55 nemo_logging:393] Async checkpoint save for step 100 (/workspace/results/evo2/checkpoints/evo2--val_loss=1.4537-epoch=0-consumed_samples=100.0.ckpt) finalized successfully.\n",
      "[NeMo I 2025-05-24 15:56:56 nemo_logging:393] Successfully saved checkpoint from iteration      99 to /workspace/results/evo2/checkpoints/evo2--val_loss=1.4537-epoch=0-consumed_samples=100.0-last.ckpt\n",
      "[NeMo I 2025-05-24 15:56:56 nemo_logging:393] Async checkpoint save for step 100 (/workspace/results/evo2/checkpoints/evo2--val_loss=1.4537-epoch=0-consumed_samples=100.0-last.ckpt) finalized successfully.\n",
      "[NeMo I 2025-05-24 15:56:56 nemo_logging:393] Async finalization time took 1.020 s\n",
      "`Trainer.fit` stopped: `max_steps=100` reached.\n"
     ]
    }
   ],
   "source": [
    "!train_evo2 \\\n",
    "    -d training_data_config.yaml \\\n",
    "    --dataset-dir {preprocessed_data} \\\n",
    "    --model-size 1b \\\n",
    "    --devices 1 \\\n",
    "    --num-nodes 1 \\\n",
    "    --seq-length 1 \\\n",
    "    --micro-batch-size 1 \\\n",
    "    --lr 0.0001 \\\n",
    "    --warmup-steps 5 \\\n",
    "    --max-steps 100 \\\n",
    "    --ckpt-dir nemo2_evo2_1b_8k \\\n",
    "    --clip-grad 1 \\\n",
    "    --wd 0.01 \\\n",
    "    --activation-checkpoint-recompute-num-layers 1 \\\n",
    "    --val-check-interval 50 \\\n",
    "    --ckpt-async-save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "eb824a00-ea7c-4ef2-8e0b-66e6189876c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mDEPRECATION: Loading egg at /usr/local/lib/python3.12/dist-packages/looseversion-1.3.0-py3.12.egg is deprecated. pip 25.1 will enforce this behaviour change. A possible replacement is to use pip for package installation. Discussion can be found at https://github.com/pypa/pip/issues/12330\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mDEPRECATION: Loading egg at /usr/local/lib/python3.12/dist-packages/lightning_utilities-0.12.0.dev0-py3.12.egg is deprecated. pip 25.1 will enforce this behaviour change. A possible replacement is to use pip for package installation. Discussion can be found at https://github.com/pypa/pip/issues/12330\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mDEPRECATION: Loading egg at /usr/local/lib/python3.12/dist-packages/dill-0.3.9-py3.12.egg is deprecated. pip 25.1 will enforce this behaviour change. A possible replacement is to use pip for package installation. Discussion can be found at https://github.com/pypa/pip/issues/12330\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mDEPRECATION: Loading egg at /usr/local/lib/python3.12/dist-packages/opt_einsum-3.4.0-py3.12.egg is deprecated. pip 25.1 will enforce this behaviour change. A possible replacement is to use pip for package installation. Discussion can be found at https://github.com/pypa/pip/issues/12330\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mDEPRECATION: Loading egg at /usr/local/lib/python3.12/dist-packages/nvfuser-0.2.23a0+6627725-py3.12-linux-x86_64.egg is deprecated. pip 25.1 will enforce this behaviour change. A possible replacement is to use pip for package installation. Discussion can be found at https://github.com/pypa/pip/issues/12330\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mDEPRECATION: Loading egg at /usr/local/lib/python3.12/dist-packages/lightning_thunder-0.2.0.dev0-py3.12.egg is deprecated. pip 25.1 will enforce this behaviour change. A possible replacement is to use pip for package installation. Discussion can be found at https://github.com/pypa/pip/issues/12330\u001b[0m\u001b[33m\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install -q peft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e4f1a484-0a58-4fe2-bb80-b344eeba271e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cp /workspace/bionemo_train.py /usr/local/lib/python3.12/dist-packages/bionemo/evo2/run/train.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7f72369-7e12-4796-a18c-3822b4598e03",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not find the bitsandbytes CUDA binary at PosixPath('/usr/local/lib/python3.12/dist-packages/bitsandbytes/libbitsandbytes_cuda129.so')\n",
      "The installed version of bitsandbytes was compiled without GPU support. 8-bit optimizers, 8-bit multiplication, and GPU quantization are unavailable.\n",
      "[NeMo I 2025-06-01 15:37:07 nemo_logging:393] Using byte-level tokenization\n",
      "[NeMo W 2025-06-01 15:37:07 nemo_logging:405] WandB is currently turned off.\n",
      "[NeMo W 2025-06-01 15:37:07 nemo_logging:405] User-set tensorboard is currently turned off. Internally one may still be set by NeMo2.\n",
      "Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "[NeMo I 2025-06-01 15:37:07 nemo_logging:393] Experiments will be logged at results/evo2/dev\n",
      "[NeMo W 2025-06-01 15:37:07 nemo_logging:405] There were no checkpoints found in checkpoint_dir or no checkpoint folder at checkpoint_dir :results/evo2/checkpoints. Training from scratch.\n",
      "[NeMo I 2025-06-01 15:37:07 nemo_logging:393] Fixing mis-match between ddp-config & mcore-optimizer config\n",
      "[NeMo I 2025-06-01 15:37:07 nemo_logging:393] Rank 0 has data parallel group : [0]\n",
      "[NeMo I 2025-06-01 15:37:07 nemo_logging:393] Rank 0 has combined group of data parallel and context parallel : [0]\n",
      "[NeMo I 2025-06-01 15:37:07 nemo_logging:393] All data parallel group ranks with context parallel combined: [[0]]\n",
      "[NeMo I 2025-06-01 15:37:07 nemo_logging:393] Ranks 0 has data parallel rank: 0\n",
      "[NeMo I 2025-06-01 15:37:07 nemo_logging:393] Rank 0 has context parallel group: [0]\n",
      "[NeMo I 2025-06-01 15:37:07 nemo_logging:393] All context parallel group ranks: [[0]]\n",
      "[NeMo I 2025-06-01 15:37:07 nemo_logging:393] Ranks 0 has context parallel rank: 0\n",
      "[NeMo I 2025-06-01 15:37:07 nemo_logging:393] Rank 0 has model parallel group: [0]\n",
      "[NeMo I 2025-06-01 15:37:07 nemo_logging:393] All model parallel group ranks: [[0]]\n",
      "[NeMo I 2025-06-01 15:37:07 nemo_logging:393] Rank 0 has tensor model parallel group: [0]\n",
      "[NeMo I 2025-06-01 15:37:07 nemo_logging:393] All tensor model parallel group ranks: [[0]]\n",
      "[NeMo I 2025-06-01 15:37:07 nemo_logging:393] Rank 0 has tensor model parallel rank: 0\n",
      "[NeMo I 2025-06-01 15:37:07 nemo_logging:393] Rank 0 has pipeline model parallel group: [0]\n",
      "[NeMo I 2025-06-01 15:37:07 nemo_logging:393] Rank 0 has embedding group: [0]\n",
      "[NeMo I 2025-06-01 15:37:07 nemo_logging:393] All pipeline model parallel group ranks: [[0]]\n",
      "[NeMo I 2025-06-01 15:37:07 nemo_logging:393] Rank 0 has pipeline model parallel rank 0\n",
      "[NeMo I 2025-06-01 15:37:07 nemo_logging:393] All embedding group ranks: [[0]]\n",
      "[NeMo I 2025-06-01 15:37:07 nemo_logging:393] Rank 0 has embedding rank: 0\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 1 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[NeMo I 2025-06-01 15:37:08 utils:554] Building Evo2Dataset splits with sizes=[300000, 6020, 1] and config=GPTDatasetConfig(random_seed=1234, sequence_length=1, blend=None, blend_per_split=[(['/workspace/preprocessed_data/XTT22_train_byte-level_train'], [1.0]), (['/workspace/preprocessed_data/XTT22_train_byte-level_val'], [1.0]), (['/workspace/preprocessed_data/XTT22_train_byte-level_test'], [1.0])], split=None, split_matrix=None, num_dataset_builder_threads=1, path_to_cache=None, mmap_bin_files=True, mock=False, tokenizer=<nemo.collections.common.tokenizers.bytelevel_tokenizers.ByteLevelTokenizer object at 0x77e4f623ba40>, mid_level_dataset_surplus=0.005, reset_position_ids=False, reset_attention_mask=False, eod_mask_loss=False, create_attention_mask=False, drop_last_partial_validation_sequence=True, add_extra_token_to_sequence=True, object_storage_cache_path=None)\n",
      "[NeMo I 2025-06-01 15:37:08 utils:554] Load the _IndexReader from /workspace/preprocessed_data/XTT22_train_byte-level_train.idx\n",
      "[NeMo I 2025-06-01 15:37:08 utils:554] \tExtract the sequence lengths\n",
      "[NeMo I 2025-06-01 15:37:08 utils:554] \tExtract the sequence pointers\n",
      "[NeMo I 2025-06-01 15:37:08 utils:554] \tExtract the document indices\n",
      "[NeMo I 2025-06-01 15:37:08 utils:554] > total number of sequences: 10896\n",
      "[NeMo I 2025-06-01 15:37:08 utils:554] > total number of documents: 10896\n",
      "[NeMo I 2025-06-01 15:37:08 utils:554] Build and save the Evo2Dataset train indices\n"
     ]
    }
   ],
   "source": [
    "\n",
    "!train_evo2 \\\n",
    "    -d training_data_config.yaml \\\n",
    "    --dataset-dir {preprocessed_data} \\\n",
    "    --model-size 1b \\\n",
    "    --devices 1 \\\n",
    "    --num-nodes 1 \\\n",
    "    --seq-length 1 \\\n",
    "    --micro-batch-size 1 \\\n",
    "    --lr 0.0001 \\\n",
    "    --warmup-steps 5 \\\n",
    "    --max-steps 300000 \\\n",
    "    --ckpt-dir nemo2_evo2_1b_8k \\\n",
    "    --clip-grad 1 \\\n",
    "    --wd 0.01 \\\n",
    "    --activation-checkpoint-recompute-num-layers 1 \\\n",
    "    --val-check-interval 1000 \\\n",
    "    --ckpt-async-save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ad8f9c7-55d5-4876-9a7b-ab7720eb8c85",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import stat\n",
    "\n",
    "# 检查文件路径\n",
    "file_path = \"/usr/local/bin/train_evo2\"\n",
    "\n",
    "# 首先检查文件是否存在\n",
    "if os.path.exists(file_path):\n",
    "    print(f\"文件存在: {file_path}\")\n",
    "    \n",
    "    # 获取文件信息\n",
    "    file_stat = os.stat(file_path)\n",
    "    print(f\"文件大小: {file_stat.st_size} 字节\")\n",
    "    print(f\"文件权限: {stat.filemode(file_stat.st_mode)}\")\n",
    "    print(f\"是否可执行: {os.access(file_path, os.X_OK)}\")\n",
    "    \n",
    "    # 检查文件类型\n",
    "    with open(file_path, 'rb') as f:\n",
    "        first_bytes = f.read(100)\n",
    "        print(f\"文件开头字节: {first_bytes[:50]}\")\n",
    "        \n",
    "        # 检查是否是文本文件\n",
    "        try:\n",
    "            first_text = first_bytes.decode('utf-8')\n",
    "            print(\"这是一个文本文件\")\n",
    "            print(f\"文件开头内容: {first_text[:100]}...\")\n",
    "        except UnicodeDecodeError:\n",
    "            print(\"这是一个二进制文件\")\n",
    "    \n",
    "    # 如果是Python脚本，显示基本信息（不显示完整内容）\n",
    "    if file_path.endswith('.py') or 'python' in first_text.lower():\n",
    "        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            lines = f.readlines()\n",
    "            print(f\"\\n总行数: {len(lines)}\")\n",
    "            print(\"文件头部信息（前5行）:\")\n",
    "            for i, line in enumerate(lines[:100]):\n",
    "                print(f\"{i+1}: {line.rstrip()}\")\n",
    "else:\n",
    "    print(f\"文件不存在: {file_path}\")\n",
    "    \n",
    "    # 检查可能的替代路径\n",
    "    possible_paths = [\n",
    "        \"/usr/local/bin/train_evo2\",\n",
    "        \"/usr/local/lib/python3.12/dist-packages/bionemo/evo2/run/train.py\",\n",
    "        \"/usr/local/lib/python3.12/dist-packages/bionemo/evo2/train.py\"\n",
    "    ]\n",
    "    \n",
    "    print(\"\\n检查其他可能的路径:\")\n",
    "    for path in possible_paths:\n",
    "        if os.path.exists(path):\n",
    "            print(f\"✓ 找到: {path}\")\n",
    "        else:\n",
    "            print(f\"✗ 不存在: {path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b51390c9-cb5e-4016-b79a-80effcc109da",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BioNeMo Evo2 训练脚本内容查看器\n",
      "================================================================================\n",
      "================================================================================\n",
      "文件路径: /usr/local/lib/python3.12/dist-packages/bionemo/evo2/run/train.py\n",
      "================================================================================\n",
      "✓ 文件存在，正在读取内容...\n",
      "\n",
      "文件大小: 29121 字符\n",
      "行数: 717\n",
      "--------------------------------------------------------------------------------\n",
      "   1: # SPDX-FileCopyrightText: Copyright (c) 2024 NVIDIA CORPORATION & AFFILIATES. All rights reserved.\n",
      "   2: # SPDX-FileCopyrightText: Copyright (c) 2024 Arc Institute. All rights reserved.\n",
      "   3: # SPDX-FileCopyrightText: Copyright (c) 2024 Michael Poli. All rights reserved.\n",
      "   4: # SPDX-FileCopyrightText: Copyright (c) 2024 Stanford University. All rights reserved\n",
      "   5: # SPDX-License-Identifier: LicenseRef-Apache2\n",
      "   6: #\n",
      "   7: # Licensed under the Apache License, Version 2.0 (the \"License\");\n",
      "   8: # you may not use this file except in compliance with the License.\n",
      "   9: # You may obtain a copy of the License at\n",
      "  10: #\n",
      "  11: #     http://www.apache.org/licenses/LICENSE-2.0\n",
      "  12: #\n",
      "  13: # Unless required by applicable law or agreed to in writing, software\n",
      "  14: # distributed under the License is distributed on an \"AS IS\" BASIS,\n",
      "  15: # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
      "  16: # See the License for the specific language governing permissions and\n",
      "  17: # limitations under the License.\n",
      "  18: \n",
      "  19: import argparse\n",
      "  20: from pathlib import Path\n",
      "  21: from typing import List, Optional\n",
      "  22: \n",
      "  23: # TODO add back support for slurm resilience.\n",
      "  24: # import nvidia_resiliency_ext.ptl_resiliency as res_module\n",
      "  25: import torch\n",
      "  26: from lightning.pytorch.callbacks import LearningRateMonitor, RichModelSummary\n",
      "  27: from megatron.core.distributed import DistributedDataParallelConfig\n",
      "  28: from megatron.core.optimizer import OptimizerConfig\n",
      "  29: from nemo import lightning as nl\n",
      "  30: from nemo.collections import llm\n",
      "  31: from nemo.collections.llm.gpt.data import MockDataModule, PreTrainingDataModule\n",
      "  32: from nemo.collections.llm.gpt.data.megatron.hyena.config import parse_dataset_config\n",
      "  33: from nemo.collections.llm.gpt.data.megatron.hyena.evo2_dataset import Evo2Dataset, Evo2DatasetPadEodLossMask\n",
      "  34: from nemo.collections.llm.gpt.model.hyena import HYENA_MODEL_OPTIONS\n",
      "  35: from nemo.collections.llm.recipes.tp_overlap_configs.userbuffers import (\n",
      "  36:     userbuffers_bf16_h100_h8192_tp4_mbs1_seqlen8192,\n",
      "  37:     userbuffers_fp8_h100_h8192_tp4_mbs1_seqlen8192,\n",
      "  38: )\n",
      "  39: from nemo.collections.nlp.modules.common.tokenizer_utils import get_nmt_tokenizer\n",
      "  40: from nemo.lightning.pytorch import callbacks as nl_callbacks\n",
      "  41: from nemo.lightning.pytorch.callbacks import ModelCheckpoint\n",
      "  42: from nemo.lightning.pytorch.callbacks.flops_callback import FLOPsMeasurementCallback\n",
      "  43: from nemo.lightning.pytorch.callbacks.megatron_comm_overlap import MegatronCommOverlapCallback\n",
      "  44: from nemo.lightning.pytorch.optim import CosineAnnealingScheduler\n",
      "  45: from nemo.lightning.pytorch.optim.megatron import MegatronOptimizerModule\n",
      "  46: from nemo.lightning.pytorch.strategies.utils import RestoreConfig\n",
      "  47: from nemo.utils.exp_manager import TimingCallback\n",
      "  48: \n",
      "  49: from bionemo.llm.utils.datamodule_utils import infer_global_batch_size\n",
      "  50: from bionemo.llm.utils.logger_utils import WandbConfig, setup_nemo_lightning_logger\n",
      "  51: \n",
      "  52: \n",
      "  53: torch._dynamo.config.suppress_errors = True\n",
      "  54: \n",
      "  55: \n",
      "  56: def parse_args(args: Optional[List[str]] = None) -> argparse.Namespace:\n",
      "  57:     \"\"\"Parse arguments for Evo2 model training.\"\"\"\n",
      "  58:     parser = argparse.ArgumentParser(\n",
      "  59:         description=\"Train a Hyena model using NeMo 2.0.\",\n",
      "  60:         formatter_class=argparse.ArgumentDefaultsHelpFormatter,\n",
      "  61:     )\n",
      "  62:     data_group = parser.add_mutually_exclusive_group(required=True)\n",
      "  63: \n",
      "  64:     data_group.add_argument(\n",
      "  65:         \"-d\",\n",
      "  66:         \"--dataset-config\",\n",
      "  67:         type=str,\n",
      "  68:         help=\"Path to the blended / weighted training dataset configuration YAML.\",\n",
      "  69:     )\n",
      "  70:     data_group.add_argument(\n",
      "  71:         \"--mock-data\",\n",
      "  72:         action=\"store_true\",\n",
      "  73:         help=\"Train with Mock data (for testing/debugging), either set this or provide a dataset config.\",\n",
      "  74:     )\n",
      "  75: \n",
      "  76:     parser.add_argument(\n",
      "  77:         \"--dataset-dir\",\n",
      "  78:         type=str,\n",
      "  79:         help=\"Absolute path to the dataset directory. Defaults to using the absolute or relative paths (dataset_prefix) specified in the dataset config YAML.\",\n",
      "  80:     )\n",
      "  81: \n",
      "  82:     parser.add_argument(\"--num-nodes\", type=int, default=1, help=\"Number of nodes to use for training, defaults to 1.\")\n",
      "  83:     parser.add_argument(\"--devices\", type=int, default=1, help=\"Number of devices to use for training, defaults to 1.\")\n",
      "  84:     parser.add_argument(\"--seq-length\", type=int, default=8192, help=\"Training sequence length\")\n",
      "  85:     parser.add_argument(\n",
      "  86:         \"--tensor-parallel-size\", type=int, default=1, help=\"Order of tensor parallelism. Defaults to 1.\"\n",
      "  87:     )\n",
      "  88:     parser.add_argument(\n",
      "  89:         \"--pipeline-model-parallel-size\", type=int, default=1, help=\"Order of pipeline parallelism. Defaults to 1.\"\n",
      "  90:     )\n",
      "  91:     parser.add_argument(\n",
      "  92:         \"--context-parallel-size\", type=int, default=1, help=\"Order of context parallelism. Defaults to 1.\"\n",
      "  93:     )\n",
      "  94:     parser.add_argument(\n",
      "  95:         \"--create-tensorboard-logger\", action=\"store_true\", default=False, help=\"Create a tensorboard logger.\"\n",
      "  96:     )\n",
      "  97:     parser.add_argument(\"--wandb-entity\", type=str, default=None, help=\"The team posting this run\")\n",
      "  98:     parser.add_argument(\"--wandb-project\", type=str, default=None, help=\"Wandb project name \")\n",
      "  99:     parser.add_argument(\"--wandb-tags\", nargs=\"+\", type=str, default=None, help=\"Tags associated with this run\")\n",
      " 100:     parser.add_argument(\n",
      " 101:         \"--wandb-group\", type=str, default=None, help=\"A unique string shared by all runs in a given group\"\n",
      " 102:     )\n",
      " 103:     parser.add_argument(\n",
      " 104:         \"--wandb-job-type\",\n",
      " 105:         type=str,\n",
      " 106:         default=None,\n",
      " 107:         help=\"A unique string representing a type of run, which is useful when you're grouping runs together into larger experiments using group.\",\n",
      " 108:     )\n",
      " 109:     parser.add_argument(\n",
      " 110:         \"--wandb-run-name\",\n",
      " 111:         type=str,\n",
      " 112:         default=None,\n",
      " 113:         help=\"A unique string representing the name of the wandb run. If not provided, the name will be generated from the model and training specifications.\",\n",
      " 114:     )\n",
      " 115: \n",
      " 116:     parser.add_argument(\n",
      " 117:         \"--wandb-id\", type=str, default=None, help=\"Sets the version, mainly used to resume a previous run\"\n",
      " 118:     )\n",
      " 119:     parser.add_argument(\n",
      " 120:         \"--wandb-anonymous\", action=\"store_true\", help=\"Enable or explicitly disable anonymous logging\"\n",
      " 121:     )\n",
      " 122:     parser.add_argument(\n",
      " 123:         \"--wandb-log-model\", action=\"store_true\", help=\"Save checkpoints in wandb dir to upload on W&B servers\"\n",
      " 124:     )\n",
      " 125:     parser.add_argument(\"--wandb-offline\", action=\"store_true\", help=\"Use wandb in offline mode\")\n",
      " 126:     parser.add_argument(\"--sequence-parallel\", action=\"store_true\", help=\"Set to enable sequence parallelism.\")\n",
      " 127:     parser.add_argument(\"--fp8\", action=\"store_true\", help=\"Set to enable FP8\")\n",
      " 128:     parser.add_argument(\"--micro-batch-size\", type=int, default=1, help=\"Micro-batch size for data-parallel training.\")\n",
      " 129:     parser.add_argument(\n",
      " 130:         \"--global-batch-size\",\n",
      " 131:         type=int,\n",
      " 132:         default=None,\n",
      " 133:         help=\"Global batch size for training. If set to None, infer it from the TP, CP, and PP parameters.\",\n",
      " 134:     )\n",
      " 135:     parser.add_argument(\n",
      " 136:         \"--grad-acc-batches\", type=int, default=1, help=\"Number of batches to accumulate gradients over.\"\n",
      " 137:     )\n",
      " 138:     parser.add_argument(\n",
      " 139:         \"--max-steps\",\n",
      " 140:         type=int,\n",
      " 141:         help=\"Number of training optimizer update steps. This controls the total number of steps as well as the \"\n",
      " 142:         \"shape of the learning rate curve.\",\n",
      " 143:         default=500000,\n",
      " 144:     )\n",
      " 145:     parser.add_argument(\n",
      " 146:         \"--early-stop-on-step\",\n",
      " 147:         type=int,\n",
      " 148:         help=\"Stop training on this step, if set. This may be useful for testing or debugging purposes.\",\n",
      " 149:     )\n",
      " 150:     parser.add_argument(\n",
      " 151:         \"--val-check-interval\", type=int, help=\"Number of steps between validation measurements and model checkpoints.\"\n",
      " 152:     )\n",
      " 153:     parser.add_argument(\"--grad-reduce-in-fp32\", action=\"store_true\", default=False, help=\"Gradient reduce in FP32.\")\n",
      " 154:     parser.add_argument(\n",
      " 155:         \"--fp8-wgrad\",\n",
      " 156:         action=\"store_true\",\n",
      " 157:         default=False,\n",
      " 158:         help=\"Faster option that is maybe less accurate (TBD) when using fp8.\",\n",
      " 159:     )\n",
      " 160:     parser.add_argument(\"--use-megatron-comm-overlap-llama3-8k\", action=\"store_true\", default=False)\n",
      " 161:     parser.add_argument(\n",
      " 162:         \"--tp-comm-overlap-backend\",\n",
      " 163:         type=str,\n",
      " 164:         choices=[\"nccl\", \"mpi\", \"gloo\"],\n",
      " 165:         default=\"nccl\",\n",
      " 166:         help=\"TP communication backend to use. Defaults to 'nccl'.\",\n",
      " 167:     )\n",
      " 168:     parser.add_argument(\"--align-param-gather\", action=\"store_true\", default=False)\n",
      " 169:     # parser.add_argument(\"--straggler-detection\", action=\"store_true\", default=False)\n",
      " 170:     parser.add_argument(\n",
      " 171:         \"--model-size\",\n",
      " 172:         type=str,\n",
      " 173:         choices=sorted(HYENA_MODEL_OPTIONS.keys()),\n",
      " 174:         default=\"7b\",\n",
      " 175:         help=\"Model architecture to use, choose between 7b, 40b, or test (a sub-model of 4 layers, less than 1B \"\n",
      " 176:         \"parameters). '_arc_1m' models have GLU / FFN dimensions that support 1M context length when trained \"\n",
      " 177:         \"with TP<=8.\",\n",
      " 178:     )\n",
      " 179:     parser.add_argument(\n",
      " 180:         \"--add-bias-output\",\n",
      " 181:         action=\"store_true\",\n",
      " 182:         default=False,\n",
      " 183:         help=\"Add bias to the output layer to enable learning a simple prior.\",\n",
      " 184:     )\n",
      " 185:     parser.add_argument(\n",
      " 186:         \"--result-dir\", type=Path, required=False, default=Path(\"./results\"), help=\"Path to the result directory.\"\n",
      " 187:     )\n",
      " 188:     parser.add_argument(\"--experiment-name\", type=str, required=False, default=\"evo2\", help=\"Name of the experiment.\")\n",
      " 189: \n",
      " 190:     parser.add_argument(\n",
      " 191:         \"--limit-val-batches\",\n",
      " 192:         type=int,\n",
      " 193:         default=20,\n",
      " 194:         help=\"Number of validation steps\",\n",
      " 195:     )\n",
      " 196:     parser.add_argument(\n",
      " 197:         \"--log-every-n-steps\",\n",
      " 198:         type=int,\n",
      " 199:         default=1,\n",
      " 200:         required=False,\n",
      " 201:         help=\"Number of steps between logging.\",\n",
      " 202:     )\n",
      " 203:     parser.add_argument(\n",
      " 204:         \"--ckpt-dir\",\n",
      " 205:         type=str,\n",
      " 206:         default=None,\n",
      " 207:         help=\"Directory to restore an initial checkpoint from. Use this for supervised fine-tuning.\",\n",
      " 208:     )\n",
      " 209:     parser.add_argument(\"--wd\", type=float, default=0.01, help=\"Weight decay for optimizer.\")\n",
      " 210:     parser.add_argument(\n",
      " 211:         \"--restore-optimizer-from-ckpt\",\n",
      " 212:         action=\"store_true\",\n",
      " 213:         help=\"Restore optimizer state from initial checkpoint. Defaults to False.\",\n",
      " 214:     )\n",
      " 215:     parser.add_argument(\n",
      " 216:         \"--no-average-in-collective\",\n",
      " 217:         action=\"store_true\",\n",
      " 218:         default=False,\n",
      " 219:         help=\"Avaerage optimizer state in collective rather than dividing by dp size and summing.\",\n",
      " 220:     )\n",
      " 221:     parser.add_argument(\"--seed\", type=int, default=1234, help=\"Set random seed for training.\")\n",
      " 222:     parser.add_argument(\"--workers\", type=int, default=8, help=\"Number of workers to use for data loading.\")\n",
      " 223:     parser.add_argument(\n",
      " 224:         \"--gc-interval\",\n",
      " 225:         type=int,\n",
      " 226:         default=0,\n",
      " 227:         help=\"Set to a value > 0 if you want to synchronize garbage collection, will do gc every gc-interval steps.\",\n",
      " 228:     )\n",
      " 229:     parser.add_argument(\n",
      " 230:         \"--enable-preemption\",\n",
      " 231:         action=\"store_true\",\n",
      " 232:         default=False,\n",
      " 233:         help=\"Enable preemption hooks. If enabled this will save a checkpoint whenever slurm exits.\",\n",
      " 234:     )\n",
      " 235:     parser.add_argument(\n",
      " 236:         \"--ckpt-async-save\",\n",
      " 237:         action=\"store_true\",\n",
      " 238:         default=False,\n",
      " 239:     )\n",
      " 240:     parser.add_argument(\n",
      " 241:         \"--ckpt-format\",\n",
      " 242:         type=str,\n",
      " 243:         choices=[\"torch_dist\", \"zarr\"],\n",
      " 244:         default=\"torch_dist\",\n",
      " 245:         help=\"Specify checkpoint format to use. Defaults to 'torch_dist', as 'zarr' is deprecated. Only use if \"\n",
      " 246:         \"resuming training from a zarr checkpoint.\",\n",
      " 247:     )\n",
      " 248:     parser.add_argument(\n",
      " 249:         \"--eod-pad-in-loss-mask\",\n",
      " 250:         action=\"store_true\",\n",
      " 251:         default=False,\n",
      " 252:         help=\"Do not predict EOD/Pad tokens (typical default, but not default in original evo2).\",\n",
      " 253:     )\n",
      " 254:     parser.add_argument(\n",
      " 255:         \"--cross-entropy-loss-fusion\",\n",
      " 256:         action=\"store_true\",\n",
      " 257:         default=False,\n",
      " 258:         help=\"Use the faster, but maybe less accurate fused form of cross entropy, \"\n",
      " 259:         \"which also has bf16 grads internally.\",\n",
      " 260:     )\n",
      " 261:     parser.add_argument(\n",
      " 262:         \"--no-fp32-residual-connection\",\n",
      " 263:         action=\"store_true\",\n",
      " 264:         default=False,\n",
      " 265:         help=\"If set, turn off fp32 residual connections which may be faster but may impact accuracy.\",\n",
      " 266:     )\n",
      " 267:     parser.add_argument(\n",
      " 268:         \"--debug-ddp-parity-freq\",\n",
      " 269:         type=int,\n",
      " 270:         default=0,\n",
      " 271:         help=\"Set to value > 0 to debug DDP weight parity between ranks.\",\n",
      " 272:     )\n",
      " 273:     parser.add_argument(\n",
      " 274:         \"--hybrid-override-pattern\",\n",
      " 275:         type=str,\n",
      " 276:         help=\"Override the hybrid override pattern in the config (specifies hyena layer ordering and type).\",\n",
      " 277:     )\n",
      " 278:     parser.add_argument(\n",
      " 279:         \"--num-layers\", type=int, help=\"If set, override the number of layers specified in the requested config.\"\n",
      " 280:     )\n",
      " 281:     parser.add_argument(\n",
      " 282:         \"--create-tflops-callback\",\n",
      " 283:         action=\"store_true\",\n",
      " 284:         default=False,\n",
      " 285:         help=\"Enable tflops calculation callback for Hyena / Evo2. Defaults to False.\",\n",
      " 286:     )\n",
      " 287:     parser.add_argument(\n",
      " 288:         \"--log-parameters-and-shapes\",\n",
      " 289:         action=\"store_true\",\n",
      " 290:         default=False,\n",
      " 291:         help=\"Log training parameters shapes and dtypes for debugging.\",\n",
      " 292:     )\n",
      " 293:     parser.add_argument(\"--lr\", type=float, default=3e-4, help=\"Learning rate.\")\n",
      " 294:     parser.add_argument(\"--min-lr\", type=float, default=3e-5, help=\"Min learning rate in cosine annealing.\")\n",
      " 295:     parser.add_argument(\"--warmup-steps\", type=int, default=2500, help=\"Number of warmup steps in cosine annealing\")\n",
      " 296:     # NSYS profiling/tooling arguments\n",
      " 297:     parser.add_argument(\n",
      " 298:         \"--nsys-profiling\",\n",
      " 299:         action=\"store_true\",\n",
      " 300:         default=False,\n",
      " 301:         help=\"Enable targeted `nsys` profiling on the training loop for a defined step range. To actually get profiling\"\n",
      " 302:         \" output you must run the whole program with `nsys`. For example: \"\n",
      " 303:         \" `nsys profile -s none -o output_report_name -t cuda,nvtx --force-overwrite true \"\n",
      " 304:         \"--capture-range=cudaProfilerApi --capture-range-end=stop  [regular python command here]`\",\n",
      " 305:     )\n",
      " 306:     # start, end, rank\n",
      " 307:     parser.add_argument(\n",
      " 308:         \"--nsys-start-step\",\n",
      " 309:         type=int,\n",
      " 310:         required=False,\n",
      " 311:         default=0,\n",
      " 312:         help=\"Start nsys profiling after this step.\",\n",
      " 313:     )\n",
      " 314:     parser.add_argument(\n",
      " 315:         \"--nsys-end-step\",\n",
      " 316:         type=int,\n",
      " 317:         required=False,\n",
      " 318:         help=\"End nsys profiling after this step.\",\n",
      " 319:     )\n",
      " 320:     parser.add_argument(\n",
      " 321:         \"--no-renormalize-loss\",\n",
      " 322:         action=\"store_true\",\n",
      " 323:         default=False,\n",
      " 324:         help=\"Do not renormalize the loss weights.\",\n",
      " 325:     )\n",
      " 326:     # rank as list of integers\n",
      " 327:     parser.add_argument(\n",
      " 328:         \"--nsys-ranks\",\n",
      " 329:         type=int,\n",
      " 330:         nargs=\"+\",\n",
      " 331:         required=False,\n",
      " 332:         default=[0],\n",
      " 333:         help=\"Enable nsys profiling for these ranks.\",\n",
      " 334:     )\n",
      " 335:     parser.add_argument(\n",
      " 336:         \"--activation-checkpoint-recompute-num-layers\",\n",
      " 337:         type=int,\n",
      " 338:         help=\"If set, override the default value set in the config.\",\n",
      " 339:     )\n",
      " 340:     parser.add_argument(\n",
      " 341:         \"--disable-checkpointing\",\n",
      " 342:         action=\"store_false\",\n",
      " 343:         default=True,\n",
      " 344:         dest=\"create_checkpoint_callback\",\n",
      " 345:         help=\"Disable creating a ModelCheckpoint callback.\",\n",
      " 346:     )\n",
      " 347:     parser.add_argument(\n",
      " 348:         \"--clip-grad\",\n",
      " 349:         type=float,\n",
      " 350:         default=1.0,\n",
      " 351:         help=\"Grad clip value. Note that when using DDP this may need to be inflated.\",\n",
      " 352:     )\n",
      " 353:     parser.add_argument(\n",
      " 354:         \"--seq-len-interpolation-factor\",\n",
      " 355:         type=float,\n",
      " 356:         help=\"Adjusts the linear scaling of ROPE (Rotary Position Embedding) for context extension. \"\n",
      " 357:         \"Set this factor relative to your base context length e.g., for an original context length of 8192 and \"\n",
      " 358:         \"an extended context length of 524288, use 524288/8192 = 64.\",\n",
      " 359:     )\n",
      " 360:     parser.add_argument(\n",
      " 361:         \"--overlap-param-gather\",\n",
      " 362:         action=\"store_true\",\n",
      " 363:         default=False,\n",
      " 364:         help=\"Overlap the parameter gather with the optimizer step. This is currently disabled due to a NeMo bug \"\n",
      " 365:         \"when using DDP. Making this an option defaulting to False is a temporary solution until the bug is fixed.\",\n",
      " 366:     )\n",
      " 367:     parser.add_argument(\n",
      " 368:         \"--overlap-grad-reduce\",\n",
      " 369:         action=\"store_true\",\n",
      " 370:         default=False,\n",
      " 371:         help=\"Overlap the gradient reduce with the optimizer step.\",\n",
      " 372:     )\n",
      " 373:     parser.add_argument(\n",
      " 374:         \"--hidden-dropout\",\n",
      " 375:         type=float,\n",
      " 376:         default=0.0,\n",
      " 377:         help=\"Dropout probability for the hyena layers\",\n",
      " 378:     )\n",
      " 379:     parser.add_argument(\n",
      " 380:         \"--attention-dropout\",\n",
      " 381:         type=float,\n",
      " 382:         default=0.0,\n",
      " 383:         help=\"Dropout probability for the attention layers.\",\n",
      " 384:     )\n",
      " 385:     recompute_group = parser.add_mutually_exclusive_group(required=False)\n",
      " 386:     recompute_group.add_argument(\"--no-activation-checkpointing\", action=\"store_true\", default=False)\n",
      " 387:     recompute_group.add_argument(\"--selective-activation-checkpointing\", action=\"store_true\", default=False)\n",
      " 388:     return parser.parse_args(args=args)\n",
      " 389: \n",
      " 390: \n",
      " 391: def train(args: argparse.Namespace) -> nl.Trainer:\n",
      " 392:     \"\"\"Main function to run Evo2 training.\"\"\"\n",
      " 393:     # Instantiate tokenizer.\n",
      " 394:     tokenizer = get_nmt_tokenizer(\n",
      " 395:         \"byte-level\",\n",
      " 396:     )\n",
      " 397: \n",
      " 398:     # Infer global batch size.\n",
      " 399:     global_batch_size = args.global_batch_size\n",
      " 400:     if global_batch_size is None:\n",
      " 401:         global_batch_size = infer_global_batch_size(\n",
      " 402:             micro_batch_size=args.micro_batch_size,\n",
      " 403:             num_nodes=args.num_nodes,\n",
      " 404:             devices=args.devices,\n",
      " 405:             accumulate_grad_batches=args.grad_acc_batches,\n",
      " 406:             tensor_model_parallel_size=args.tensor_parallel_size,\n",
      " 407:             pipeline_model_parallel_size=args.pipeline_model_parallel_size,\n",
      " 408:             context_model_parallel_size=args.context_parallel_size,\n",
      " 409:         )\n",
      " 410:     if args.mock_data:\n",
      " 411:         data_module = MockDataModule(\n",
      " 412:             seq_length=args.seq_length,\n",
      " 413:             micro_batch_size=args.micro_batch_size,\n",
      " 414:             global_batch_size=global_batch_size,\n",
      " 415:             num_workers=args.workers,\n",
      " 416:             tokenizer=tokenizer,\n",
      " 417:         )\n",
      " 418:     else:\n",
      " 419:         blended_dataset_config = parse_dataset_config(\n",
      " 420:             dataset_config_path=args.dataset_config, dataset_path=args.dataset_dir\n",
      " 421:         )\n",
      " 422:         dataset_cls = Evo2DatasetPadEodLossMask if args.eod_pad_in_loss_mask else Evo2Dataset\n",
      " 423:         # Instantiate pre-training module.\n",
      " 424:         data_module = PreTrainingDataModule(\n",
      " 425:             paths=blended_dataset_config,\n",
      " 426:             dataset_cls=dataset_cls,\n",
      " 427:             seq_length=args.seq_length,\n",
      " 428:             micro_batch_size=args.micro_batch_size,\n",
      " 429:             global_batch_size=global_batch_size,\n",
      " 430:             seed=args.seed,\n",
      " 431:             num_workers=args.workers,\n",
      " 432:             tokenizer=tokenizer,\n",
      " 433:             eod_mask_loss=args.eod_pad_in_loss_mask,\n",
      " 434:         )\n",
      " 435: \n",
      " 436:     if args.no_activation_checkpointing:\n",
      " 437:         activation_checkpointing_args = {\n",
      " 438:             \"recompute_granularity\": None,\n",
      " 439:             \"recompute_method\": None,\n",
      " 440:             \"recompute_num_layers\": None,\n",
      " 441:         }\n",
      " 442:     elif args.selective_activation_checkpointing:\n",
      " 443:         activation_checkpointing_args = {\n",
      " 444:             \"recompute_granularity\": \"selective\",\n",
      " 445:             \"recompute_method\": None,\n",
      " 446:             \"recompute_num_layers\": None,\n",
      " 447:         }\n",
      " 448:     else:\n",
      " 449:         if args.activation_checkpoint_recompute_num_layers is not None:\n",
      " 450:             activation_checkpointing_args = {\n",
      " 451:                 \"recompute_num_layers\": args.activation_checkpoint_recompute_num_layers,\n",
      " 452:             }\n",
      " 453:         else:\n",
      " 454:             activation_checkpointing_args = {}\n",
      " 455: \n",
      " 456:     # Retrieve model config.\n",
      " 457:     config_modifiers_init = {\n",
      " 458:         \"tp_comm_overlap\": args.use_megatron_comm_overlap_llama3_8k,\n",
      " 459:         \"seq_length\": args.seq_length,\n",
      " 460:         \"hidden_dropout\": args.hidden_dropout,\n",
      " 461:         \"attention_dropout\": args.attention_dropout,\n",
      " 462:         \"to_upper\": \"weighted\" if args.no_renormalize_loss else \"normalized_weighted\",\n",
      " 463:         \"distribute_saved_activations\": False if args.sequence_parallel else True,\n",
      " 464:         \"cross_entropy_loss_fusion\": args.cross_entropy_loss_fusion,\n",
      " 465:         \"fp32_residual_connection\": not args.no_fp32_residual_connection,\n",
      " 466:         \"add_bias_output\": args.add_bias_output,\n",
      " 467:         **activation_checkpointing_args,\n",
      " 468:     }\n",
      " 469:     if args.hybrid_override_pattern:\n",
      " 470:         config_modifiers_init[\"hybrid_override_pattern\"] = args.hybrid_override_pattern\n",
      " 471:     if args.num_layers:\n",
      " 472:         config_modifiers_init[\"num_layers\"] = args.num_layers\n",
      " 473: \n",
      " 474:     if args.model_size not in HYENA_MODEL_OPTIONS:\n",
      " 475:         raise ValueError(f\"Invalid model size: {args.model_size}\")\n",
      " 476:     evo2_config = HYENA_MODEL_OPTIONS[args.model_size](**config_modifiers_init)\n",
      " 477: \n",
      " 478:     # Instantiate model.\n",
      " 479:     model = llm.HyenaModel(evo2_config, tokenizer=data_module.tokenizer)\n",
      " 480: \n",
      " 481:     # Setup callbacks.\n",
      " 482:     callbacks = [\n",
      " 483:         RichModelSummary(max_depth=4),\n",
      " 484:         LearningRateMonitor(),\n",
      " 485:         TimingCallback(),\n",
      " 486:     ]\n",
      " 487: \n",
      " 488:     if args.enable_preemption:\n",
      " 489:         callbacks.append(nl_callbacks.PreemptionCallback())\n",
      " 490:     if args.debug_ddp_parity_freq > 0:\n",
      " 491:         callbacks.append(nl_callbacks.DdpParityChecker(interval=args.debug_ddp_parity_freq))\n",
      " 492:     if args.log_parameters_and_shapes:\n",
      " 493:         callbacks.append(nl_callbacks.ParameterDebugger())\n",
      " 494:     if args.create_tflops_callback:\n",
      " 495:         # Add callback that logs the tera-FLOPS per second per GPU during training.\n",
      " 496:         flop_meas_callback = FLOPsMeasurementCallback(\n",
      " 497:             evo2_config,\n",
      " 498:             data_module,\n",
      " 499:             \"hyena\",\n",
      " 500:         )\n",
      " 501:         callbacks.append(flop_meas_callback)\n",
      " 502: \n",
      " 503:     # TODO(@cye): Add this back when it works with 24.12.\n",
      " 504:     # if args.straggler_detection:\n",
      " 505:     #     callbacks.append(\n",
      " 506:     #         res_module.StragglerDetectionCallback(\n",
      " 507:     #             report_time_interval=300,\n",
      " 508:     #             calc_relative_gpu_perf=True,\n",
      " 509:     #             calc_individual_gpu_perf=True,\n",
      " 510:     #             num_gpu_perf_scores_to_print=5,\n",
      " 511:     #             gpu_relative_perf_threshold=0.7,\n",
      " 512:     #             gpu_individual_perf_threshold=0.7,\n",
      " 513:     #             stop_if_detected=True,\n",
      " 514:     #             enable_ptl_logging=True,\n",
      " 515:     #         )\n",
      " 516:     #     )\n",
      " 517:     if args.use_megatron_comm_overlap_llama3_8k:\n",
      " 518:         # Pick the floating point appropriate config.\n",
      " 519:         if args.fp8:\n",
      " 520:             tp_comm_overlap_cfg = userbuffers_fp8_h100_h8192_tp4_mbs1_seqlen8192\n",
      " 521:         else:\n",
      " 522:             tp_comm_overlap_cfg = userbuffers_bf16_h100_h8192_tp4_mbs1_seqlen8192\n",
      " 523:         callbacks.append(\n",
      " 524:             MegatronCommOverlapCallback(\n",
      " 525:                 tp_comm_overlap=evo2_config.tp_comm_overlap,\n",
      " 526:                 tp_comm_overlap_cfg=tp_comm_overlap_cfg,\n",
      " 527:                 tp_comm_bootstrap_backend=args.tp_comm_overlap_backend,\n",
      " 528:                 wgrad_deferral_limit=22,  # default from NeMo\n",
      " 529:                 overlap_param_gather_with_optimizer_step=False,  # Currently disabled due to an issue with checkpointing.\n",
      " 530:                 align_param_gather=args.align_param_gather,\n",
      " 531:             )\n",
      " 532:         )\n",
      " 533: \n",
      " 534:     if args.gc_interval > 0:\n",
      " 535:         callbacks.append(\n",
      " 536:             nl_callbacks.GarbageCollectionCallback(\n",
      " 537:                 gc_interval_train=args.gc_interval, gc_interval_val=args.gc_interval\n",
      " 538:             )\n",
      " 539:         )\n",
      " 540:     if args.nsys_profiling:\n",
      " 541:         if args.nsys_end_step is None:\n",
      " 542:             nsys_end_step = args.max_steps\n",
      " 543:         else:\n",
      " 544:             nsys_end_step = args.nsys_end_step\n",
      " 545:         callbacks.append(\n",
      " 546:             nl_callbacks.NsysCallback(\n",
      " 547:                 start_step=args.nsys_start_step, end_step=nsys_end_step, ranks=args.nsys_ranks, gen_shape=True\n",
      " 548:             )\n",
      " 549:         )\n",
      " 550: \n",
      " 551:     wandb_run_name = (\n",
      " 552:         f\"evo2-size-{args.model_size}-TP{args.tensor_parallel_size}-\"\n",
      " 553:         f\"PP{args.pipeline_model_parallel_size}-CP{args.context_parallel_size}\"\n",
      " 554:         f\"-GBS{global_batch_size}-MBS{args.micro_batch_size}-SkipLossRenorm{args.no_renormalize_loss}\"\n",
      " 555:         f\"-NOAC{args.no_activation_checkpointing}-SELAC{args.selective_activation_checkpointing}\"\n",
      " 556:         f\"-ACRNL{evo2_config.recompute_num_layers}\"\n",
      " 557:         f\"-PAT{evo2_config.hybrid_override_pattern}\"\n",
      " 558:         f\"-F32R{evo2_config.fp32_residual_connection}\"\n",
      " 559:         f\"-FCE{evo2_config.cross_entropy_loss_fusion}\"\n",
      " 560:         f\"-AIC{not args.no_average_in_collective}\"\n",
      " 561:         f\"-PEOD{args.eod_pad_in_loss_mask}\"\n",
      " 562:         f\"-BO{args.add_bias_output}\"\n",
      " 563:         f\"-GCLP{args.clip_grad}\"\n",
      " 564:         f\"-HDO{args.hidden_dropout}\"\n",
      " 565:         f\"-ADO{args.attention_dropout}\"\n",
      " 566:         f\"-LR{args.lr}-MINLR{args.min_lr}-WUSTEPS{args.warmup_steps}-WD{args.wd}\"\n",
      " 567:         f\"-GRFP32{args.grad_reduce_in_fp32}-FP8WG{args.fp8_wgrad and args.fp8}\"\n",
      " 568:         f\"-OGR{args.overlap_grad_reduce}-OPG{args.overlap_param_gather}\"\n",
      " 569:         f\"-NODES{args.num_nodes}-FP8{args.fp8}\"\n",
      " 570:     )\n",
      " 571: \n",
      " 572:     wandb_config: Optional[WandbConfig] = (\n",
      " 573:         None\n",
      " 574:         if args.wandb_project is None\n",
      " 575:         else WandbConfig(\n",
      " 576:             offline=args.wandb_offline,\n",
      " 577:             project=args.wandb_project,\n",
      " 578:             name=args.wandb_run_name if args.wandb_run_name is not None else wandb_run_name,\n",
      " 579:             entity=args.wandb_entity,\n",
      " 580:             tags=args.wandb_tags,\n",
      " 581:             group=args.wandb_group,\n",
      " 582:             job_type=args.wandb_job_type,\n",
      " 583:             id=args.wandb_id,\n",
      " 584:             anonymous=args.wandb_anonymous,\n",
      " 585:             log_model=args.wandb_log_model,\n",
      " 586:         )\n",
      " 587:     )\n",
      " 588:     nemo_logger = setup_nemo_lightning_logger(\n",
      " 589:         root_dir=args.result_dir,\n",
      " 590:         name=args.experiment_name,\n",
      " 591:         initialize_tensorboard_logger=args.create_tensorboard_logger,\n",
      " 592:         wandb_config=wandb_config,\n",
      " 593:     )\n",
      " 594: \n",
      " 595:     if args.create_checkpoint_callback:\n",
      " 596:         checkpoint_path = str(Path(nemo_logger.save_dir) / \"checkpoints\")\n",
      " 597:         checkpoint_callback = ModelCheckpoint(\n",
      " 598:             every_n_train_steps=args.val_check_interval,\n",
      " 599:             dirpath=checkpoint_path,\n",
      " 600:             save_top_k=5,\n",
      " 601:             always_save_context=True,\n",
      " 602:             save_optim_on_train_end=True,\n",
      " 603:             save_context_on_train_end=True,\n",
      " 604:         )\n",
      " 605:         callbacks.append(checkpoint_callback)\n",
      " 606: \n",
      " 607:         auto_resume = nl.AutoResume(\n",
      " 608:             resume_if_exists=True,\n",
      " 609:             resume_ignore_no_checkpoint=True,\n",
      " 610:             resume_past_end=False,\n",
      " 611:             resume_from_directory=checkpoint_path,\n",
      " 612:             restore_config=(\n",
      " 613:                 RestoreConfig(\n",
      " 614:                     path=args.ckpt_dir,\n",
      " 615:                     load_model_state=True,\n",
      " 616:                     load_optim_state=args.restore_optimizer_from_ckpt,\n",
      " 617:                 )\n",
      " 618:                 if args.ckpt_dir\n",
      " 619:                 else None\n",
      " 620:             ),\n",
      " 621:         )\n",
      " 622:     else:\n",
      " 623:         auto_resume = None\n",
      " 624: \n",
      " 625:     ddp: DistributedDataParallelConfig = DistributedDataParallelConfig(\n",
      " 626:         check_for_nan_in_grad=True,\n",
      " 627:         overlap_grad_reduce=args.overlap_grad_reduce,\n",
      " 628:         overlap_param_gather=args.overlap_param_gather,  # Verify that this works using\n",
      " 629:         grad_reduce_in_fp32=args.grad_reduce_in_fp32,\n",
      " 630:         align_param_gather=args.align_param_gather,\n",
      " 631:         average_in_collective=not args.no_average_in_collective,\n",
      " 632:     )\n",
      " 633:     # Initialize Megatron Strategy and Trainer.\n",
      " 634:     strategy = nl.MegatronStrategy(\n",
      " 635:         ddp=ddp,\n",
      " 636:         tensor_model_parallel_size=args.tensor_parallel_size,\n",
      " 637:         pipeline_model_parallel_size=args.pipeline_model_parallel_size,\n",
      " 638:         context_parallel_size=args.context_parallel_size,\n",
      " 639:         pipeline_dtype=torch.bfloat16,\n",
      " 640:         sequence_parallel=args.sequence_parallel,\n",
      " 641:         ckpt_load_optimizer=True,\n",
      " 642:         ckpt_save_optimizer=True,\n",
      " 643:         ckpt_async_save=args.ckpt_async_save,\n",
      " 644:         save_ckpt_format=args.ckpt_format,\n",
      " 645:         ckpt_load_strictness=\"log_all\",  # or rebasing to https://github.com/NVIDIA/NeMo/pull/11988/files#diff-7667eae242a8ef776bff78cd08e79bc81df4896a450f0a781f6ed317a3dfb7ffR139\n",
      " 646:     )\n",
      " 647:     trainer = nl.Trainer(\n",
      " 648:         devices=args.devices,\n",
      " 649:         num_nodes=args.num_nodes,\n",
      " 650:         max_steps=args.max_steps if args.early_stop_on_step is None else args.early_stop_on_step,\n",
      " 651:         accelerator=\"gpu\",\n",
      " 652:         strategy=strategy,\n",
      " 653:         callbacks=callbacks,\n",
      " 654:         log_every_n_steps=args.log_every_n_steps,\n",
      " 655:         limit_val_batches=args.limit_val_batches,\n",
      " 656:         num_sanity_val_steps=0,\n",
      " 657:         use_distributed_sampler=False,\n",
      " 658:         plugins=nl.MegatronMixedPrecision(\n",
      " 659:             precision=\"bf16-mixed\",\n",
      " 660:             params_dtype=torch.bfloat16,\n",
      " 661:             grad_reduce_in_fp32=args.grad_reduce_in_fp32,\n",
      " 662:             fp8=\"hybrid\" if args.fp8 else None,\n",
      " 663:             fp8_amax_history_len=16 if args.fp8 else 1,\n",
      " 664:             fp8_amax_compute_algo=\"max\" if args.fp8 else \"most_recent\",\n",
      " 665:             fp8_wgrad=args.fp8\n",
      " 666:             and (\n",
      " 667:                 args.fp8_wgrad or args.use_megatron_comm_overlap_llama3_8k\n",
      " 668:             ),  # faster and less accurate when set to True, and MUST be True if using TP communication overlap\n",
      " 669:         ),\n",
      " 670:         val_check_interval=args.val_check_interval,\n",
      " 671:         enable_checkpointing=args.create_checkpoint_callback,\n",
      " 672:     )\n",
      " 673: \n",
      " 674:     # Logger setup\n",
      " 675:     nemo_logger.setup(\n",
      " 676:         trainer,\n",
      " 677:         resume_if_exists=True,\n",
      " 678:     )\n",
      " 679: \n",
      " 680:     if auto_resume is not None:\n",
      " 681:         auto_resume.setup(trainer, model)\n",
      " 682: \n",
      " 683:     # Optimizer and scheduler setup\n",
      " 684:     opt_config = OptimizerConfig(\n",
      " 685:         optimizer=\"adam\",\n",
      " 686:         lr=args.lr,\n",
      " 687:         adam_beta1=0.9,\n",
      " 688:         adam_beta2=0.95,\n",
      " 689:         weight_decay=args.wd,\n",
      " 690:         clip_grad=args.clip_grad,\n",
      " 691:         use_distributed_optimizer=True,\n",
      " 692:         bf16=True,\n",
      " 693:     )\n",
      " 694: \n",
      " 695:     sched = CosineAnnealingScheduler(\n",
      " 696:         max_steps=trainer.max_steps,\n",
      " 697:         warmup_steps=args.warmup_steps,\n",
      " 698:         min_lr=args.min_lr,\n",
      " 699:     )\n",
      " 700: \n",
      " 701:     opt = MegatronOptimizerModule(opt_config, sched, no_weight_decay_cond=evo2_config.hyena_no_weight_decay_cond_fn)\n",
      " 702:     opt.connect(model)\n",
      " 703: \n",
      " 704:     # Start training\n",
      " 705:     trainer.fit(model, data_module)\n",
      " 706:     return trainer\n",
      " 707: \n",
      " 708: \n",
      " 709: def main():\n",
      " 710:     \"\"\"Parsing args and running evo2 training.\"\"\"\n",
      " 711:     args = parse_args()\n",
      " 712:     train(args=args)\n",
      " 713: \n",
      " 714: \n",
      " 715: if __name__ == \"__main__\":\n",
      " 716:     main()\n",
      " 717: \n",
      "--------------------------------------------------------------------------------\n",
      "✓ 文件内容已打印完成\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "打印 BioNeMo Evo2 训练脚本内容\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "def print_file_content():\n",
    "    \"\"\"打印指定文件的内容\"\"\"\n",
    "    \n",
    "    file_path = \"/usr/local/lib/python3.12/dist-packages/bionemo/evo2/run/train.py\"\n",
    "    \n",
    "    print(\"=\" * 80)\n",
    "    print(f\"文件路径: {file_path}\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    try:\n",
    "        # 检查文件是否存在\n",
    "        if not os.path.exists(file_path):\n",
    "            print(f\"❌ 文件不存在: {file_path}\")\n",
    "            \n",
    "            # 尝试查找类似的文件\n",
    "            print(\"\\n正在搜索相关文件...\")\n",
    "            base_dir = \"/usr/local/lib/python3.12/dist-packages/\"\n",
    "            \n",
    "            if os.path.exists(base_dir):\n",
    "                print(f\"✓ 基础目录存在: {base_dir}\")\n",
    "                \n",
    "                # 搜索 bionemo 相关目录\n",
    "                for root, dirs, files in os.walk(base_dir):\n",
    "                    if \"bionemo\" in root.lower():\n",
    "                        print(f\"找到相关目录: {root}\")\n",
    "                        if \"train.py\" in files:\n",
    "                            print(f\"  -> 包含 train.py: {os.path.join(root, 'train.py')}\")\n",
    "            else:\n",
    "                print(f\"❌ 基础目录不存在: {base_dir}\")\n",
    "            \n",
    "            return False\n",
    "        \n",
    "        # 读取并打印文件内容\n",
    "        print(f\"✓ 文件存在，正在读取内容...\\n\")\n",
    "        \n",
    "        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            content = f.read()\n",
    "        \n",
    "        # 打印文件信息\n",
    "        lines = content.split('\\n')\n",
    "        print(f\"文件大小: {len(content)} 字符\")\n",
    "        print(f\"行数: {len(lines)}\")\n",
    "        print(\"-\" * 80)\n",
    "        \n",
    "        # 打印内容（带行号）\n",
    "        for i, line in enumerate(lines, 1):\n",
    "            print(f\"{i:4d}: {line}\")\n",
    "        \n",
    "        print(\"-\" * 80)\n",
    "        print(\"✓ 文件内容已打印完成\")\n",
    "        return True\n",
    "        \n",
    "    except PermissionError:\n",
    "        print(f\"❌ 权限不足，无法读取文件: {file_path}\")\n",
    "        print(\"请尝试使用 sudo 运行此脚本\")\n",
    "        return False\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ 读取文件时发生错误: {e}\")\n",
    "        return False\n",
    "\n",
    "def search_alternative_paths():\n",
    "    \"\"\"搜索可能的替代路径\"\"\"\n",
    "    \n",
    "    potential_paths = [\n",
    "        \"/usr/local/lib/python3.12/dist-packages/bionemo/evo2/run/train.py\",\n",
    "        \"/usr/local/lib/python3.11/dist-packages/bionemo/evo2/run/train.py\",\n",
    "        \"/usr/lib/python3.12/dist-packages/bionemo/evo2/run/train.py\",\n",
    "        \"/usr/lib/python3.11/dist-packages/bionemo/evo2/run/train.py\",\n",
    "    ]\n",
    "    \n",
    "    # 也检查当前用户的site-packages\n",
    "    import site\n",
    "    user_site = site.getusersitepackages()\n",
    "    if user_site:\n",
    "        potential_paths.append(f\"{user_site}/bionemo/evo2/run/train.py\")\n",
    "    \n",
    "    print(\"\\n搜索可能的路径:\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    found_files = []\n",
    "    for path in potential_paths:\n",
    "        if os.path.exists(path):\n",
    "            print(f\"✓ 找到: {path}\")\n",
    "            found_files.append(path)\n",
    "        else:\n",
    "            print(f\"✗ 不存在: {path}\")\n",
    "    \n",
    "    return found_files\n",
    "\n",
    "def main():\n",
    "    \"\"\"主函数\"\"\"\n",
    "    print(\"BioNeMo Evo2 训练脚本内容查看器\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    # 首先尝试打印目标文件\n",
    "    success = print_file_content()\n",
    "    \n",
    "    if not success:\n",
    "        # 如果失败，搜索替代路径\n",
    "        found_files = search_alternative_paths()\n",
    "        \n",
    "        if found_files:\n",
    "            print(f\"\\n找到 {len(found_files)} 个相关文件。\")\n",
    "            for i, file_path in enumerate(found_files, 1):\n",
    "                print(f\"\\n{i}. 正在打印: {file_path}\")\n",
    "                print(\"=\" * 80)\n",
    "                \n",
    "                try:\n",
    "                    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "                        content = f.read()\n",
    "                    \n",
    "                    lines = content.split('\\n')\n",
    "                    print(f\"文件大小: {len(content)} 字符\")\n",
    "                    print(f\"行数: {len(lines)}\")\n",
    "                    print(\"-\" * 80)\n",
    "                    \n",
    "                    for line_num, line in enumerate(lines, 1):\n",
    "                        print(f\"{line_num:4d}: {line}\")\n",
    "                    \n",
    "                    print(\"-\" * 80)\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    print(f\"❌ 读取文件 {file_path} 时发生错误: {e}\")\n",
    "        else:\n",
    "            print(\"\\n❌ 未找到任何相关的训练脚本文件\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9a20f4f4-8c19-44b7-94b5-db53eff61976",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/bin/evo2_convert_to_nemo2\", line 4, in <module>\n",
      "    from bionemo.evo2.utils.checkpoint.convert_to_nemo import main\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/bionemo/evo2/utils/checkpoint/convert_to_nemo.py\", line 24, in <module>\n",
      "    from nemo.collections.llm.gpt.model.hyena import (\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/nemo/collections/llm/__init__.py\", line 16, in <module>\n",
      "    from nemo.utils.import_utils import safe_import\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/nemo/utils/__init__.py\", line 17, in <module>\n",
      "    from nemo.utils.cast_utils import (\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/nemo/utils/cast_utils.py\", line 17, in <module>\n",
      "    import torch\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/torch/__init__.py\", line 411, in <module>\n",
      "    from torch._C import *  # noqa: F403\n",
      "    ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"<frozen importlib._bootstrap>\", line 463, in _lock_unlock_module\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "!evo2_convert_to_nemo2 \\\n",
    "  --model-path /workspace/savanna_evo2_7b/savanna_evo2_7b.pt \\\n",
    "  --model-size 7b --output-dir nemo2_evo2_7b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "026ce977-d70f-40b8-90e3-8eba91cd315d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!train_evo2 \\\n",
    "    -d training_data_config.yaml \\\n",
    "    --dataset-dir {preprocessed_data} \\\n",
    "    --model-size 7b \\\n",
    "    --devices 4 \\\n",
    "    --num-nodes 1 \\\n",
    "    --seq-length 1 \\\n",
    "    --micro-batch-size 1 \\\n",
    "    --lr 0.0001 \\\n",
    "    --warmup-steps 5 \\\n",
    "    --max-steps 200000 \\\n",
    "    --ckpt-dir nemo2_evo2_7b \\\n",
    "    --clip-grad 1 \\\n",
    "    --wd 0.01 \\\n",
    "    --activation-checkpoint-recompute-num-layers 1 \\\n",
    "    --val-check-interval 1000 \\\n",
    "    --ckpt-async-save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "454a2753-12ba-4e73-ad9e-79f12c123c4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not find the bitsandbytes CUDA binary at PosixPath('/usr/local/lib/python3.12/dist-packages/bitsandbytes/libbitsandbytes_cuda129.so')\n",
      "The installed version of bitsandbytes was compiled without GPU support. 8-bit optimizers, 8-bit multiplication, and GPU quantization are unavailable.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "[NeMo W 2025-06-08 13:50:10 nemo_logging:405] No version folders would be created under the log folder as 'resume_if_exists' is enabled.\n",
      "[NeMo I 2025-06-08 13:50:10 nemo_logging:393] Experiments will be logged at /tmp/tmpb5yk13vp/default\n",
      "[NeMo W 2025-06-08 13:50:10 nemo_logging:405] \"update_logger_directory\" is True. Overwriting tensorboard logger \"save_dir\" to /tmp/tmpb5yk13vp\n",
      "[NeMo I 2025-06-08 13:50:10 nemo_logging:393] Using byte-level tokenization\n",
      "[NeMo I 2025-06-08 13:50:11 nemo_logging:393] Rank 0 has data parallel group : [0]\n",
      "[NeMo I 2025-06-08 13:50:11 nemo_logging:393] Rank 0 has combined group of data parallel and context parallel : [0]\n",
      "[NeMo I 2025-06-08 13:50:11 nemo_logging:393] All data parallel group ranks with context parallel combined: [[0]]\n",
      "[NeMo I 2025-06-08 13:50:11 nemo_logging:393] Ranks 0 has data parallel rank: 0\n",
      "[NeMo I 2025-06-08 13:50:11 nemo_logging:393] Rank 0 has context parallel group: [0]\n",
      "[NeMo I 2025-06-08 13:50:11 nemo_logging:393] All context parallel group ranks: [[0]]\n",
      "[NeMo I 2025-06-08 13:50:11 nemo_logging:393] Ranks 0 has context parallel rank: 0\n",
      "[NeMo I 2025-06-08 13:50:11 nemo_logging:393] Rank 0 has model parallel group: [0]\n",
      "[NeMo I 2025-06-08 13:50:11 nemo_logging:393] All model parallel group ranks: [[0]]\n",
      "[NeMo I 2025-06-08 13:50:11 nemo_logging:393] Rank 0 has tensor model parallel group: [0]\n",
      "[NeMo I 2025-06-08 13:50:11 nemo_logging:393] All tensor model parallel group ranks: [[0]]\n",
      "[NeMo I 2025-06-08 13:50:11 nemo_logging:393] Rank 0 has tensor model parallel rank: 0\n",
      "[NeMo I 2025-06-08 13:50:11 nemo_logging:393] Rank 0 has pipeline model parallel group: [0]\n",
      "[NeMo I 2025-06-08 13:50:11 nemo_logging:393] Rank 0 has embedding group: [0]\n",
      "[NeMo I 2025-06-08 13:50:11 nemo_logging:393] All pipeline model parallel group ranks: [[0]]\n",
      "[NeMo I 2025-06-08 13:50:11 nemo_logging:393] Rank 0 has pipeline model parallel rank 0\n",
      "[NeMo I 2025-06-08 13:50:11 nemo_logging:393] All embedding group ranks: [[0]]\n",
      "[NeMo I 2025-06-08 13:50:11 nemo_logging:393] Rank 0 has embedding rank: 0\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 1 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[NeMo I 2025-06-08 13:50:11 num_microbatches_calculator:228] setting number of microbatches to constant 1\n",
      "[NeMo I 2025-06-08 13:50:11 nemo_logging:393] Padded vocab_size: 512, original vocab_size: 512, dummy tokens: 0.\n",
      "[NeMo W 2025-06-08 13:50:11 random:222] CPU RNG state changed within GPU RNG context\n",
      "[NeMo W 2025-06-08 13:50:11 random:222] CPU RNG state changed within GPU RNG context\n",
      "[NeMo W 2025-06-08 13:50:11 random:222] CPU RNG state changed within GPU RNG context\n",
      "[NeMo W 2025-06-08 13:50:11 random:222] CPU RNG state changed within GPU RNG context\n",
      "[NeMo W 2025-06-08 13:50:11 random:222] CPU RNG state changed within GPU RNG context\n",
      "[NeMo W 2025-06-08 13:50:11 random:222] CPU RNG state changed within GPU RNG context\n",
      "[NeMo W 2025-06-08 13:50:11 random:222] CPU RNG state changed within GPU RNG context\n",
      "[NeMo W 2025-06-08 13:50:11 random:222] CPU RNG state changed within GPU RNG context\n",
      "[NeMo W 2025-06-08 13:50:11 random:222] CPU RNG state changed within GPU RNG context\n",
      "[NeMo W 2025-06-08 13:50:11 random:222] CPU RNG state changed within GPU RNG context\n",
      "[NeMo W 2025-06-08 13:50:11 random:222] CPU RNG state changed within GPU RNG context\n",
      "[NeMo W 2025-06-08 13:50:11 random:222] CPU RNG state changed within GPU RNG context\n",
      "[NeMo W 2025-06-08 13:50:11 random:222] CPU RNG state changed within GPU RNG context\n",
      "[NeMo W 2025-06-08 13:50:11 random:222] CPU RNG state changed within GPU RNG context\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [4]\n",
      "[NeMo W 2025-06-08 13:50:12 nemo_logging:405] Could not copy Trainer's 'max_steps' to LR scheduler's 'max_steps'. If you are not using an LR scheduler, this warning can safely be ignored.\n",
      "[NeMo I 2025-06-08 13:50:12 nemo_logging:393]  > number of parameters on (tensor, pipeline) model parallel rank (0 ,0): 1108204800\n",
      "[NeMo I 2025-06-08 13:50:12 utils:554] Setting up DistributedDataParallel with config DistributedDataParallelConfig(grad_reduce_in_fp32=False, overlap_grad_reduce=False, overlap_param_gather=False, align_param_gather=False, use_distributed_optimizer=False, num_distributed_optimizer_instances=1, check_for_nan_in_grad=True, check_for_large_grads=False, bucket_size=None, pad_buckets_for_high_nccl_busbw=False, average_in_collective=False, fp8_param_gather=False, use_custom_fsdp=False, data_parallel_sharding_strategy='no_shard', gradient_reduce_div_fusion=True, suggested_communication_unit_size=None, preserve_fp32_weights=True, keep_fp8_transpose_cache_when_using_custom_fsdp=False)\n",
      "[NeMo I 2025-06-08 13:50:12 utils:575] Number of buckets for gradient all-reduce / reduce-scatter: 1\n",
      "    Params for bucket 1 (1108204800 elements, 1108204800 padded size):\n",
      "    \tmodule.decoder.layers.23.mixer.dense_projection.weight\n",
      "    \tmodule.decoder.layers.20.mixer.hyena_proj_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.17.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.13.mixer.hyena_proj_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.10.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.2.mixer.dense.weight\n",
      "    \tmodule.decoder.layers.1.mixer.mixer.filter.h\n",
      "    \tmodule.decoder.layers.23.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.21.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.13.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.12.mixer.mixer.conv_bias\n",
      "    \tmodule.decoder.layers.6.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.3.self_attention.linear_proj.bias\n",
      "    \tmodule.decoder.layers.19.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.17.self_attention.linear_qkv.layer_norm_weight\n",
      "    \tmodule.decoder.layers.14.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.12.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.10.self_attention.linear_qkv.layer_norm_weight\n",
      "    \tmodule.decoder.layers.7.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.4.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.0.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.21.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.20.mixer.dense.bias\n",
      "    \tmodule.decoder.layers.18.mixer.dense_projection.weight\n",
      "    \tmodule.decoder.layers.15.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.13.mixer.dense.bias\n",
      "    \tmodule.decoder.layers.11.mixer.dense_projection.weight\n",
      "    \tmodule.decoder.layers.8.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.6.mixer.dense.bias\n",
      "    \tmodule.decoder.layers.3.self_attention.linear_qkv.layer_norm_weight\n",
      "    \tmodule.decoder.layers.1.mixer.dense_projection.weight\n",
      "    \tmodule.decoder.layers.24.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.24.self_attention.linear_proj.bias\n",
      "    \tmodule.decoder.layers.14.mixer.dense.weight\n",
      "    \tmodule.decoder.layers.7.mixer.dense.weight\n",
      "    \tmodule.decoder.layers.4.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.2.mixer.dense_projection.layer_norm_weight\n",
      "    \tmodule.decoder.layers.1.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.20.mixer.dense_projection.weight\n",
      "    \tmodule.decoder.layers.17.self_attention.linear_proj.bias\n",
      "    \tmodule.decoder.layers.13.mixer.dense_projection.weight\n",
      "    \tmodule.decoder.layers.2.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.24.self_attention.linear_qkv.layer_norm_weight\n",
      "    \tmodule.decoder.layers.21.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.18.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.16.mixer.mixer.filter.R\n",
      "    \tmodule.decoder.layers.13.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.11.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.9.mixer.mixer.filter.R\n",
      "    \tmodule.decoder.layers.6.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.3.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.1.mixer.dense.bias\n",
      "    \tmodule.decoder.layers.22.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.20.mixer.mixer.conv_bias\n",
      "    \tmodule.decoder.layers.15.mixer.dense_projection.layer_norm_weight\n",
      "    \tmodule.decoder.layers.13.mixer.mixer.conv_bias\n",
      "    \tmodule.decoder.layers.8.mixer.dense_projection.layer_norm_weight\n",
      "    \tmodule.decoder.layers.4.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.0.mixer.hyena_proj_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.21.mixer.dense.weight\n",
      "    \tmodule.decoder.layers.18.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.15.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.11.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.8.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.5.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.16.mixer.dense.weight\n",
      "    \tmodule.decoder.layers.9.mixer.dense.weight\n",
      "    \tmodule.decoder.layers.4.mixer.dense.weight\n",
      "    \tmodule.decoder.layers.2.mixer.mixer.filter.gamma\n",
      "    \tmodule.decoder.layers.23.mixer.mixer.filter.R\n",
      "    \tmodule.decoder.layers.21.mixer.dense.bias\n",
      "    \tmodule.decoder.layers.20.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.17.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.10.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.6.mixer.mixer.conv_bias\n",
      "    \tmodule.decoder.layers.0.mlp.linear_fc1.weight\n",
      "    \tmodule.embedding.word_embeddings.weight\n",
      "    \tmodule.decoder.layers.22.mixer.dense_projection.layer_norm_weight\n",
      "    \tmodule.decoder.layers.19.mixer.dense.bias\n",
      "    \tmodule.decoder.layers.18.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.14.mixer.dense_projection.layer_norm_weight\n",
      "    \tmodule.decoder.layers.11.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.7.mixer.dense_projection.layer_norm_weight\n",
      "    \tmodule.decoder.layers.3.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.1.mixer.hyena_proj_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.22.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.19.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.12.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.5.mixer.dense_projection.layer_norm_weight\n",
      "    \tmodule.decoder.layers.2.mixer.mixer.filter.p\n",
      "    \tmodule.decoder.layers.0.mixer.mixer.short_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.23.mixer.dense.weight\n",
      "    \tmodule.decoder.layers.18.mixer.dense.weight\n",
      "    \tmodule.decoder.layers.16.mixer.dense_projection.layer_norm_weight\n",
      "    \tmodule.decoder.layers.15.mixer.mixer.conv_bias\n",
      "    \tmodule.decoder.layers.11.mixer.dense.weight\n",
      "    \tmodule.decoder.layers.9.mixer.dense_projection.layer_norm_weight\n",
      "    \tmodule.decoder.layers.8.mixer.dense.bias\n",
      "    \tmodule.decoder.layers.5.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.5.mixer.dense.bias\n",
      "    \tmodule.decoder.layers.24.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.22.mixer.dense.bias\n",
      "    \tmodule.decoder.layers.16.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.9.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.2.mixer.hyena_proj_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.21.mixer.dense_projection.layer_norm_weight\n",
      "    \tmodule.decoder.layers.20.mixer.mixer.filter.R\n",
      "    \tmodule.decoder.layers.18.mixer.dense.bias\n",
      "    \tmodule.decoder.layers.17.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.13.mixer.mixer.filter.R\n",
      "    \tmodule.decoder.layers.11.mixer.dense.bias\n",
      "    \tmodule.decoder.layers.10.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.6.mixer.mixer.filter.R\n",
      "    \tmodule.decoder.layers.2.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.0.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.22.mixer.mixer.conv_bias\n",
      "    \tmodule.decoder.layers.19.mixer.dense_projection.layer_norm_weight\n",
      "    \tmodule.decoder.layers.14.mixer.mixer.short_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.12.mixer.dense_projection.layer_norm_weight\n",
      "    \tmodule.decoder.layers.7.mixer.mixer.short_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.4.mixer.dense_projection.layer_norm_weight\n",
      "    \tmodule.decoder.layers.2.mixer.mixer.conv_bias\n",
      "    \tmodule.decoder.layers.23.mixer.dense_projection.layer_norm_weight\n",
      "    \tmodule.decoder.layers.19.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.19.mixer.mixer.conv_bias\n",
      "    \tmodule.decoder.layers.15.mixer.hyena_proj_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.12.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.12.mixer.dense.bias\n",
      "    \tmodule.decoder.layers.8.mixer.hyena_proj_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.2.mixer.dense.bias\n",
      "    \tmodule.decoder.layers.0.mixer.dense.weight\n",
      "    \tmodule.decoder.layers.23.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.20.mixer.dense.weight\n",
      "    \tmodule.decoder.layers.16.mixer.mixer.filter.gamma\n",
      "    \tmodule.decoder.layers.13.mixer.dense.weight\n",
      "    \tmodule.decoder.layers.9.mixer.mixer.filter.gamma\n",
      "    \tmodule.decoder.layers.6.mixer.dense.weight\n",
      "    \tmodule.decoder.layers.6.mixer.dense_projection.layer_norm_weight\n",
      "    \tmodule.decoder.layers.0.mixer.dense_projection.weight\n",
      "    \tmodule.decoder.layers.24.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.23.mixer.mixer.conv_bias\n",
      "    \tmodule.decoder.layers.17.self_attention.linear_proj.weight\n",
      "    \tmodule.decoder.layers.15.mixer.mixer.filter.h\n",
      "    \tmodule.decoder.layers.10.self_attention.linear_proj.weight\n",
      "    \tmodule.decoder.layers.8.mixer.mixer.filter.h\n",
      "    \tmodule.decoder.layers.2.mixer.dense_projection.weight\n",
      "    \tmodule.decoder.final_norm.weight\n",
      "    \tmodule.decoder.layers.21.mixer.mixer.short_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.18.mixer.dense_projection.layer_norm_weight\n",
      "    \tmodule.decoder.layers.15.mixer.dense.bias\n",
      "    \tmodule.decoder.layers.15.mixer.dense.weight\n",
      "    \tmodule.decoder.layers.11.mixer.dense_projection.layer_norm_weight\n",
      "    \tmodule.decoder.layers.8.mixer.dense.weight\n",
      "    \tmodule.decoder.layers.7.mixer.dense.bias\n",
      "    \tmodule.decoder.layers.6.mixer.mixer.filter.gamma\n",
      "    \tmodule.decoder.layers.2.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.1.mixer.dense.weight\n",
      "    \tmodule.decoder.layers.22.mixer.hyena_proj_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.16.mixer.mixer.filter.p\n",
      "    \tmodule.decoder.layers.14.mixer.hyena_proj_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.9.mixer.mixer.filter.p\n",
      "    \tmodule.decoder.layers.7.mixer.hyena_proj_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.4.mixer.mixer.short_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.1.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.0.mixer.dense.bias\n",
      "    \tmodule.decoder.layers.23.mixer.mixer.filter.gamma\n",
      "    \tmodule.decoder.layers.20.mixer.dense_projection.layer_norm_weight\n",
      "    \tmodule.decoder.layers.15.mixer.dense_projection.weight\n",
      "    \tmodule.decoder.layers.13.mixer.dense_projection.layer_norm_weight\n",
      "    \tmodule.decoder.layers.8.mixer.dense_projection.weight\n",
      "    \tmodule.decoder.layers.5.mixer.hyena_proj_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.24.self_attention.linear_proj.weight\n",
      "    \tmodule.decoder.layers.20.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.16.mixer.hyena_proj_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.13.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.9.mixer.hyena_proj_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.6.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.6.mixer.hyena_proj_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.3.self_attention.linear_qkv.weight\n",
      "    \tmodule.decoder.layers.1.mixer.mixer.conv_bias\n",
      "    \tmodule.decoder.layers.22.mixer.dense.weight\n",
      "    \tmodule.decoder.layers.16.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.14.mixer.dense.bias\n",
      "    \tmodule.decoder.layers.9.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.8.mixer.mixer.conv_bias\n",
      "    \tmodule.decoder.layers.5.mixer.mixer.filter.h\n",
      "    \tmodule.decoder.layers.4.mixer.dense.bias\n",
      "    \tmodule.decoder.layers.1.mixer.dense_projection.layer_norm_weight\n",
      "    \tmodule.decoder.layers.23.mixer.mixer.filter.p\n",
      "    \tmodule.decoder.layers.21.mixer.hyena_proj_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.18.mixer.mixer.short_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.15.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.11.mixer.mixer.short_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.8.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.5.mixer.dense.weight\n",
      "    \tmodule.decoder.layers.3.self_attention.linear_proj.weight\n",
      "    \tmodule.decoder.layers.22.mixer.dense_projection.weight\n",
      "    \tmodule.decoder.layers.19.mixer.hyena_proj_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.16.mixer.dense.bias\n",
      "    \tmodule.decoder.layers.14.mixer.dense_projection.weight\n",
      "    \tmodule.decoder.layers.12.mixer.hyena_proj_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.9.mixer.dense.bias\n",
      "    \tmodule.decoder.layers.7.mixer.dense_projection.weight\n",
      "    \tmodule.decoder.layers.4.mixer.hyena_proj_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.23.mixer.hyena_proj_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.20.mixer.mixer.filter.gamma\n",
      "    \tmodule.decoder.layers.17.self_attention.linear_qkv.weight\n",
      "    \tmodule.decoder.layers.13.mixer.mixer.filter.gamma\n",
      "    \tmodule.decoder.layers.10.self_attention.linear_qkv.weight\n",
      "    \tmodule.decoder.layers.5.mixer.dense_projection.weight\n",
      "    \tmodule.decoder.layers.23.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.22.mixer.mixer.filter.h\n",
      "    \tmodule.decoder.layers.20.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.19.mixer.mixer.filter.h\n",
      "    \tmodule.decoder.layers.16.mixer.dense_projection.weight\n",
      "    \tmodule.decoder.layers.12.mixer.mixer.filter.h\n",
      "    \tmodule.decoder.layers.10.self_attention.linear_proj.bias\n",
      "    \tmodule.decoder.layers.9.mixer.dense_projection.weight\n",
      "    \tmodule.decoder.layers.6.mixer.dense_projection.weight\n",
      "    \tmodule.decoder.layers.3.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.22.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.19.mixer.dense.weight\n",
      "    \tmodule.decoder.layers.16.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.14.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.12.mixer.dense.weight\n",
      "    \tmodule.decoder.layers.9.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.7.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.5.mixer.mixer.conv_bias\n",
      "    \tmodule.decoder.layers.2.mixer.mixer.filter.R\n",
      "    \tmodule.decoder.layers.0.mixer.dense_projection.layer_norm_weight\n",
      "    \tmodule.decoder.layers.18.mixer.hyena_proj_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.23.mixer.dense.bias\n",
      "    \tmodule.decoder.layers.21.mixer.dense_projection.weight\n",
      "    \tmodule.decoder.layers.20.mixer.mixer.filter.p\n",
      "    \tmodule.decoder.layers.16.mixer.mixer.conv_bias\n",
      "    \tmodule.decoder.layers.13.mixer.mixer.filter.p\n",
      "    \tmodule.decoder.layers.11.mixer.hyena_proj_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.9.mixer.mixer.conv_bias\n",
      "    \tmodule.decoder.layers.6.mixer.mixer.filter.p\n",
      "    \tmodule.decoder.layers.5.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.24.self_attention.linear_qkv.weight\n",
      "    \tmodule.decoder.layers.19.mixer.dense_projection.weight\n",
      "    \tmodule.decoder.layers.14.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.12.mixer.dense_projection.weight\n",
      "    \tmodule.decoder.layers.7.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.4.mixer.dense_projection.weight\n",
      "    \tmodule.decoder.layers.1.mlp.linear_fc2.weight\n",
      "[NeMo I 2025-06-08 13:50:12 nemo_logging:393] Doing selective restore from RestoreConfig(path='results/evo2/checkpoints/evo2--val_loss=1.4537-epoch=0-consumed_samples=100.0-last', adapter_path=None, load_model_state=True, load_optim_state=False, load_artifacts=False)\n",
      "[NeMo I 2025-06-08 13:50:12 nemo_logging:393] Using <megatron.core.dist_checkpointing.strategies.fully_parallel.FullyParallelLoadStrategyWrapper object at 0x73f388f1b2f0> dist-ckpt load strategy.\n",
      "[NeMo W 2025-06-08 13:50:12 validation:364] Some keys found in the checkpoint are missing in the provided sharded state dict. \n",
      "    Missing keys (for all ranks): {'optimizer.state.exp_avg.module.decoder.layers.20.mixer.dense_projection.layer_norm_weight', 'optimizer.state.exp_avg_sq.module.decoder.layers.2.mixer.dense.bias', 'optimizer.state.exp_avg_sq.module.decoder.layers.18.mlp.linear_fc2.weight', 'optimizer.state.fp32_param.module.decoder.layers.9.mlp.linear_fc2.weight', 'optimizer.state.fp32_param.module.decoder.layers.19.mlp.linear_fc2.weight', 'optimizer.state.exp_avg.module.decoder.layers.20.mixer.dense.weight', 'optimizer.state.fp32_param.module.decoder.layers.22.mixer.dense.bias', 'optimizer.state.exp_avg.module.decoder.layers.20.mixer.mixer.filter.gamma', 'optimizer.state.exp_avg.module.decoder.layers.7.mlp.linear_fc1.layer_norm_weight', 'optimizer.state.exp_avg_sq.module.decoder.layers.9.mixer.mixer.filter.gamma', 'optimizer.state.fp32_param.module.decoder.layers.9.mixer.dense.weight', 'optimizer.state.fp32_param.module.decoder.layers.2.mixer.mixer.conv_bias', 'optimizer.state.exp_avg.module.decoder.layers.7.mixer.hyena_proj_conv.short_conv_weight', 'optimizer.state.exp_avg.module.decoder.layers.10.self_attention.linear_qkv.weight', 'optimizer.state.exp_avg_sq.module.decoder.layers.2.mixer.mixer.filter.p', 'optimizer.state.exp_avg.module.decoder.layers.22.mixer.dense.weight', 'optimizer.state.exp_avg.module.decoder.layers.12.mixer.mixer.filter.h', 'optimizer.state.fp32_param.module.decoder.layers.5.mixer.dense_projection.weight', 'optimizer.state.exp_avg_sq.module.decoder.layers.20.mlp.linear_fc1.layer_norm_weight', 'optimizer.state.exp_avg.module.decoder.layers.5.mixer.mixer.conv_bias', 'optimizer.state.fp32_param.module.decoder.layers.0.mlp.linear_fc2.weight', 'optimizer.state.fp32_param.module.decoder.layers.23.mlp.linear_fc1.weight', 'optimizer.state.exp_avg_sq.module.decoder.layers.23.mixer.mixer.filter.gamma', 'optimizer.state.exp_avg.module.decoder.layers.22.mixer.mixer.filter.h', 'optimizer.state.fp32_param.module.decoder.layers.17.mlp.linear_fc1.weight', 'optimizer.state.fp32_param.module.decoder.layers.9.mlp.linear_fc1.weight', 'optimizer.state.exp_avg.module.decoder.layers.8.mlp.linear_fc1.weight', 'optimizer.state.exp_avg.module.decoder.layers.4.mixer.mixer.short_conv.short_conv_weight', 'optimizer.state.exp_avg.module.decoder.layers.3.self_attention.linear_proj.bias', 'optimizer.state.fp32_param.module.decoder.layers.12.mixer.hyena_proj_conv.short_conv_weight', 'optimizer.state.exp_avg_sq.module.decoder.layers.18.mixer.dense.weight', 'optimizer.state.exp_avg.module.decoder.layers.23.mixer.mixer.conv_bias', 'optimizer.state.exp_avg_sq.module.decoder.layers.5.mixer.dense.bias', 'optimizer.state.fp32_param.module.decoder.layers.9.mixer.mixer.filter.R', 'optimizer.state.exp_avg_sq.module.decoder.layers.24.self_attention.linear_proj.weight', 'optimizer.state.fp32_param.module.decoder.layers.13.mixer.mixer.filter.gamma', 'optimizer.state.exp_avg_sq.module.decoder.layers.6.mlp.linear_fc1.layer_norm_weight', 'optimizer.state.exp_avg.module.decoder.layers.5.mixer.dense_projection.weight', 'optimizer.state.exp_avg_sq.module.decoder.layers.3.mlp.linear_fc1.layer_norm_weight', 'optimizer.state.fp32_param.module.decoder.layers.7.mixer.dense.weight', 'optimizer.state.exp_avg_sq.module.decoder.layers.5.mixer.dense.weight', 'optimizer.state.exp_avg.module.decoder.layers.20.mixer.mixer.filter.R', 'optimizer.state.exp_avg.module.decoder.layers.23.mlp.linear_fc1.weight', 'optimizer.state.exp_avg.module.decoder.layers.14.mlp.linear_fc2.weight', 'optimizer.state.exp_avg.module.decoder.layers.1.mlp.linear_fc1.weight', 'optimizer.state.exp_avg_sq.module.decoder.final_norm.weight', 'optimizer.state.exp_avg_sq.module.decoder.layers.6.mlp.linear_fc1.weight', 'optimizer.state.exp_avg_sq.module.decoder.layers.15.mixer.mixer.conv_bias', 'optimizer.state.fp32_param.module.decoder.layers.16.mixer.dense_projection.weight', 'optimizer.state.fp32_param.module.decoder.layers.10.self_attention.linear_proj.bias', 'optimizer.state.exp_avg.module.decoder.layers.14.mixer.dense.bias', 'optimizer.state.fp32_param.module.decoder.layers.20.mixer.mixer.conv_bias', 'optimizer.state.exp_avg.module.decoder.layers.21.mixer.hyena_proj_conv.short_conv_weight', 'optimizer.state.fp32_param.module.decoder.layers.8.mixer.dense_projection.weight', 'optimizer.state.exp_avg.module.decoder.layers.3.mlp.linear_fc1.weight', 'optimizer.state.fp32_param.module.decoder.layers.16.mixer.mixer.filter.R', 'optimizer.state.fp32_param.module.decoder.layers.20.mixer.dense_projection.layer_norm_weight', 'optimizer.state.exp_avg_sq.module.decoder.layers.14.mixer.dense.bias', 'optimizer.state.exp_avg_sq.module.decoder.layers.13.mixer.mixer.filter.R', 'optimizer.state.fp32_param.module.decoder.layers.1.mixer.dense_projection.layer_norm_weight', 'optimizer.state.fp32_param.module.decoder.layers.6.mlp.linear_fc1.layer_norm_weight', 'optimizer.state.fp32_param.module.decoder.layers.23.mixer.mixer.filter.gamma', 'optimizer.state.fp32_param.module.decoder.layers.23.mixer.hyena_proj_conv.short_conv_weight', 'optimizer.state.fp32_param.module.decoder.layers.6.mixer.mixer.filter.p', 'optimizer.state.exp_avg_sq.module.decoder.layers.7.mlp.linear_fc2.weight', 'optimizer.state.fp32_param.module.decoder.layers.1.mixer.dense_projection.weight', 'optimizer.state.exp_avg_sq.module.decoder.layers.7.mixer.dense.weight', 'optimizer.state.exp_avg.module.decoder.layers.21.mixer.dense_projection.weight', 'optimizer.state.fp32_param.module.decoder.layers.19.mixer.dense_projection.layer_norm_weight', 'optimizer.state.exp_avg_sq.module.decoder.layers.9.mixer.hyena_proj_conv.short_conv_weight', 'optimizer.state.exp_avg_sq.module.decoder.layers.21.mixer.dense.bias', 'optimizer.state.fp32_param.module.decoder.layers.9.mixer.hyena_proj_conv.short_conv_weight', 'optimizer.state.exp_avg_sq.module.decoder.layers.0.mlp.linear_fc2.weight', 'optimizer.state.exp_avg_sq.module.decoder.layers.23.mixer.mixer.filter.R', 'optimizer.state.fp32_param.module.decoder.layers.14.mixer.mixer.short_conv.short_conv_weight', 'optimizer.state.fp32_param.module.decoder.layers.9.mixer.mixer.conv_bias', 'optimizer.state.exp_avg_sq.module.decoder.layers.1.mlp.linear_fc2.weight', 'optimizer.state.exp_avg.module.decoder.layers.0.mlp.linear_fc1.weight', 'optimizer.state.fp32_param.module.decoder.layers.17.self_attention.linear_proj.weight', 'optimizer.state.fp32_param.module.decoder.layers.7.mixer.mixer.short_conv.short_conv_weight', 'optimizer.state.exp_avg_sq.module.decoder.layers.22.mlp.linear_fc1.weight', 'optimizer.state.exp_avg_sq.module.embedding.word_embeddings.weight', 'optimizer.state.fp32_param.module.decoder.layers.9.mixer.dense.bias', 'optimizer.state.fp32_param.module.decoder.layers.23.mixer.dense.bias', 'optimizer.state.exp_avg_sq.module.decoder.layers.2.mixer.mixer.filter.gamma', 'optimizer.state.fp32_param.module.decoder.layers.22.mixer.hyena_proj_conv.short_conv_weight', 'optimizer.state.exp_avg_sq.module.decoder.layers.7.mlp.linear_fc1.weight', 'optimizer.state.exp_avg.module.decoder.layers.13.mixer.dense.weight', 'optimizer.state.fp32_param.module.decoder.layers.19.mixer.dense.weight', 'optimizer.state.fp32_param.module.decoder.layers.22.mlp.linear_fc2.weight', 'optimizer.state.fp32_param.module.decoder.layers.21.mixer.mixer.short_conv.short_conv_weight', 'optimizer.state.fp32_param.module.decoder.layers.1.mlp.linear_fc1.weight', 'optimizer.state.fp32_param.module.decoder.layers.1.mixer.hyena_proj_conv.short_conv_weight', 'optimizer.state.exp_avg.module.decoder.layers.5.mixer.mixer.filter.h', 'optimizer.state.fp32_param.module.decoder.layers.0.mlp.linear_fc1.layer_norm_weight', 'optimizer.state.fp32_param.module.decoder.layers.14.mixer.hyena_proj_conv.short_conv_weight', 'optimizer.state.exp_avg_sq.module.decoder.layers.13.mixer.mixer.filter.p', 'optimizer.state.exp_avg_sq.module.decoder.layers.1.mixer.mixer.conv_bias', 'optimizer.state.fp32_param.module.decoder.layers.5.mixer.mixer.filter.h', 'optimizer.state.exp_avg.module.decoder.layers.6.mlp.linear_fc1.weight', 'optimizer.state.fp32_param.module.decoder.layers.22.mixer.dense.weight', 'optimizer.state.exp_avg_sq.module.decoder.layers.16.mixer.mixer.filter.gamma', 'optimizer.state.exp_avg_sq.module.decoder.layers.11.mlp.linear_fc2.weight', 'optimizer.state.fp32_param.module.decoder.layers.21.mixer.dense.bias', 'optimizer.state.fp32_param.module.decoder.layers.9.mlp.linear_fc1.layer_norm_weight', 'optimizer.state.fp32_param.module.decoder.layers.8.mlp.linear_fc1.layer_norm_weight', 'optimizer.state.exp_avg_sq.module.decoder.layers.12.mixer.dense_projection.layer_norm_weight', 'optimizer.state.exp_avg_sq.module.decoder.layers.20.mixer.dense.weight', 'optimizer.state.fp32_param.module.decoder.layers.1.mixer.mixer.conv_bias', 'optimizer.state.exp_avg.module.decoder.layers.6.mixer.hyena_proj_conv.short_conv_weight', 'optimizer.state.exp_avg_sq.module.decoder.layers.16.mixer.dense_projection.layer_norm_weight', 'optimizer.state.fp32_param.module.decoder.layers.16.mixer.mixer.filter.gamma', 'optimizer.state.exp_avg.module.decoder.layers.18.mixer.mixer.short_conv.short_conv_weight', 'optimizer.state.exp_avg.module.decoder.layers.2.mixer.dense.weight', 'optimizer.state.exp_avg_sq.module.decoder.layers.13.mlp.linear_fc1.layer_norm_weight', 'optimizer.state.exp_avg.module.decoder.layers.16.mixer.dense.weight', 'optimizer.state.exp_avg.module.decoder.layers.12.mixer.dense_projection.layer_norm_weight', 'optimizer.state.exp_avg_sq.module.decoder.layers.3.self_attention.linear_proj.weight', 'optimizer.state.exp_avg_sq.module.decoder.layers.19.mlp.linear_fc1.layer_norm_weight', 'optimizer.state.exp_avg_sq.module.decoder.layers.15.mixer.dense_projection.layer_norm_weight', 'optimizer.state.exp_avg_sq.module.decoder.layers.11.mlp.linear_fc1.weight', 'optimizer.state.fp32_param.module.decoder.layers.24.self_attention.linear_proj.bias', 'optimizer.state.exp_avg.module.decoder.layers.15.mixer.dense.bias', 'optimizer.state.exp_avg_sq.module.decoder.layers.1.mixer.dense_projection.weight', 'optimizer.state.exp_avg_sq.module.decoder.layers.1.mixer.dense_projection.layer_norm_weight', 'optimizer.state.exp_avg_sq.module.decoder.layers.4.mlp.linear_fc2.weight', 'optimizer.state.exp_avg_sq.module.decoder.layers.18.mlp.linear_fc1.weight', 'optimizer.state.fp32_param.module.decoder.layers.23.mixer.mixer.filter.R', 'optimizer.state.exp_avg_sq.module.decoder.layers.20.mixer.hyena_proj_conv.short_conv_weight', 'optimizer.state.exp_avg.module.decoder.layers.19.mlp.linear_fc1.layer_norm_weight', 'optimizer.state.fp32_param.module.decoder.layers.11.mixer.dense_projection.weight', 'optimizer.state.exp_avg_sq.module.decoder.layers.5.mixer.dense_projection.weight', 'optimizer.state.exp_avg.module.decoder.layers.17.self_attention.linear_proj.weight', 'optimizer.state.exp_avg.module.decoder.layers.23.mixer.mixer.filter.p', 'optimizer.state.exp_avg_sq.module.decoder.layers.3.self_attention.linear_proj.bias', 'optimizer.state.fp32_param.module.decoder.layers.13.mixer.dense.weight', 'optimizer.state.exp_avg.module.decoder.layers.1.mlp.linear_fc2.weight', 'optimizer.state.fp32_param.module.decoder.layers.18.mixer.dense.weight', 'optimizer.state.exp_avg_sq.module.decoder.layers.19.mlp.linear_fc2.weight', 'optimizer.state.exp_avg.module.decoder.layers.19.mlp.linear_fc1.weight', 'optimizer.state.exp_avg.module.decoder.layers.2.mlp.linear_fc2.weight', 'optimizer.state.exp_avg.module.decoder.layers.15.mlp.linear_fc1.layer_norm_weight', 'optimizer.state.exp_avg.module.decoder.layers.12.mlp.linear_fc1.weight', 'optimizer.state.fp32_param.module.decoder.layers.23.mlp.linear_fc2.weight', 'optimizer.state.exp_avg_sq.module.decoder.layers.9.mlp.linear_fc2.weight', 'optimizer.state.exp_avg_sq.module.decoder.layers.0.mixer.mixer.short_conv.short_conv_weight', 'optimizer.state.exp_avg_sq.module.decoder.layers.20.mixer.mixer.filter.p', 'optimizer.state.fp32_param.module.decoder.layers.14.mlp.linear_fc1.layer_norm_weight', 'optimizer.state.exp_avg.module.decoder.layers.6.mixer.dense_projection.weight', 'optimizer.state.exp_avg_sq.module.decoder.layers.1.mixer.hyena_proj_conv.short_conv_weight', 'optimizer.state.exp_avg.module.decoder.layers.5.mixer.dense_projection.layer_norm_weight', 'optimizer.state.exp_avg_sq.module.decoder.layers.17.mlp.linear_fc1.layer_norm_weight', 'optimizer.state.exp_avg.module.decoder.layers.16.mixer.dense_projection.layer_norm_weight', 'optimizer.state.fp32_param.module.decoder.layers.1.mixer.mixer.filter.h', 'optimizer.state.exp_avg.module.decoder.layers.0.mixer.hyena_proj_conv.short_conv_weight', 'optimizer.state.exp_avg_sq.module.decoder.layers.7.mixer.dense_projection.weight', 'optimizer.state.exp_avg_sq.module.decoder.layers.6.mixer.hyena_proj_conv.short_conv_weight', 'optimizer.state.fp32_param.module.decoder.layers.5.mlp.linear_fc2.weight', 'optimizer.state.exp_avg.module.decoder.layers.6.mixer.dense.bias', 'optimizer.state.exp_avg_sq.module.decoder.layers.3.self_attention.linear_qkv.layer_norm_weight', 'optimizer.state.exp_avg.module.decoder.layers.12.mixer.hyena_proj_conv.short_conv_weight', 'optimizer.state.exp_avg.module.decoder.layers.7.mixer.dense_projection.weight', 'optimizer.state.exp_avg.module.decoder.layers.9.mixer.mixer.filter.p', 'optimizer.state.exp_avg.module.decoder.layers.19.mixer.dense_projection.weight', 'optimizer.state.fp32_param.module.decoder.layers.6.mixer.mixer.filter.R', 'optimizer.state.fp32_param.module.decoder.layers.13.mixer.mixer.filter.R', 'optimizer.state.fp32_param.module.decoder.layers.12.mixer.dense_projection.layer_norm_weight', 'optimizer.state.exp_avg.module.decoder.layers.18.mlp.linear_fc1.weight', 'optimizer.state.exp_avg.module.decoder.layers.2.mixer.dense_projection.weight', 'optimizer.state.exp_avg.module.decoder.layers.17.mlp.linear_fc1.weight', 'optimizer.state.fp32_param.module.decoder.layers.12.mlp.linear_fc2.weight', 'optimizer.state.fp32_param.module.decoder.layers.7.mixer.dense_projection.weight', 'optimizer.state.exp_avg.module.decoder.layers.3.self_attention.linear_proj.weight', 'optimizer.state.exp_avg_sq.module.decoder.layers.21.mixer.dense_projection.weight', 'optimizer.state.fp32_param.module.decoder.layers.6.mixer.dense.weight', 'optimizer.state.exp_avg.module.decoder.layers.23.mlp.linear_fc1.layer_norm_weight', 'optimizer.state.exp_avg.module.decoder.layers.6.mlp.linear_fc2.weight', 'optimizer.state.exp_avg_sq.module.decoder.layers.13.mixer.dense_projection.layer_norm_weight', 'optimizer.state.fp32_param.module.decoder.layers.12.mixer.mixer.conv_bias', 'optimizer.state.fp32_param.module.decoder.layers.24.self_attention.linear_qkv.weight', 'optimizer.state.fp32_param.module.decoder.layers.5.mlp.linear_fc1.weight', 'optimizer.state.fp32_param.module.decoder.layers.12.mixer.dense.bias', 'optimizer.state.fp32_param.module.decoder.layers.18.mlp.linear_fc1.layer_norm_weight', 'optimizer.state.exp_avg_sq.module.decoder.layers.5.mixer.mixer.filter.h', 'optimizer.state.exp_avg_sq.module.decoder.layers.4.mixer.dense_projection.layer_norm_weight', 'optimizer.state.exp_avg_sq.module.decoder.layers.16.mixer.mixer.filter.R', 'optimizer.state.exp_avg.module.decoder.layers.8.mixer.mixer.filter.h', 'optimizer.state.exp_avg_sq.module.decoder.layers.16.mlp.linear_fc1.layer_norm_weight', 'optimizer.state.exp_avg_sq.module.decoder.layers.0.mlp.linear_fc1.layer_norm_weight', 'optimizer.state.exp_avg_sq.module.decoder.layers.2.mixer.hyena_proj_conv.short_conv_weight', 'optimizer.state.exp_avg.module.decoder.layers.22.mixer.hyena_proj_conv.short_conv_weight', 'optimizer.state.fp32_param.module.decoder.layers.4.mixer.dense_projection.layer_norm_weight', 'optimizer.state.fp32_param.module.decoder.layers.2.mixer.hyena_proj_conv.short_conv_weight', 'optimizer.state.exp_avg.module.decoder.layers.22.mlp.linear_fc2.weight', 'optimizer.state.exp_avg_sq.module.decoder.layers.6.mixer.mixer.conv_bias', 'optimizer.state.exp_avg_sq.module.decoder.layers.19.mixer.dense.weight', 'optimizer.state.exp_avg_sq.module.decoder.layers.18.mlp.linear_fc1.layer_norm_weight', 'optimizer.state.fp32_param.module.decoder.layers.13.mlp.linear_fc1.layer_norm_weight', 'optimizer.state.fp32_param.module.decoder.layers.3.self_attention.linear_proj.weight', 'optimizer.state.exp_avg.module.decoder.layers.17.self_attention.linear_qkv.weight', 'optimizer.state.exp_avg_sq.module.decoder.layers.19.mixer.hyena_proj_conv.short_conv_weight', 'optimizer.state.exp_avg.module.decoder.layers.11.mixer.dense_projection.weight', 'optimizer.state.exp_avg_sq.module.decoder.layers.14.mlp.linear_fc1.layer_norm_weight', 'optimizer.state.fp32_param.module.decoder.layers.6.mixer.dense_projection.layer_norm_weight', 'optimizer.state.exp_avg.module.embedding.word_embeddings.weight', 'optimizer.state.exp_avg_sq.module.decoder.layers.14.mlp.linear_fc2.weight', 'optimizer.state.exp_avg.module.decoder.layers.21.mixer.dense.weight', 'optimizer.state.exp_avg_sq.module.decoder.layers.8.mlp.linear_fc1.layer_norm_weight', 'optimizer.state.exp_avg.module.decoder.layers.11.mlp.linear_fc2.weight', 'optimizer.state.fp32_param.module.decoder.layers.4.mixer.mixer.short_conv.short_conv_weight', 'optimizer.state.exp_avg.module.decoder.layers.24.self_attention.linear_proj.bias', 'optimizer.state.exp_avg.module.decoder.layers.12.mlp.linear_fc2.weight', 'optimizer.state.fp32_param.module.decoder.layers.24.mlp.linear_fc2.weight', 'optimizer.state.fp32_param.module.decoder.layers.14.mixer.dense_projection.layer_norm_weight', 'optimizer.state.exp_avg.module.decoder.layers.9.mixer.dense.weight', 'optimizer.state.fp32_param.module.decoder.layers.19.mlp.linear_fc1.weight', 'optimizer.state.exp_avg.module.decoder.layers.18.mixer.dense_projection.weight', 'optimizer.state.fp32_param.module.decoder.layers.17.self_attention.linear_proj.bias', 'optimizer.state.exp_avg.module.decoder.layers.21.mixer.dense_projection.layer_norm_weight', 'optimizer.state.fp32_param.module.decoder.layers.5.mlp.linear_fc1.layer_norm_weight', 'optimizer.state.fp32_param.module.decoder.layers.24.self_attention.linear_qkv.layer_norm_weight', 'optimizer.state.exp_avg_sq.module.decoder.layers.4.mixer.hyena_proj_conv.short_conv_weight', 'optimizer.state.exp_avg.module.decoder.layers.18.mixer.dense_projection.layer_norm_weight', 'optimizer.state.exp_avg.module.decoder.layers.0.mixer.dense.weight', 'optimizer.state.fp32_param.module.decoder.layers.0.mixer.dense_projection.layer_norm_weight', 'optimizer.state.exp_avg_sq.module.decoder.layers.21.mlp.linear_fc2.weight', 'optimizer.state.exp_avg_sq.module.decoder.layers.12.mixer.dense.bias', 'optimizer.state.fp32_param.module.decoder.layers.17.self_attention.linear_qkv.weight', 'optimizer.state.fp32_param.module.decoder.layers.3.mlp.linear_fc2.weight', 'optimizer.state.exp_avg_sq.module.decoder.layers.20.mixer.dense.bias', 'optimizer.state.exp_avg_sq.module.decoder.layers.23.mixer.mixer.filter.p', 'optimizer.state.exp_avg_sq.module.decoder.layers.23.mixer.dense_projection.layer_norm_weight', 'optimizer.state.exp_avg_sq.module.decoder.layers.8.mlp.linear_fc2.weight', 'optimizer.state.fp32_param.module.decoder.layers.13.mixer.dense_projection.layer_norm_weight', 'optimizer.state.exp_avg_sq.module.decoder.layers.3.mlp.linear_fc2.weight', 'optimizer.state.exp_avg.module.decoder.layers.11.mlp.linear_fc1.layer_norm_weight', 'optimizer.state.exp_avg.module.decoder.layers.1.mixer.dense_projection.layer_norm_weight', 'optimizer.state.exp_avg_sq.module.decoder.layers.15.mixer.hyena_proj_conv.short_conv_weight', 'optimizer.state.exp_avg_sq.module.decoder.layers.8.mixer.dense.weight', 'optimizer.state.exp_avg_sq.module.decoder.layers.6.mlp.linear_fc2.weight', 'optimizer.state.exp_avg.module.decoder.layers.6.mlp.linear_fc1.layer_norm_weight', 'optimizer.state.exp_avg_sq.module.decoder.layers.1.mixer.mixer.filter.h', 'optimizer.state.fp32_param.module.decoder.layers.22.mlp.linear_fc1.layer_norm_weight', 'optimizer.state.exp_avg_sq.module.decoder.layers.22.mixer.hyena_proj_conv.short_conv_weight', 'optimizer.state.exp_avg_sq.module.decoder.layers.16.mixer.mixer.conv_bias', 'optimizer.state.exp_avg_sq.module.decoder.layers.8.mixer.dense.bias', 'optimizer.state.exp_avg.module.decoder.layers.13.mixer.dense_projection.weight', 'optimizer.state.exp_avg.module.decoder.layers.6.mixer.mixer.filter.gamma', 'optimizer.state.fp32_param.module.decoder.layers.4.mlp.linear_fc2.weight', 'optimizer.state.fp32_param.module.decoder.layers.4.mixer.hyena_proj_conv.short_conv_weight', 'optimizer.state.exp_avg_sq.module.decoder.layers.2.mlp.linear_fc1.layer_norm_weight', 'optimizer.state.exp_avg_sq.module.decoder.layers.15.mlp.linear_fc2.weight', 'optimizer.state.exp_avg.module.decoder.layers.23.mixer.mixer.filter.R', 'optimizer.state.exp_avg.module.decoder.layers.12.mixer.mixer.conv_bias', 'optimizer.state.exp_avg_sq.module.decoder.layers.22.mlp.linear_fc1.layer_norm_weight', 'optimizer.state.exp_avg_sq.module.decoder.layers.0.mixer.dense_projection.layer_norm_weight', 'optimizer.state.exp_avg.module.decoder.layers.7.mlp.linear_fc1.weight', 'optimizer.state.exp_avg_sq.module.decoder.layers.22.mixer.dense_projection.weight', 'optimizer.state.exp_avg_sq.module.decoder.layers.9.mlp.linear_fc1.layer_norm_weight', 'optimizer.state.exp_avg.module.decoder.layers.1.mixer.dense_projection.weight', 'optimizer.state.exp_avg.module.decoder.layers.15.mlp.linear_fc2.weight', 'optimizer.state.fp32_param.module.decoder.layers.23.mixer.mixer.conv_bias', 'optimizer.state.exp_avg_sq.module.decoder.layers.21.mixer.mixer.short_conv.short_conv_weight', 'optimizer.state.fp32_param.module.decoder.layers.2.mixer.dense.bias', 'optimizer.state.fp32_param.module.decoder.layers.19.mixer.mixer.conv_bias', 'optimizer.state.fp32_param.module.decoder.layers.11.mlp.linear_fc1.weight', 'optimizer.state.exp_avg_sq.module.decoder.layers.7.mixer.hyena_proj_conv.short_conv_weight', 'optimizer.state.exp_avg.module.decoder.layers.19.mixer.dense.weight', 'optimizer.state.exp_avg_sq.module.decoder.layers.23.mixer.dense.weight', 'optimizer.state.exp_avg_sq.module.decoder.layers.22.mixer.mixer.conv_bias', 'optimizer.state.fp32_param.module.decoder.layers.15.mixer.dense_projection.weight', 'optimizer.state.exp_avg.module.decoder.layers.15.mixer.dense_projection.layer_norm_weight', 'optimizer.state.exp_avg.module.decoder.layers.1.mlp.linear_fc1.layer_norm_weight', 'optimizer.state.fp32_param.module.decoder.layers.16.mixer.dense.bias', 'optimizer.state.exp_avg.module.decoder.layers.12.mlp.linear_fc1.layer_norm_weight', 'optimizer.state.fp32_param.module.decoder.layers.8.mixer.mixer.filter.h', 'optimizer.state.exp_avg_sq.module.decoder.layers.10.mlp.linear_fc2.weight', 'optimizer.state.exp_avg.module.decoder.layers.3.self_attention.linear_qkv.weight', 'optimizer.state.exp_avg_sq.module.decoder.layers.24.self_attention.linear_qkv.weight', 'optimizer.state.exp_avg_sq.module.decoder.layers.14.mixer.dense_projection.layer_norm_weight', 'optimizer.state.fp32_param.module.decoder.layers.11.mixer.dense.weight', 'optimizer.state.exp_avg_sq.module.decoder.layers.11.mlp.linear_fc1.layer_norm_weight', 'optimizer.state.exp_avg.module.decoder.layers.15.mixer.mixer.conv_bias', 'optimizer.state.fp32_param.module.decoder.layers.20.mixer.mixer.filter.gamma', 'optimizer.state.exp_avg.module.decoder.layers.13.mixer.dense_projection.layer_norm_weight', 'optimizer.state.exp_avg.module.decoder.layers.1.mixer.dense.weight', 'optimizer.state.exp_avg.module.decoder.layers.2.mixer.dense.bias', 'optimizer.state.exp_avg.module.decoder.layers.13.mlp.linear_fc1.layer_norm_weight', 'optimizer.state.exp_avg_sq.module.decoder.layers.4.mixer.dense.bias', 'optimizer.state.fp32_param.module.decoder.layers.6.mlp.linear_fc2.weight', 'optimizer.state.exp_avg_sq.module.decoder.layers.18.mixer.dense.bias', 'optimizer.state.fp32_param.module.decoder.layers.2.mixer.dense.weight', 'optimizer.state.exp_avg.module.decoder.layers.5.mixer.dense.bias', 'optimizer.state.exp_avg.module.decoder.layers.9.mixer.mixer.conv_bias', 'optimizer.state.fp32_param.module.decoder.layers.7.mlp.linear_fc1.weight', 'optimizer.state.exp_avg.module.decoder.layers.10.mlp.linear_fc1.layer_norm_weight', 'optimizer.state.fp32_param.module.decoder.layers.11.mixer.mixer.short_conv.short_conv_weight', 'optimizer.state.exp_avg.module.decoder.layers.5.mlp.linear_fc2.weight', 'optimizer.state.fp32_param.module.decoder.layers.0.mixer.dense_projection.weight', 'optimizer.state.fp32_param.module.decoder.layers.2.mlp.linear_fc2.weight', 'optimizer.state.fp32_param.module.decoder.layers.6.mixer.mixer.filter.gamma', 'optimizer.state.exp_avg_sq.module.decoder.layers.12.mlp.linear_fc1.layer_norm_weight', 'optimizer.state.fp32_param.module.decoder.layers.14.mlp.linear_fc1.weight', 'optimizer.state.exp_avg.module.decoder.layers.23.mixer.dense.weight', 'optimizer.state.fp32_param.module.decoder.layers.15.mixer.mixer.conv_bias', 'optimizer.state.exp_avg.module.decoder.layers.6.mixer.mixer.filter.R', 'optimizer.state.exp_avg_sq.module.decoder.layers.22.mixer.mixer.filter.h', 'optimizer.state.fp32_param.module.decoder.layers.7.mlp.linear_fc1.layer_norm_weight', 'optimizer.state.exp_avg.module.decoder.layers.20.mixer.mixer.conv_bias', 'optimizer.state.exp_avg_sq.module.decoder.layers.16.mixer.dense_projection.weight', 'optimizer.state.exp_avg_sq.module.decoder.layers.21.mixer.dense_projection.layer_norm_weight', 'optimizer.state.fp32_param.module.decoder.layers.16.mixer.dense_projection.layer_norm_weight', 'optimizer.state.fp32_param.module.decoder.layers.16.mixer.mixer.conv_bias', 'optimizer.state.exp_avg_sq.module.decoder.layers.18.mixer.dense_projection.weight', 'optimizer.state.exp_avg.module.decoder.layers.14.mixer.dense_projection.layer_norm_weight', 'optimizer.state.exp_avg.module.decoder.layers.16.mixer.mixer.filter.p', 'optimizer.state.fp32_param.module.decoder.layers.9.mixer.mixer.filter.p', 'optimizer.state.exp_avg_sq.module.decoder.layers.10.self_attention.linear_proj.weight', 'optimizer.state.exp_avg.module.decoder.layers.4.mixer.dense_projection.layer_norm_weight', 'optimizer.state.exp_avg.module.decoder.layers.13.mlp.linear_fc2.weight', 'optimizer.state.exp_avg.module.decoder.layers.7.mixer.dense_projection.layer_norm_weight', 'optimizer.state.exp_avg.module.decoder.layers.17.mlp.linear_fc1.layer_norm_weight', 'optimizer.state.exp_avg_sq.module.decoder.layers.17.self_attention.linear_qkv.weight', 'optimizer.state.exp_avg_sq.module.decoder.layers.0.mixer.dense_projection.weight', 'optimizer.state.exp_avg.module.decoder.layers.12.mixer.dense.weight', 'optimizer.state.exp_avg_sq.module.decoder.layers.3.mlp.linear_fc1.weight', 'optimizer.state.fp32_param.module.decoder.layers.3.self_attention.linear_qkv.weight', 'optimizer.state.exp_avg_sq.module.decoder.layers.19.mixer.dense_projection.weight', 'optimizer.state.exp_avg_sq.module.decoder.layers.11.mixer.dense.bias', 'optimizer.state.exp_avg_sq.module.decoder.layers.9.mixer.mixer.filter.p', 'optimizer.state.fp32_param.module.decoder.layers.5.mixer.mixer.conv_bias', 'optimizer.state.exp_avg_sq.module.decoder.layers.6.mixer.mixer.filter.R', 'optimizer.state.exp_avg.module.decoder.layers.11.mixer.hyena_proj_conv.short_conv_weight', 'optimizer.state.exp_avg_sq.module.decoder.layers.14.mixer.hyena_proj_conv.short_conv_weight', 'optimizer.state.exp_avg_sq.module.decoder.layers.9.mixer.mixer.filter.R', 'optimizer.state.fp32_param.module.decoder.layers.16.mlp.linear_fc1.weight', 'optimizer.state.exp_avg.module.decoder.layers.4.mlp.linear_fc1.weight', 'optimizer.state.exp_avg.module.decoder.layers.14.mixer.dense.weight', 'optimizer.state.exp_avg_sq.module.decoder.layers.6.mixer.dense_projection.weight', 'optimizer.state.exp_avg_sq.module.decoder.layers.9.mixer.dense_projection.weight', 'optimizer.state.fp32_param.module.decoder.layers.23.mlp.linear_fc1.layer_norm_weight', 'optimizer.state.exp_avg.module.decoder.layers.0.mlp.linear_fc2.weight', 'optimizer.state.fp32_param.module.decoder.layers.10.self_attention.linear_qkv.weight', 'optimizer.state.exp_avg_sq.module.decoder.layers.9.mixer.dense.weight', 'optimizer.state.exp_avg_sq.module.decoder.layers.14.mlp.linear_fc1.weight', 'optimizer.state.exp_avg_sq.module.decoder.layers.12.mlp.linear_fc1.weight', 'optimizer.state.exp_avg.module.decoder.layers.24.self_attention.linear_qkv.weight', 'optimizer.state.exp_avg.module.decoder.layers.22.mixer.dense_projection.layer_norm_weight', 'optimizer.state.fp32_param.module.decoder.layers.11.mlp.linear_fc2.weight', 'optimizer.state.exp_avg_sq.module.decoder.layers.23.mixer.dense_projection.weight', 'optimizer.state.exp_avg_sq.module.decoder.layers.20.mlp.linear_fc1.weight', 'optimizer.state.exp_avg_sq.module.decoder.layers.13.mixer.dense.weight', 'optimizer.state.exp_avg_sq.module.decoder.layers.4.mlp.linear_fc1.weight', 'optimizer.state.exp_avg_sq.module.decoder.layers.24.mlp.linear_fc2.weight', 'optimizer.state.exp_avg.module.decoder.layers.24.mlp.linear_fc2.weight', 'optimizer.state.fp32_param.module.decoder.layers.2.mlp.linear_fc1.layer_norm_weight', 'optimizer.state.exp_avg_sq.module.decoder.layers.5.mixer.hyena_proj_conv.short_conv_weight', 'optimizer.state.fp32_param.module.decoder.layers.12.mlp.linear_fc1.layer_norm_weight', 'optimizer.state.exp_avg_sq.module.decoder.layers.2.mixer.dense_projection.layer_norm_weight', 'optimizer.state.exp_avg_sq.module.decoder.layers.2.mlp.linear_fc1.weight', 'optimizer.state.exp_avg.module.decoder.layers.0.mixer.dense_projection.layer_norm_weight', 'optimizer.state.exp_avg_sq.module.decoder.layers.5.mlp.linear_fc1.layer_norm_weight', 'optimizer.state.exp_avg.module.decoder.layers.8.mixer.hyena_proj_conv.short_conv_weight', 'optimizer.state.exp_avg.module.decoder.layers.6.mixer.mixer.conv_bias', 'optimizer.state.exp_avg_sq.module.decoder.layers.15.mlp.linear_fc1.weight', 'optimizer.state.fp32_param.module.decoder.layers.21.mixer.dense_projection.layer_norm_weight', 'optimizer.state.fp32_param.module.decoder.layers.8.mlp.linear_fc1.weight', 'optimizer.state.fp32_param.module.decoder.layers.20.mlp.linear_fc2.weight', 'optimizer.state.fp32_param.module.decoder.layers.23.mixer.dense_projection.layer_norm_weight', 'optimizer.state.exp_avg.module.decoder.layers.23.mlp.linear_fc2.weight', 'optimizer.state.exp_avg.module.decoder.layers.11.mixer.mixer.short_conv.short_conv_weight', 'optimizer.state.fp32_param.module.decoder.final_norm.weight', 'optimizer.state.fp32_param.module.decoder.layers.0.mixer.hyena_proj_conv.short_conv_weight', 'optimizer.state.fp32_param.module.decoder.layers.18.mixer.dense.bias', 'optimizer.state.exp_avg.module.decoder.layers.16.mixer.mixer.conv_bias', 'optimizer.state.exp_avg_sq.module.decoder.layers.24.mlp.linear_fc1.layer_norm_weight', 'optimizer.state.fp32_param.module.decoder.layers.0.mixer.mixer.short_conv.short_conv_weight', 'optimizer.state.exp_avg.module.decoder.layers.13.mixer.dense.bias', 'optimizer.state.exp_avg_sq.module.decoder.layers.22.mixer.dense_projection.layer_norm_weight', 'optimizer.state.exp_avg.module.decoder.layers.3.self_attention.linear_qkv.layer_norm_weight', 'optimizer.state.fp32_param.module.decoder.layers.18.mixer.dense_projection.weight', 'optimizer.state.fp32_param.module.decoder.layers.3.mlp.linear_fc1.weight', 'optimizer.state.exp_avg.module.decoder.layers.14.mlp.linear_fc1.weight', 'optimizer.state.exp_avg_sq.module.decoder.layers.14.mixer.mixer.short_conv.short_conv_weight', 'optimizer.state.exp_avg.module.decoder.layers.12.mixer.dense_projection.weight', 'optimizer.state.exp_avg.module.decoder.layers.1.mixer.dense.bias', 'optimizer.state.fp32_param.module.decoder.layers.10.mlp.linear_fc1.layer_norm_weight', 'optimizer.state.exp_avg_sq.module.decoder.layers.5.mixer.mixer.conv_bias', 'optimizer.state.exp_avg.module.decoder.layers.1.mixer.mixer.conv_bias', 'optimizer.state.fp32_param.module.decoder.layers.4.mixer.dense.weight', 'optimizer.state.exp_avg.module.decoder.layers.13.mlp.linear_fc1.weight', 'optimizer.state.fp32_param.module.decoder.layers.6.mlp.linear_fc1.weight', 'optimizer.state.exp_avg_sq.module.decoder.layers.6.mixer.dense.weight', 'optimizer.state.exp_avg_sq.module.decoder.layers.9.mixer.dense_projection.layer_norm_weight', 'optimizer.state.fp32_param.module.decoder.layers.21.mlp.linear_fc1.layer_norm_weight', 'optimizer.state.exp_avg.module.decoder.layers.21.mlp.linear_fc1.weight', 'optimizer.state.exp_avg.module.decoder.layers.15.mixer.dense.weight', 'optimizer.state.fp32_param.module.decoder.layers.15.mixer.mixer.filter.h', 'optimizer.state.fp32_param.module.decoder.layers.9.mixer.dense_projection.layer_norm_weight', 'optimizer.state.exp_avg_sq.module.decoder.layers.12.mixer.dense_projection.weight', 'optimizer.state.exp_avg_sq.module.decoder.layers.20.mixer.mixer.filter.R', 'optimizer.state.fp32_param.module.decoder.layers.8.mixer.dense_projection.layer_norm_weight', 'optimizer.state.exp_avg.module.decoder.layers.22.mixer.dense.bias', 'optimizer.state.fp32_param.module.decoder.layers.13.mixer.mixer.filter.p', 'optimizer.state.exp_avg_sq.module.decoder.layers.21.mlp.linear_fc1.layer_norm_weight', 'optimizer.state.fp32_param.module.decoder.layers.21.mlp.linear_fc2.weight', 'optimizer.state.exp_avg.module.decoder.layers.10.self_attention.linear_proj.weight', 'optimizer.state.exp_avg_sq.module.decoder.layers.18.mixer.mixer.short_conv.short_conv_weight', 'optimizer.state.fp32_param.module.decoder.layers.24.self_attention.linear_proj.weight', 'optimizer.state.exp_avg_sq.module.decoder.layers.18.mixer.dense_projection.layer_norm_weight', 'optimizer.state.exp_avg_sq.module.decoder.layers.19.mixer.dense_projection.layer_norm_weight', 'optimizer.state.fp32_param.module.decoder.layers.24.mlp.linear_fc1.layer_norm_weight', 'optimizer.state.exp_avg_sq.module.decoder.layers.13.mlp.linear_fc2.weight', 'optimizer.state.exp_avg.module.decoder.layers.0.mixer.mixer.short_conv.short_conv_weight', 'optimizer.state.exp_avg_sq.module.decoder.layers.22.mixer.dense.weight', 'optimizer.state.fp32_param.module.decoder.layers.20.mlp.linear_fc1.weight', 'optimizer.state.fp32_param.module.decoder.layers.12.mlp.linear_fc1.weight', 'optimizer.state.fp32_param.module.decoder.layers.12.mixer.dense.weight', 'optimizer.state.fp32_param.module.decoder.layers.22.mixer.mixer.filter.h', 'optimizer.state.fp32_param.module.decoder.layers.2.mixer.dense_projection.weight', 'optimizer.state.exp_avg_sq.module.decoder.layers.15.mixer.mixer.filter.h', 'optimizer.state.exp_avg.module.decoder.layers.9.mlp.linear_fc2.weight', 'optimizer.state.exp_avg_sq.module.decoder.layers.13.mixer.dense.bias', 'optimizer.state.fp32_param.module.decoder.layers.16.mixer.dense.weight', 'optimizer.state.exp_avg.module.decoder.layers.24.self_attention.linear_qkv.layer_norm_weight', 'optimizer.state.fp32_param.module.decoder.layers.15.mixer.dense_projection.layer_norm_weight', 'optimizer.state.exp_avg.module.decoder.layers.12.mixer.dense.bias', 'optimizer.state.exp_avg.module.decoder.layers.22.mlp.linear_fc1.weight', 'optimizer.state.exp_avg.module.decoder.layers.22.mlp.linear_fc1.layer_norm_weight', 'optimizer.state.fp32_param.module.decoder.layers.7.mixer.hyena_proj_conv.short_conv_weight', 'optimizer.state.exp_avg_sq.module.decoder.layers.15.mixer.dense.bias', 'optimizer.state.exp_avg_sq.module.decoder.layers.9.mlp.linear_fc1.weight', 'optimizer.state.exp_avg_sq.module.decoder.layers.21.mixer.hyena_proj_conv.short_conv_weight', 'optimizer.state.fp32_param.module.decoder.layers.2.mixer.dense_projection.layer_norm_weight', 'optimizer.state.fp32_param.module.decoder.layers.11.mixer.hyena_proj_conv.short_conv_weight', 'optimizer.state.exp_avg.module.decoder.layers.13.mixer.mixer.filter.p', 'optimizer.state.exp_avg_sq.module.decoder.layers.13.mlp.linear_fc1.weight', 'optimizer.state.exp_avg.module.decoder.layers.13.mixer.mixer.filter.gamma', 'optimizer.state.fp32_param.module.decoder.layers.16.mlp.linear_fc2.weight', 'optimizer.state.exp_avg_sq.module.decoder.layers.2.mixer.dense.weight', 'optimizer.state.fp32_param.module.decoder.layers.20.mixer.dense_projection.weight', 'optimizer.state.fp32_param.module.decoder.layers.13.mlp.linear_fc1.weight', 'optimizer.state.exp_avg_sq.module.decoder.layers.20.mlp.linear_fc2.weight', 'optimizer.state.fp32_param.module.decoder.layers.17.self_attention.linear_qkv.layer_norm_weight', 'optimizer.state.exp_avg_sq.module.decoder.layers.16.mixer.hyena_proj_conv.short_conv_weight', 'optimizer.state.exp_avg.module.decoder.layers.16.mixer.mixer.filter.gamma', 'optimizer.state.fp32_param.module.decoder.layers.3.mlp.linear_fc1.layer_norm_weight', 'optimizer.state.exp_avg.module.decoder.layers.18.mixer.dense.weight', 'optimizer.state.exp_avg_sq.module.decoder.layers.11.mixer.mixer.short_conv.short_conv_weight', 'optimizer.state.fp32_param.module.decoder.layers.2.mixer.mixer.filter.R', 'optimizer.state.exp_avg_sq.module.decoder.layers.16.mixer.dense.bias', 'optimizer.state.exp_avg.module.decoder.layers.5.mlp.linear_fc1.weight', 'optimizer.state.exp_avg.module.decoder.layers.6.mixer.dense.weight', 'optimizer.state.exp_avg.module.decoder.layers.24.mlp.linear_fc1.layer_norm_weight', 'optimizer.state.fp32_param.module.decoder.layers.1.mlp.linear_fc2.weight', 'optimizer.state.fp32_param.module.decoder.layers.20.mlp.linear_fc1.layer_norm_weight', 'optimizer.state.exp_avg.module.decoder.layers.11.mlp.linear_fc1.weight', 'optimizer.state.exp_avg.module.decoder.layers.8.mixer.dense_projection.layer_norm_weight', 'optimizer.state.exp_avg_sq.module.decoder.layers.23.mlp.linear_fc1.weight', 'optimizer.state.exp_avg_sq.module.decoder.layers.5.mlp.linear_fc1.weight', 'optimizer.state.fp32_param.module.decoder.layers.15.mixer.dense.weight', 'optimizer.state.exp_avg_sq.module.decoder.layers.11.mixer.dense_projection.layer_norm_weight', 'optimizer.state.exp_avg.module.decoder.layers.9.mixer.hyena_proj_conv.short_conv_weight', 'optimizer.state.exp_avg.module.decoder.layers.8.mixer.dense_projection.weight', 'optimizer.state.fp32_param.module.decoder.layers.7.mixer.dense_projection.layer_norm_weight', 'optimizer.state.fp32_param.module.decoder.layers.10.mlp.linear_fc2.weight', 'optimizer.state.exp_avg.module.decoder.layers.7.mixer.dense.bias', 'optimizer.state.exp_avg_sq.module.decoder.layers.10.mlp.linear_fc1.layer_norm_weight', 'optimizer.state.exp_avg.module.decoder.layers.14.mixer.dense_projection.weight', 'optimizer.state.fp32_param.module.decoder.layers.15.mlp.linear_fc2.weight', 'optimizer.state.exp_avg_sq.module.decoder.layers.4.mixer.dense.weight', 'optimizer.state.exp_avg_sq.module.decoder.layers.7.mixer.dense.bias', 'optimizer.state.exp_avg_sq.module.decoder.layers.6.mixer.mixer.filter.gamma', 'optimizer.state.fp32_param.module.decoder.layers.21.mixer.hyena_proj_conv.short_conv_weight', 'optimizer.state.exp_avg.module.decoder.layers.19.mixer.mixer.filter.h', 'optimizer.state.exp_avg.module.decoder.layers.0.mixer.dense_projection.weight', 'optimizer.state.fp32_param.module.decoder.layers.15.mixer.dense.bias', 'optimizer.state.exp_avg_sq.module.decoder.layers.11.mixer.hyena_proj_conv.short_conv_weight', 'optimizer.state.exp_avg_sq.module.decoder.layers.17.mlp.linear_fc1.weight', 'optimizer.state.exp_avg.module.decoder.layers.11.mixer.dense.bias', 'optimizer.state.fp32_param.module.decoder.layers.21.mixer.dense.weight', 'optimizer.state.exp_avg.module.decoder.layers.20.mlp.linear_fc1.layer_norm_weight', 'optimizer.state.exp_avg.module.decoder.layers.21.mlp.linear_fc2.weight', 'optimizer.state.exp_avg.module.decoder.layers.14.mlp.linear_fc1.layer_norm_weight', 'optimizer.state.exp_avg_sq.module.decoder.layers.14.mixer.dense_projection.weight', 'optimizer.state.fp32_param.module.decoder.layers.23.mixer.dense.weight', 'optimizer.state.exp_avg.module.decoder.layers.9.mixer.mixer.filter.gamma', 'optimizer.state.fp32_param.module.decoder.layers.3.self_attention.linear_qkv.layer_norm_weight', 'optimizer.state.exp_avg_sq.module.decoder.layers.1.mlp.linear_fc1.weight', 'optimizer.state.fp32_param.module.decoder.layers.5.mixer.dense_projection.layer_norm_weight', 'optimizer.state.exp_avg.module.decoder.layers.23.mixer.mixer.filter.gamma', 'optimizer.state.exp_avg.module.decoder.layers.13.mixer.mixer.filter.R', 'optimizer.state.exp_avg.module.decoder.layers.3.mlp.linear_fc1.layer_norm_weight', 'optimizer.state.fp32_param.module.decoder.layers.13.mixer.mixer.conv_bias', 'optimizer.state.exp_avg.module.decoder.layers.19.mlp.linear_fc2.weight', 'optimizer.state.fp32_param.module.decoder.layers.5.mixer.dense.weight', 'optimizer.state.exp_avg.module.decoder.layers.21.mixer.mixer.short_conv.short_conv_weight', 'optimizer.state.fp32_param.module.decoder.layers.6.mixer.dense_projection.weight', 'optimizer.state.exp_avg_sq.module.decoder.layers.0.mixer.dense.weight', 'optimizer.state.fp32_param.module.decoder.layers.21.mixer.dense_projection.weight', 'optimizer.state.exp_avg_sq.module.decoder.layers.21.mixer.dense.weight', 'optimizer.state.exp_avg_sq.module.decoder.layers.9.mixer.dense.bias', 'optimizer.state.fp32_param.module.decoder.layers.1.mixer.dense.bias', 'optimizer.state.fp32_param.module.decoder.layers.15.mlp.linear_fc1.layer_norm_weight', 'optimizer.state.fp32_param.module.decoder.layers.14.mlp.linear_fc2.weight', 'optimizer.state.exp_avg.module.decoder.layers.18.mixer.hyena_proj_conv.short_conv_weight', 'optimizer.state.exp_avg.module.decoder.layers.9.mixer.dense_projection.layer_norm_weight', 'optimizer.state.exp_avg.module.decoder.layers.17.self_attention.linear_qkv.layer_norm_weight', 'optimizer.state.exp_avg.module.decoder.layers.7.mlp.linear_fc2.weight', 'optimizer.state.fp32_param.module.decoder.layers.16.mlp.linear_fc1.layer_norm_weight', 'optimizer.state.fp32_param.module.decoder.layers.13.mixer.dense.bias', 'optimizer.state.exp_avg.module.decoder.layers.10.self_attention.linear_proj.bias', 'optimizer.state.exp_avg_sq.module.decoder.layers.18.mixer.hyena_proj_conv.short_conv_weight', 'optimizer.state.exp_avg.module.decoder.layers.10.self_attention.linear_qkv.layer_norm_weight', 'optimizer.state.exp_avg_sq.module.decoder.layers.8.mixer.dense_projection.layer_norm_weight', 'optimizer.state.exp_avg_sq.module.decoder.layers.6.mixer.mixer.filter.p', 'optimizer.state.exp_avg_sq.module.decoder.layers.24.self_attention.linear_qkv.layer_norm_weight', 'optimizer.state.exp_avg_sq.module.decoder.layers.19.mixer.mixer.conv_bias', 'optimizer.state.exp_avg.module.decoder.layers.13.mixer.mixer.conv_bias', 'optimizer.state.exp_avg.module.decoder.layers.23.mixer.dense_projection.layer_norm_weight', 'optimizer.state.exp_avg.module.decoder.layers.10.mlp.linear_fc1.weight', 'optimizer.state.fp32_param.module.decoder.layers.13.mixer.hyena_proj_conv.short_conv_weight', 'optimizer.state.exp_avg.module.decoder.layers.20.mixer.dense_projection.weight', 'optimizer.state.exp_avg_sq.module.decoder.layers.8.mixer.dense_projection.weight', 'optimizer.state.fp32_param.module.decoder.layers.4.mixer.dense.bias', 'optimizer.state.fp32_param.module.decoder.layers.17.mlp.linear_fc1.layer_norm_weight', 'optimizer.state.exp_avg_sq.module.decoder.layers.2.mixer.dense_projection.weight', 'optimizer.state.exp_avg_sq.module.decoder.layers.13.mixer.dense_projection.weight', 'optimizer.state.fp32_param.module.decoder.layers.10.mlp.linear_fc1.weight', 'optimizer.state.exp_avg_sq.module.decoder.layers.19.mlp.linear_fc1.weight', 'optimizer.state.exp_avg.module.decoder.layers.14.mixer.mixer.short_conv.short_conv_weight', 'optimizer.state.exp_avg.module.decoder.layers.9.mlp.linear_fc1.weight', 'optimizer.state.fp32_param.module.decoder.layers.5.mixer.dense.bias', 'optimizer.state.exp_avg.module.decoder.layers.6.mixer.dense_projection.layer_norm_weight', 'optimizer.state.exp_avg.module.decoder.layers.11.mixer.dense_projection.layer_norm_weight', 'optimizer.state.fp32_param.module.decoder.layers.20.mixer.dense.weight', 'optimizer.state.fp32_param.module.decoder.layers.14.mixer.dense.weight', 'optimizer.state.exp_avg.module.decoder.layers.10.mlp.linear_fc2.weight', 'optimizer.state.exp_avg_sq.module.decoder.layers.22.mixer.dense.bias', 'optimizer.state.exp_avg.module.decoder.layers.4.mixer.dense.weight', 'optimizer.state.exp_avg.module.decoder.layers.1.mixer.hyena_proj_conv.short_conv_weight', 'optimizer.state.fp32_param.module.decoder.layers.13.mixer.dense_projection.weight', 'optimizer.state.exp_avg.module.decoder.layers.23.mixer.dense_projection.weight', 'optimizer.state.exp_avg.module.decoder.layers.4.mixer.hyena_proj_conv.short_conv_weight', 'optimizer.state.exp_avg_sq.module.decoder.layers.23.mlp.linear_fc1.layer_norm_weight', 'optimizer.state.fp32_param.module.decoder.layers.23.mixer.dense_projection.weight', 'optimizer.state.exp_avg_sq.module.decoder.layers.13.mixer.mixer.conv_bias', 'optimizer.state.exp_avg_sq.module.decoder.layers.0.mlp.linear_fc1.weight', 'optimizer.state.fp32_param.module.embedding.word_embeddings.weight', 'optimizer.state.fp32_param.module.decoder.layers.12.mixer.dense_projection.weight', 'optimizer.state.exp_avg.module.decoder.layers.17.self_attention.linear_proj.bias', 'optimizer.state.fp32_param.module.decoder.layers.8.mixer.hyena_proj_conv.short_conv_weight', 'optimizer.state.fp32_param.module.decoder.layers.19.mixer.dense_projection.weight', 'optimizer.state.exp_avg.module.decoder.layers.15.mixer.mixer.filter.h', 'optimizer.state.exp_avg_sq.module.decoder.layers.23.mixer.mixer.conv_bias', 'optimizer.state.exp_avg_sq.module.decoder.layers.4.mixer.mixer.short_conv.short_conv_weight', 'optimizer.state.exp_avg.module.decoder.layers.16.mlp.linear_fc1.weight', 'optimizer.state.exp_avg_sq.module.decoder.layers.19.mixer.dense.bias', 'optimizer.state.fp32_param.module.decoder.layers.16.mixer.hyena_proj_conv.short_conv_weight', 'optimizer.state.fp32_param.module.decoder.layers.8.mlp.linear_fc2.weight', 'optimizer.state.exp_avg.module.decoder.layers.17.mlp.linear_fc2.weight', 'optimizer.state.exp_avg.module.decoder.layers.4.mixer.dense.bias', 'optimizer.state.exp_avg_sq.module.decoder.layers.8.mixer.hyena_proj_conv.short_conv_weight', 'optimizer.state.fp32_param.module.decoder.layers.6.mixer.dense.bias', 'optimizer.state.exp_avg.module.decoder.layers.3.mlp.linear_fc2.weight', 'optimizer.state.exp_avg.module.decoder.layers.20.mlp.linear_fc2.weight', 'optimizer.state.exp_avg.module.decoder.layers.2.mixer.mixer.filter.R', 'optimizer.state.fp32_param.module.decoder.layers.21.mlp.linear_fc1.weight', 'optimizer.state.exp_avg.module.decoder.layers.6.mixer.mixer.filter.p', 'optimizer.state.exp_avg.module.decoder.layers.16.mlp.linear_fc2.weight', 'optimizer.state.fp32_param.module.decoder.layers.2.mlp.linear_fc1.weight', 'optimizer.state.exp_avg_sq.module.decoder.layers.12.mixer.mixer.filter.h', 'optimizer.state.exp_avg.module.decoder.layers.16.mixer.dense.bias', 'optimizer.state.fp32_param.module.decoder.layers.3.self_attention.linear_proj.bias', 'optimizer.state.fp32_param.module.decoder.layers.18.mixer.hyena_proj_conv.short_conv_weight', 'optimizer.state.exp_avg.module.decoder.layers.2.mixer.hyena_proj_conv.short_conv_weight', 'optimizer.state.exp_avg_sq.module.decoder.layers.5.mixer.dense_projection.layer_norm_weight', 'optimizer.state.exp_avg.module.decoder.layers.9.mlp.linear_fc1.layer_norm_weight', 'optimizer.state.fp32_param.module.decoder.layers.0.mixer.dense.weight', 'optimizer.state.exp_avg.module.decoder.layers.11.mixer.dense.weight', 'optimizer.state.exp_avg_sq.module.decoder.layers.20.mixer.dense_projection.layer_norm_weight', 'optimizer.state.exp_avg.module.decoder.layers.7.mixer.dense.weight', 'optimizer.state.exp_avg.module.decoder.layers.5.mixer.dense.weight', 'optimizer.state.exp_avg_sq.module.decoder.layers.23.mlp.linear_fc2.weight', 'optimizer.state.fp32_param.module.decoder.layers.23.mixer.mixer.filter.p', 'optimizer.state.fp32_param.module.decoder.layers.10.self_attention.linear_proj.weight', 'optimizer.state.exp_avg_sq.module.decoder.layers.12.mixer.hyena_proj_conv.short_conv_weight', 'optimizer.state.exp_avg.module.decoder.layers.22.mixer.mixer.conv_bias', 'optimizer.state.exp_avg.module.decoder.layers.20.mixer.dense.bias', 'optimizer.state.exp_avg.module.decoder.layers.19.mixer.dense.bias', 'optimizer.state.fp32_param.module.decoder.layers.10.self_attention.linear_qkv.layer_norm_weight', 'optimizer.state.fp32_param.module.decoder.layers.17.mlp.linear_fc2.weight', 'optimizer.state.fp32_param.module.decoder.layers.4.mlp.linear_fc1.layer_norm_weight', 'optimizer.state.exp_avg.module.decoder.layers.2.mixer.mixer.filter.gamma', 'optimizer.state.exp_avg.module.decoder.layers.5.mixer.hyena_proj_conv.short_conv_weight', 'optimizer.state.fp32_param.module.decoder.layers.20.mixer.hyena_proj_conv.short_conv_weight', 'optimizer.state.exp_avg_sq.module.decoder.layers.16.mlp.linear_fc2.weight', 'optimizer.state.exp_avg.module.decoder.layers.9.mixer.mixer.filter.R', 'optimizer.state.exp_avg.module.decoder.layers.24.self_attention.linear_proj.weight', 'optimizer.state.fp32_param.module.decoder.layers.0.mixer.dense.bias', 'optimizer.state.exp_avg_sq.module.decoder.layers.16.mlp.linear_fc1.weight', 'optimizer.state.exp_avg.module.decoder.layers.16.mixer.mixer.filter.R', 'optimizer.state.fp32_param.module.decoder.layers.12.mixer.mixer.filter.h', 'optimizer.state.exp_avg.module.decoder.layers.18.mixer.dense.bias', 'optimizer.state.exp_avg.module.decoder.layers.22.mixer.dense_projection.weight', 'optimizer.state.fp32_param.module.decoder.layers.22.mixer.dense_projection.weight', 'optimizer.state.exp_avg_sq.module.decoder.layers.14.mixer.dense.weight', 'optimizer.state.fp32_param.module.decoder.layers.20.mixer.mixer.filter.p', 'optimizer.state.exp_avg_sq.module.decoder.layers.11.mixer.dense_projection.weight', 'optimizer.state.fp32_param.module.decoder.layers.16.mixer.mixer.filter.p', 'optimizer.state.exp_avg_sq.module.decoder.layers.24.self_attention.linear_proj.bias', 'optimizer.state.exp_avg_sq.module.decoder.layers.4.mlp.linear_fc1.layer_norm_weight', 'optimizer.state.exp_avg_sq.module.decoder.layers.23.mixer.dense.bias', 'optimizer.state.fp32_param.module.decoder.layers.19.mixer.dense.bias', 'optimizer.state.exp_avg_sq.module.decoder.layers.15.mixer.dense.weight', 'optimizer.state.exp_avg_sq.module.decoder.layers.8.mixer.mixer.filter.h', 'optimizer.state.exp_avg.module.decoder.layers.4.mlp.linear_fc1.layer_norm_weight', 'optimizer.state.fp32_param.module.decoder.layers.13.mlp.linear_fc2.weight', 'optimizer.state.exp_avg.module.decoder.layers.7.mixer.mixer.short_conv.short_conv_weight', 'optimizer.state.exp_avg_sq.module.decoder.layers.10.self_attention.linear_qkv.layer_norm_weight', 'optimizer.state.exp_avg_sq.module.decoder.layers.12.mixer.dense.weight', 'optimizer.state.exp_avg.module.decoder.layers.24.mlp.linear_fc1.weight', 'optimizer.state.exp_avg.module.decoder.layers.21.mixer.dense.bias', 'optimizer.state.fp32_param.module.decoder.layers.11.mlp.linear_fc1.layer_norm_weight', 'optimizer.state.fp32_param.module.decoder.layers.14.mixer.dense.bias', 'optimizer.state.exp_avg_sq.module.decoder.layers.23.mixer.hyena_proj_conv.short_conv_weight', 'optimizer.state.exp_avg_sq.module.decoder.layers.19.mixer.mixer.filter.h', 'optimizer.state.exp_avg.module.decoder.layers.8.mixer.dense.bias', 'optimizer.state.exp_avg_sq.module.decoder.layers.6.mixer.dense_projection.layer_norm_weight', 'optimizer.state.exp_avg_sq.module.decoder.layers.10.self_attention.linear_qkv.weight', 'optimizer.state.exp_avg.module.decoder.layers.20.mlp.linear_fc1.weight', 'optimizer.state.fp32_param.module.decoder.layers.14.mixer.dense_projection.weight', 'optimizer.state.exp_avg_sq.module.decoder.layers.10.mlp.linear_fc1.weight', 'optimizer.state.exp_avg.module.decoder.layers.16.mixer.hyena_proj_conv.short_conv_weight', 'optimizer.state.fp32_param.module.decoder.layers.2.mixer.mixer.filter.p', 'optimizer.state.exp_avg.module.decoder.layers.8.mlp.linear_fc1.layer_norm_weight', 'optimizer.state.fp32_param.module.decoder.layers.8.mixer.dense.bias', 'optimizer.state.fp32_param.module.decoder.layers.19.mixer.mixer.filter.h', 'optimizer.state.exp_avg_sq.module.decoder.layers.1.mlp.linear_fc1.layer_norm_weight', 'optimizer.state.exp_avg_sq.module.decoder.layers.11.mixer.dense.weight', 'optimizer.state.fp32_param.module.decoder.layers.9.mixer.mixer.filter.gamma', 'optimizer.state.exp_avg.module.decoder.layers.23.mixer.dense.bias', 'optimizer.state.exp_avg.module.decoder.layers.2.mixer.mixer.filter.p', 'optimizer.state.fp32_param.module.decoder.layers.6.mixer.hyena_proj_conv.short_conv_weight', 'optimizer.state.exp_avg_sq.module.decoder.layers.5.mlp.linear_fc2.weight', 'optimizer.state.exp_avg_sq.module.decoder.layers.0.mixer.dense.bias', 'optimizer.state.fp32_param.module.decoder.layers.22.mixer.mixer.conv_bias', 'optimizer.state.exp_avg_sq.module.decoder.layers.4.mixer.dense_projection.weight', 'optimizer.state.exp_avg_sq.module.decoder.layers.17.mlp.linear_fc2.weight', 'optimizer.state.exp_avg.module.decoder.layers.8.mixer.mixer.conv_bias', 'optimizer.state.exp_avg_sq.module.decoder.layers.10.self_attention.linear_proj.bias', 'optimizer.state.exp_avg.module.decoder.layers.2.mlp.linear_fc1.weight', 'optimizer.state.exp_avg_sq.module.decoder.layers.12.mixer.mixer.conv_bias', 'optimizer.state.exp_avg_sq.module.decoder.layers.17.self_attention.linear_proj.weight', 'optimizer.state.exp_avg_sq.module.decoder.layers.20.mixer.mixer.filter.gamma', 'optimizer.state.exp_avg_sq.module.decoder.layers.0.mixer.hyena_proj_conv.short_conv_weight', 'optimizer.state.exp_avg_sq.module.decoder.layers.20.mixer.dense_projection.weight', 'optimizer.state.exp_avg_sq.module.decoder.layers.13.mixer.mixer.filter.gamma', 'optimizer.state.exp_avg.module.decoder.layers.4.mlp.linear_fc2.weight', 'optimizer.state.exp_avg_sq.module.decoder.layers.6.mixer.dense.bias', 'optimizer.state.fp32_param.module.decoder.layers.5.mixer.hyena_proj_conv.short_conv_weight', 'optimizer.state.fp32_param.module.decoder.layers.15.mixer.hyena_proj_conv.short_conv_weight', 'optimizer.state.exp_avg.module.decoder.layers.13.mixer.hyena_proj_conv.short_conv_weight', 'optimizer.state.exp_avg_sq.module.decoder.layers.12.mlp.linear_fc2.weight', 'optimizer.state.fp32_param.module.decoder.layers.0.mlp.linear_fc1.weight', 'optimizer.state.exp_avg_sq.module.decoder.layers.1.mixer.dense.weight', 'optimizer.state.exp_avg.module.decoder.layers.15.mixer.hyena_proj_conv.short_conv_weight', 'optimizer.state.fp32_param.module.decoder.layers.22.mlp.linear_fc1.weight', 'optimizer.state.fp32_param.module.decoder.layers.11.mixer.dense_projection.layer_norm_weight', 'optimizer.state.fp32_param.module.decoder.layers.4.mlp.linear_fc1.weight', 'optimizer.state.exp_avg_sq.module.decoder.layers.17.self_attention.linear_qkv.layer_norm_weight', 'optimizer.state.exp_avg.module.decoder.layers.23.mixer.hyena_proj_conv.short_conv_weight', 'optimizer.state.fp32_param.module.decoder.layers.11.mixer.dense.bias', 'optimizer.state.exp_avg.module.decoder.layers.15.mlp.linear_fc1.weight', 'optimizer.state.fp32_param.module.decoder.layers.2.mixer.mixer.filter.gamma', 'optimizer.state.exp_avg_sq.module.decoder.layers.21.mlp.linear_fc1.weight', 'optimizer.state.exp_avg.module.decoder.layers.18.mlp.linear_fc2.weight', 'optimizer.state.fp32_param.module.decoder.layers.4.mixer.dense_projection.weight', 'optimizer.state.exp_avg.module.decoder.layers.19.mixer.mixer.conv_bias', 'optimizer.state.exp_avg.module.decoder.layers.2.mlp.linear_fc1.layer_norm_weight', 'optimizer.state.exp_avg.module.decoder.layers.18.mlp.linear_fc1.layer_norm_weight', 'optimizer.state.exp_avg_sq.module.decoder.layers.8.mixer.mixer.conv_bias', 'optimizer.state.exp_avg_sq.module.decoder.layers.15.mixer.dense_projection.weight', 'optimizer.state.fp32_param.module.decoder.layers.9.mixer.dense_projection.weight', 'optimizer.state.exp_avg.module.decoder.layers.20.mixer.hyena_proj_conv.short_conv_weight', 'optimizer.state.exp_avg.module.decoder.layers.5.mlp.linear_fc1.layer_norm_weight', 'optimizer.state.exp_avg.module.decoder.layers.16.mixer.dense_projection.weight', 'optimizer.state.exp_avg_sq.module.decoder.layers.3.self_attention.linear_qkv.weight', 'optimizer.state.fp32_param.module.decoder.layers.7.mlp.linear_fc2.weight', 'optimizer.state.exp_avg_sq.module.decoder.layers.1.mixer.dense.bias', 'optimizer.state.fp32_param.module.decoder.layers.6.mixer.mixer.conv_bias', 'optimizer.state.exp_avg_sq.module.decoder.layers.7.mlp.linear_fc1.layer_norm_weight', 'optimizer.state.fp32_param.module.decoder.layers.24.mlp.linear_fc1.weight', 'optimizer.state.exp_avg_sq.module.decoder.layers.8.mlp.linear_fc1.weight', 'optimizer.state.exp_avg_sq.module.decoder.layers.7.mixer.dense_projection.layer_norm_weight', 'optimizer.state.fp32_param.module.decoder.layers.20.mixer.dense.bias', 'optimizer.state.exp_avg_sq.module.decoder.layers.17.self_attention.linear_proj.bias', 'optimizer.state.fp32_param.module.decoder.layers.15.mlp.linear_fc1.weight', 'optimizer.state.exp_avg.module.decoder.layers.14.mixer.hyena_proj_conv.short_conv_weight', 'optimizer.state.exp_avg.module.decoder.layers.0.mlp.linear_fc1.layer_norm_weight', 'optimizer.state.exp_avg.module.decoder.layers.1.mixer.mixer.filter.h', 'optimizer.state.exp_avg.module.decoder.layers.16.mlp.linear_fc1.layer_norm_weight', 'optimizer.state.exp_avg.module.decoder.layers.19.mixer.dense_projection.layer_norm_weight', 'optimizer.state.exp_avg_sq.module.decoder.layers.22.mlp.linear_fc2.weight', 'optimizer.state.exp_avg_sq.module.decoder.layers.15.mlp.linear_fc1.layer_norm_weight', 'optimizer.state.fp32_param.module.decoder.layers.8.mixer.mixer.conv_bias', 'optimizer.state.fp32_param.module.decoder.layers.18.mlp.linear_fc1.weight', 'optimizer.state.exp_avg_sq.module.decoder.layers.2.mlp.linear_fc2.weight', 'optimizer.state.exp_avg_sq.module.decoder.layers.16.mixer.dense.weight', 'optimizer.state.exp_avg.module.decoder.layers.0.mixer.dense.bias', 'optimizer.state.exp_avg_sq.module.decoder.layers.9.mixer.mixer.conv_bias', 'optimizer.state.exp_avg.module.decoder.layers.2.mixer.mixer.conv_bias', 'optimizer.state.exp_avg_sq.module.decoder.layers.24.mlp.linear_fc1.weight', 'optimizer.state.fp32_param.module.decoder.layers.18.mixer.mixer.short_conv.short_conv_weight', 'optimizer.state.exp_avg_sq.module.decoder.layers.13.mixer.hyena_proj_conv.short_conv_weight', 'optimizer.state.exp_avg.module.decoder.layers.9.mixer.dense.bias', 'optimizer.state.exp_avg.module.decoder.layers.4.mixer.dense_projection.weight', 'optimizer.state.fp32_param.module.decoder.layers.18.mixer.dense_projection.layer_norm_weight', 'optimizer.state.exp_avg.module.decoder.final_norm.weight', 'optimizer.state.fp32_param.module.decoder.layers.8.mixer.dense.weight', 'optimizer.state.exp_avg_sq.module.decoder.layers.2.mixer.mixer.filter.R', 'optimizer.state.exp_avg.module.decoder.layers.21.mlp.linear_fc1.layer_norm_weight', 'optimizer.state.fp32_param.module.decoder.layers.19.mlp.linear_fc1.layer_norm_weight', 'optimizer.state.exp_avg.module.decoder.layers.15.mixer.dense_projection.weight', 'optimizer.state.exp_avg.module.decoder.layers.19.mixer.hyena_proj_conv.short_conv_weight', 'optimizer.state.exp_avg_sq.module.decoder.layers.20.mixer.mixer.conv_bias', 'optimizer.state.fp32_param.module.decoder.layers.7.mixer.dense.bias', 'optimizer.state.fp32_param.module.decoder.layers.20.mixer.mixer.filter.R', 'optimizer.state.exp_avg.module.decoder.layers.20.mixer.mixer.filter.p', 'optimizer.state.fp32_param.module.decoder.layers.1.mixer.dense.weight', 'optimizer.state.exp_avg_sq.module.decoder.layers.2.mixer.mixer.conv_bias', 'optimizer.state.exp_avg_sq.module.decoder.layers.7.mixer.mixer.short_conv.short_conv_weight', 'optimizer.state.fp32_param.module.decoder.layers.1.mlp.linear_fc1.layer_norm_weight', 'optimizer.state.exp_avg_sq.module.decoder.layers.16.mixer.mixer.filter.p', 'optimizer.state.fp32_param.module.decoder.layers.22.mixer.dense_projection.layer_norm_weight', 'optimizer.state.exp_avg.module.decoder.layers.8.mlp.linear_fc2.weight', 'optimizer.state.exp_avg.module.decoder.layers.8.mixer.dense.weight', 'optimizer.state.fp32_param.module.decoder.layers.19.mixer.hyena_proj_conv.short_conv_weight', 'optimizer.state.fp32_param.module.decoder.layers.18.mlp.linear_fc2.weight', 'optimizer.state.exp_avg.module.decoder.layers.2.mixer.dense_projection.layer_norm_weight', 'optimizer.state.exp_avg.module.decoder.layers.9.mixer.dense_projection.weight'}. \n",
      "[NeMo I 2025-06-08 13:50:13 nemo_logging:393] Global Checkpoint Load : Rank : 0 : Start time : 1749390612.103s : Time spent in load_checkpoint: 1.479s\n",
      "[NeMo I 2025-06-08 13:50:13 nemo_logging:393] Restoring model weights from RestoreConfig(path='results/evo2/checkpoints/evo2--val_loss=1.4537-epoch=0-consumed_samples=100.0-last', adapter_path=None, load_model_state=True, load_optim_state=False, load_artifacts=False)\n",
      "[NeMo I 2025-06-08 13:50:13 nemo_logging:393] Finished restoring from RestoreConfig(path='results/evo2/checkpoints/evo2--val_loss=1.4537-epoch=0-consumed_samples=100.0-last', adapter_path=None, load_model_state=True, load_optim_state=False, load_artifacts=False), cleaning up.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tempfile\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '4'\n",
    "os.environ['TORCHINDUCTOR_CACHE_DIR'] = tempfile.mkdtemp()\n",
    "os.environ['USER'] = 'user'\n",
    "os.environ['USERNAME'] = 'user'\n",
    "!predict_evo2 \\\n",
    "    --fasta sequence_truncation/biological_truncated_sequences_fixed.fasta \\\n",
    "    --ckpt-dir results/evo2/checkpoints/evo2--val_loss=1.4537-epoch=0-consumed_samples=100.0-last \\\n",
    "    --model-size 1b \\\n",
    "    --tensor-parallel-size 1 \\\n",
    "    --pipeline-model-parallel-size 1 \\\n",
    "    --context-parallel-size 1 \\\n",
    "    --batch-size 1 \\\n",
    "    --output-dir prediction_results_06082149 \\\n",
    "    --ckpt-format torch_dist \\\n",
    "    --output-log-prob-seqs \\\n",
    "    --log-prob-collapse-option mean \\\n",
    "    --prepend-bos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "596542d6-a754-4b19-8d97-36374bed43ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not find the bitsandbytes CUDA binary at PosixPath('/usr/local/lib/python3.12/dist-packages/bitsandbytes/libbitsandbytes_cuda129.so')\n",
      "The installed version of bitsandbytes was compiled without GPU support. 8-bit optimizers, 8-bit multiplication, and GPU quantization are unavailable.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "[NeMo W 2025-06-23 12:33:04 nemo_logging:405] No version folders would be created under the log folder as 'resume_if_exists' is enabled.\n",
      "[NeMo I 2025-06-23 12:33:04 nemo_logging:393] Experiments will be logged at /tmp/tmp24sf05a5/default\n",
      "[NeMo W 2025-06-23 12:33:04 nemo_logging:405] \"update_logger_directory\" is True. Overwriting tensorboard logger \"save_dir\" to /tmp/tmp24sf05a5\n",
      "[NeMo I 2025-06-23 12:33:04 nemo_logging:393] Using byte-level tokenization\n",
      "[NeMo I 2025-06-23 12:33:05 nemo_logging:393] Rank 0 has data parallel group : [0]\n",
      "[NeMo I 2025-06-23 12:33:05 nemo_logging:393] Rank 0 has combined group of data parallel and context parallel : [0]\n",
      "[NeMo I 2025-06-23 12:33:05 nemo_logging:393] All data parallel group ranks with context parallel combined: [[0]]\n",
      "[NeMo I 2025-06-23 12:33:05 nemo_logging:393] Ranks 0 has data parallel rank: 0\n",
      "[NeMo I 2025-06-23 12:33:05 nemo_logging:393] Rank 0 has context parallel group: [0]\n",
      "[NeMo I 2025-06-23 12:33:05 nemo_logging:393] All context parallel group ranks: [[0]]\n",
      "[NeMo I 2025-06-23 12:33:05 nemo_logging:393] Ranks 0 has context parallel rank: 0\n",
      "[NeMo I 2025-06-23 12:33:05 nemo_logging:393] Rank 0 has model parallel group: [0]\n",
      "[NeMo I 2025-06-23 12:33:05 nemo_logging:393] All model parallel group ranks: [[0]]\n",
      "[NeMo I 2025-06-23 12:33:05 nemo_logging:393] Rank 0 has tensor model parallel group: [0]\n",
      "[NeMo I 2025-06-23 12:33:05 nemo_logging:393] All tensor model parallel group ranks: [[0]]\n",
      "[NeMo I 2025-06-23 12:33:05 nemo_logging:393] Rank 0 has tensor model parallel rank: 0\n",
      "[NeMo I 2025-06-23 12:33:05 nemo_logging:393] Rank 0 has pipeline model parallel group: [0]\n",
      "[NeMo I 2025-06-23 12:33:05 nemo_logging:393] Rank 0 has embedding group: [0]\n",
      "[NeMo I 2025-06-23 12:33:05 nemo_logging:393] All pipeline model parallel group ranks: [[0]]\n",
      "[NeMo I 2025-06-23 12:33:05 nemo_logging:393] Rank 0 has pipeline model parallel rank 0\n",
      "[NeMo I 2025-06-23 12:33:05 nemo_logging:393] All embedding group ranks: [[0]]\n",
      "[NeMo I 2025-06-23 12:33:05 nemo_logging:393] Rank 0 has embedding rank: 0\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 1 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[NeMo I 2025-06-23 12:33:05 num_microbatches_calculator:228] setting number of microbatches to constant 1\n",
      "[NeMo I 2025-06-23 12:33:05 nemo_logging:393] Padded vocab_size: 512, original vocab_size: 512, dummy tokens: 0.\n",
      "[NeMo W 2025-06-23 12:33:05 random:222] CPU RNG state changed within GPU RNG context\n",
      "[NeMo W 2025-06-23 12:33:05 random:222] CPU RNG state changed within GPU RNG context\n",
      "[NeMo W 2025-06-23 12:33:05 random:222] CPU RNG state changed within GPU RNG context\n",
      "[NeMo W 2025-06-23 12:33:05 random:222] CPU RNG state changed within GPU RNG context\n",
      "[NeMo W 2025-06-23 12:33:05 random:222] CPU RNG state changed within GPU RNG context\n",
      "[NeMo W 2025-06-23 12:33:05 random:222] CPU RNG state changed within GPU RNG context\n",
      "[NeMo W 2025-06-23 12:33:05 random:222] CPU RNG state changed within GPU RNG context\n",
      "[NeMo W 2025-06-23 12:33:05 random:222] CPU RNG state changed within GPU RNG context\n",
      "[NeMo W 2025-06-23 12:33:05 random:222] CPU RNG state changed within GPU RNG context\n",
      "[NeMo W 2025-06-23 12:33:05 random:222] CPU RNG state changed within GPU RNG context\n",
      "[NeMo W 2025-06-23 12:33:05 random:222] CPU RNG state changed within GPU RNG context\n",
      "[NeMo W 2025-06-23 12:33:05 random:222] CPU RNG state changed within GPU RNG context\n",
      "[NeMo W 2025-06-23 12:33:05 random:222] CPU RNG state changed within GPU RNG context\n",
      "[NeMo W 2025-06-23 12:33:05 random:222] CPU RNG state changed within GPU RNG context\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [4]\n",
      "[NeMo W 2025-06-23 12:33:05 nemo_logging:405] Could not copy Trainer's 'max_steps' to LR scheduler's 'max_steps'. If you are not using an LR scheduler, this warning can safely be ignored.\n",
      "[NeMo I 2025-06-23 12:33:05 nemo_logging:393]  > number of parameters on (tensor, pipeline) model parallel rank (0 ,0): 1108204800\n",
      "[NeMo I 2025-06-23 12:33:05 utils:554] Setting up DistributedDataParallel with config DistributedDataParallelConfig(grad_reduce_in_fp32=False, overlap_grad_reduce=False, overlap_param_gather=False, align_param_gather=False, use_distributed_optimizer=False, num_distributed_optimizer_instances=1, check_for_nan_in_grad=True, check_for_large_grads=False, bucket_size=None, pad_buckets_for_high_nccl_busbw=False, average_in_collective=False, fp8_param_gather=False, use_custom_fsdp=False, data_parallel_sharding_strategy='no_shard', gradient_reduce_div_fusion=True, suggested_communication_unit_size=None, preserve_fp32_weights=True, keep_fp8_transpose_cache_when_using_custom_fsdp=False)\n",
      "[NeMo I 2025-06-23 12:33:05 utils:575] Number of buckets for gradient all-reduce / reduce-scatter: 1\n",
      "    Params for bucket 1 (1108204800 elements, 1108204800 padded size):\n",
      "    \tmodule.decoder.final_norm.weight\n",
      "    \tmodule.decoder.layers.23.mixer.mixer.filter.R\n",
      "    \tmodule.decoder.layers.20.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.17.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.10.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.8.mixer.dense.bias\n",
      "    \tmodule.decoder.layers.4.mixer.dense.bias\n",
      "    \tmodule.decoder.layers.2.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.0.mixer.dense_projection.weight\n",
      "    \tmodule.decoder.layers.22.mixer.dense_projection.layer_norm_weight\n",
      "    \tmodule.decoder.layers.19.mixer.dense.bias\n",
      "    \tmodule.decoder.layers.18.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.14.mixer.dense_projection.layer_norm_weight\n",
      "    \tmodule.decoder.layers.11.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.7.mixer.dense_projection.layer_norm_weight\n",
      "    \tmodule.decoder.layers.3.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.1.mixer.dense.weight\n",
      "    \tmodule.decoder.layers.22.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.19.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.12.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.8.mixer.mixer.conv_bias\n",
      "    \tmodule.decoder.layers.5.mixer.dense_projection.layer_norm_weight\n",
      "    \tmodule.decoder.layers.0.mixer.hyena_proj_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.23.mixer.dense.weight\n",
      "    \tmodule.decoder.layers.18.mixer.dense.weight\n",
      "    \tmodule.decoder.layers.16.mixer.dense_projection.layer_norm_weight\n",
      "    \tmodule.decoder.layers.15.mixer.mixer.conv_bias\n",
      "    \tmodule.decoder.layers.11.mixer.dense.weight\n",
      "    \tmodule.decoder.layers.9.mixer.dense_projection.layer_norm_weight\n",
      "    \tmodule.decoder.layers.5.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.5.mixer.dense.bias\n",
      "    \tmodule.decoder.layers.24.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.22.mixer.dense.bias\n",
      "    \tmodule.decoder.layers.16.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.9.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.2.mixer.mixer.filter.gamma\n",
      "    \tmodule.decoder.layers.21.mixer.dense.bias\n",
      "    \tmodule.decoder.layers.20.mixer.mixer.filter.R\n",
      "    \tmodule.decoder.layers.18.mixer.dense.bias\n",
      "    \tmodule.decoder.layers.17.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.13.mixer.mixer.filter.R\n",
      "    \tmodule.decoder.layers.10.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.9.mixer.mixer.conv_bias\n",
      "    \tmodule.decoder.layers.6.mixer.mixer.conv_bias\n",
      "    \tmodule.decoder.layers.3.self_attention.linear_proj.weight\n",
      "    \tmodule.decoder.layers.0.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.22.mixer.mixer.conv_bias\n",
      "    \tmodule.decoder.layers.19.mixer.dense_projection.layer_norm_weight\n",
      "    \tmodule.decoder.layers.14.mixer.mixer.short_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.12.mixer.dense_projection.layer_norm_weight\n",
      "    \tmodule.decoder.layers.7.mixer.mixer.short_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.4.mixer.dense_projection.layer_norm_weight\n",
      "    \tmodule.decoder.layers.1.mixer.dense.bias\n",
      "    \tmodule.decoder.layers.23.mixer.dense_projection.layer_norm_weight\n",
      "    \tmodule.decoder.layers.19.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.19.mixer.mixer.conv_bias\n",
      "    \tmodule.decoder.layers.15.mixer.hyena_proj_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.12.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.12.mixer.dense.bias\n",
      "    \tmodule.decoder.layers.8.mixer.hyena_proj_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.2.mixer.mixer.filter.p\n",
      "    \tmodule.decoder.layers.0.mixer.mixer.short_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.23.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.20.mixer.dense.weight\n",
      "    \tmodule.decoder.layers.16.mixer.mixer.filter.gamma\n",
      "    \tmodule.decoder.layers.13.mixer.dense.weight\n",
      "    \tmodule.decoder.layers.10.self_attention.linear_proj.bias\n",
      "    \tmodule.decoder.layers.9.mixer.mixer.filter.gamma\n",
      "    \tmodule.decoder.layers.6.mixer.dense.weight\n",
      "    \tmodule.decoder.layers.6.mixer.dense_projection.layer_norm_weight\n",
      "    \tmodule.decoder.layers.24.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.23.mixer.mixer.conv_bias\n",
      "    \tmodule.decoder.layers.17.self_attention.linear_proj.weight\n",
      "    \tmodule.decoder.layers.15.mixer.mixer.filter.h\n",
      "    \tmodule.decoder.layers.10.self_attention.linear_proj.weight\n",
      "    \tmodule.decoder.layers.2.mixer.hyena_proj_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.0.mixer.dense.bias\n",
      "    \tmodule.decoder.layers.21.mixer.dense_projection.layer_norm_weight\n",
      "    \tmodule.decoder.layers.18.mixer.dense_projection.layer_norm_weight\n",
      "    \tmodule.decoder.layers.15.mixer.dense.bias\n",
      "    \tmodule.decoder.layers.15.mixer.dense.weight\n",
      "    \tmodule.decoder.layers.11.mixer.dense_projection.layer_norm_weight\n",
      "    \tmodule.decoder.layers.8.mixer.dense.weight\n",
      "    \tmodule.decoder.layers.6.mixer.dense.bias\n",
      "    \tmodule.decoder.layers.2.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.0.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.22.mixer.hyena_proj_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.16.mixer.mixer.filter.p\n",
      "    \tmodule.decoder.layers.14.mixer.hyena_proj_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.9.mixer.mixer.filter.p\n",
      "    \tmodule.decoder.layers.7.mixer.hyena_proj_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.4.mixer.mixer.short_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.2.mixer.mixer.conv_bias\n",
      "    \tmodule.decoder.layers.23.mixer.mixer.filter.gamma\n",
      "    \tmodule.decoder.layers.20.mixer.dense_projection.layer_norm_weight\n",
      "    \tmodule.decoder.layers.15.mixer.dense_projection.weight\n",
      "    \tmodule.decoder.layers.13.mixer.dense_projection.layer_norm_weight\n",
      "    \tmodule.decoder.layers.8.mixer.dense_projection.weight\n",
      "    \tmodule.decoder.layers.5.mixer.hyena_proj_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.2.mixer.dense.bias\n",
      "    \tmodule.decoder.layers.0.mixer.dense.weight\n",
      "    \tmodule.decoder.layers.24.self_attention.linear_proj.weight\n",
      "    \tmodule.decoder.layers.20.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.16.mixer.hyena_proj_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.13.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.9.mixer.hyena_proj_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.6.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.6.mixer.mixer.filter.gamma\n",
      "    \tmodule.decoder.layers.3.self_attention.linear_qkv.weight\n",
      "    \tmodule.decoder.layers.3.self_attention.linear_proj.bias\n",
      "    \tmodule.decoder.layers.22.mixer.dense.weight\n",
      "    \tmodule.decoder.layers.16.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.14.mixer.dense.bias\n",
      "    \tmodule.decoder.layers.9.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.8.mixer.mixer.filter.h\n",
      "    \tmodule.decoder.layers.5.mixer.mixer.filter.h\n",
      "    \tmodule.decoder.layers.2.mixer.dense_projection.weight\n",
      "    \tmodule.decoder.layers.23.mixer.mixer.filter.p\n",
      "    \tmodule.decoder.layers.21.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.18.mixer.mixer.short_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.15.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.11.mixer.mixer.short_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.8.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.6.mixer.mixer.filter.R\n",
      "    \tmodule.decoder.layers.5.mixer.dense.weight\n",
      "    \tmodule.decoder.layers.2.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.1.mixer.dense_projection.layer_norm_weight\n",
      "    \tmodule.decoder.layers.22.mixer.dense_projection.weight\n",
      "    \tmodule.decoder.layers.19.mixer.hyena_proj_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.16.mixer.dense.bias\n",
      "    \tmodule.decoder.layers.14.mixer.dense_projection.weight\n",
      "    \tmodule.decoder.layers.12.mixer.hyena_proj_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.9.mixer.dense.bias\n",
      "    \tmodule.decoder.layers.7.mixer.dense_projection.weight\n",
      "    \tmodule.decoder.layers.4.mixer.hyena_proj_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.1.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.23.mixer.hyena_proj_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.20.mixer.mixer.filter.gamma\n",
      "    \tmodule.decoder.layers.17.self_attention.linear_qkv.weight\n",
      "    \tmodule.decoder.layers.13.mixer.mixer.filter.gamma\n",
      "    \tmodule.decoder.layers.10.self_attention.linear_qkv.weight\n",
      "    \tmodule.decoder.layers.5.mixer.dense_projection.weight\n",
      "    \tmodule.decoder.layers.23.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.22.mixer.mixer.filter.h\n",
      "    \tmodule.decoder.layers.21.mixer.dense_projection.weight\n",
      "    \tmodule.decoder.layers.19.mixer.mixer.filter.h\n",
      "    \tmodule.decoder.layers.16.mixer.dense_projection.weight\n",
      "    \tmodule.decoder.layers.12.mixer.mixer.filter.h\n",
      "    \tmodule.decoder.layers.9.mixer.dense_projection.weight\n",
      "    \tmodule.decoder.layers.6.mixer.hyena_proj_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.3.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.1.mixer.mixer.conv_bias\n",
      "    \tmodule.decoder.layers.22.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.19.mixer.dense.weight\n",
      "    \tmodule.decoder.layers.16.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.14.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.12.mixer.dense.weight\n",
      "    \tmodule.decoder.layers.9.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.7.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.5.mixer.mixer.conv_bias\n",
      "    \tmodule.decoder.layers.23.mixer.dense.bias\n",
      "    \tmodule.decoder.layers.21.mixer.hyena_proj_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.20.mixer.mixer.filter.p\n",
      "    \tmodule.decoder.layers.18.mixer.hyena_proj_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.16.mixer.mixer.conv_bias\n",
      "    \tmodule.decoder.layers.13.mixer.mixer.filter.p\n",
      "    \tmodule.decoder.layers.11.mixer.dense.bias\n",
      "    \tmodule.decoder.layers.11.mixer.hyena_proj_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.6.mixer.mixer.filter.p\n",
      "    \tmodule.decoder.layers.5.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.24.self_attention.linear_qkv.weight\n",
      "    \tmodule.decoder.layers.19.mixer.dense_projection.weight\n",
      "    \tmodule.decoder.layers.14.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.12.mixer.dense_projection.weight\n",
      "    \tmodule.decoder.layers.7.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.4.mixer.dense_projection.weight\n",
      "    \tmodule.decoder.layers.23.mixer.dense_projection.weight\n",
      "    \tmodule.decoder.layers.20.mixer.hyena_proj_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.17.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.17.self_attention.linear_proj.bias\n",
      "    \tmodule.decoder.layers.13.mixer.hyena_proj_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.10.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.embedding.word_embeddings.weight\n",
      "    \tmodule.decoder.layers.23.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.21.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.20.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.13.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.12.mixer.mixer.conv_bias\n",
      "    \tmodule.decoder.layers.6.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.6.mixer.dense_projection.weight\n",
      "    \tmodule.decoder.layers.19.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.17.self_attention.linear_qkv.layer_norm_weight\n",
      "    \tmodule.decoder.layers.14.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.12.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.10.self_attention.linear_qkv.layer_norm_weight\n",
      "    \tmodule.decoder.layers.7.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.4.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.2.mixer.mixer.filter.R\n",
      "    \tmodule.decoder.layers.0.mixer.dense_projection.layer_norm_weight\n",
      "    \tmodule.decoder.layers.21.mixer.mixer.short_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.20.mixer.dense.bias\n",
      "    \tmodule.decoder.layers.18.mixer.dense_projection.weight\n",
      "    \tmodule.decoder.layers.15.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.13.mixer.dense.bias\n",
      "    \tmodule.decoder.layers.11.mixer.dense_projection.weight\n",
      "    \tmodule.decoder.layers.8.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.1.mixer.hyena_proj_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.24.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.24.self_attention.linear_proj.bias\n",
      "    \tmodule.decoder.layers.14.mixer.dense.weight\n",
      "    \tmodule.decoder.layers.7.mixer.dense.weight\n",
      "    \tmodule.decoder.layers.4.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.1.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.20.mixer.dense_projection.weight\n",
      "    \tmodule.decoder.layers.13.mixer.dense_projection.weight\n",
      "    \tmodule.decoder.layers.2.mixer.dense.weight\n",
      "    \tmodule.decoder.layers.1.mixer.mixer.filter.h\n",
      "    \tmodule.decoder.layers.24.self_attention.linear_qkv.layer_norm_weight\n",
      "    \tmodule.decoder.layers.21.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.18.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.16.mixer.mixer.filter.R\n",
      "    \tmodule.decoder.layers.13.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.11.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.9.mixer.mixer.filter.R\n",
      "    \tmodule.decoder.layers.6.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.3.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.22.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.20.mixer.mixer.conv_bias\n",
      "    \tmodule.decoder.layers.15.mixer.dense_projection.layer_norm_weight\n",
      "    \tmodule.decoder.layers.13.mixer.mixer.conv_bias\n",
      "    \tmodule.decoder.layers.8.mixer.dense_projection.layer_norm_weight\n",
      "    \tmodule.decoder.layers.4.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.1.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.0.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.3.self_attention.linear_qkv.layer_norm_weight\n",
      "    \tmodule.decoder.layers.21.mixer.dense.weight\n",
      "    \tmodule.decoder.layers.18.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.15.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.11.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.8.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.7.mixer.dense.bias\n",
      "    \tmodule.decoder.layers.5.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.1.mixer.dense_projection.weight\n",
      "    \tmodule.decoder.layers.16.mixer.dense.weight\n",
      "    \tmodule.decoder.layers.9.mixer.dense.weight\n",
      "    \tmodule.decoder.layers.4.mixer.dense.weight\n",
      "    \tmodule.decoder.layers.2.mixer.dense_projection.layer_norm_weight\n",
      "[NeMo I 2025-06-23 12:33:06 nemo_logging:393] Doing selective restore from RestoreConfig(path='nemo2_evo2_1b_8k', adapter_path=None, load_model_state=True, load_optim_state=False, load_artifacts=False)\n",
      "[NeMo I 2025-06-23 12:33:06 nemo_logging:393] Using <megatron.core.dist_checkpointing.strategies.fully_parallel.FullyParallelLoadStrategyWrapper object at 0x76c3ee3b36e0> dist-ckpt load strategy.\n",
      "[NeMo I 2025-06-23 12:33:07 nemo_logging:393] Global Checkpoint Load : Rank : 0 : Start time : 1750681986.054s : Time spent in load_checkpoint: 1.534s\n",
      "[NeMo I 2025-06-23 12:33:07 nemo_logging:393] Restoring model weights from RestoreConfig(path='nemo2_evo2_1b_8k', adapter_path=None, load_model_state=True, load_optim_state=False, load_artifacts=False)\n",
      "[NeMo I 2025-06-23 12:33:07 nemo_logging:393] Finished restoring from RestoreConfig(path='nemo2_evo2_1b_8k', adapter_path=None, load_model_state=True, load_optim_state=False, load_artifacts=False), cleaning up.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tempfile\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '4'\n",
    "os.environ['TORCHINDUCTOR_CACHE_DIR'] = tempfile.mkdtemp()\n",
    "os.environ['USER'] = 'user'\n",
    "os.environ['USERNAME'] = 'user'\n",
    "!predict_evo2 \\\n",
    "    --fasta sequence_truncation/biological_truncated_sequences_fixed.fasta \\\n",
    "    --ckpt-dir nemo2_evo2_1b_8k \\\n",
    "    --model-size 1b \\\n",
    "    --tensor-parallel-size 1 \\\n",
    "    --pipeline-model-parallel-size 1 \\\n",
    "    --context-parallel-size 1 \\\n",
    "    --batch-size 1 \\\n",
    "    --output-dir prediction_results_nolog_XTT22_0shot \\\n",
    "    --ckpt-format torch_dist \\\n",
    "    --log-prob-collapse-option mean \\\n",
    "    --prepend-bos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bce75953-2028-4005-916c-72adf0a613c6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
