{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f1f816cb-6abb-4cf9-9a0b-d1382a4c9910",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "concat_path = \"XTT22_train.fa\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e5a015b5-fad5-4d11-adcd-2fb18c594536",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_fasta_path = os.path.abspath(concat_path)\n",
    "output_dir = os.path.abspath(\"preprocessed_data\")\n",
    "output_yaml = f\"\"\"\n",
    "- datapaths: [\"{full_fasta_path}\"]\n",
    "  output_dir: \"{output_dir}\"\n",
    "  output_prefix: XTT22_train\n",
    "  train_split: 0.9\n",
    "  valid_split: 0.05\n",
    "  test_split: 0.05\n",
    "  overwrite: True\n",
    "  embed_reverse_complement: true\n",
    "  random_reverse_complement: 0.0\n",
    "  random_lineage_dropout: 0.0\n",
    "  include_sequence_id: false\n",
    "  transcribe: \"back_transcribe\"\n",
    "  force_uppercase: false\n",
    "  indexed_dataset_dtype: \"uint8\"\n",
    "  tokenizer_type: \"Byte-Level\"\n",
    "  vocab_file: null\n",
    "  vocab_size: null\n",
    "  merges_file: null\n",
    "  pretrained_tokenizer_model: null\n",
    "  special_tokens: null\n",
    "  fast_hf_tokenizer: true\n",
    "  append_eod: true\n",
    "  enforce_sample_length: null\n",
    "  ftfy: false\n",
    "  workers: 1\n",
    "  preproc_concurrency: 100000\n",
    "  chunksize: 25\n",
    "  drop_empty_sequences: true\n",
    "  nnn_filter: false  # If you split your fasta on NNN (in human these are contigs), then you should set this to true.\n",
    "  seed: 12342  # Not relevant because we are not using random reverse complement or lineage dropout.\n",
    "\"\"\"\n",
    "with open(\"preprocess_config.yaml\", \"w\") as f:\n",
    "    print(output_yaml, file=f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aadbf5cb-03b5-4a20-96e5-7bb0a7e5b942",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2025-05-24 12:37:06 nemo_logging:393] Using byte-level tokenization\n",
      "[NeMo I 2025-05-24 12:37:06 nemo_logging:393] Created temporary binary datasets: /workspace/preprocessed_data/XTT22_train_byte-level_train.bin.tmp /workspace/preprocessed_data/XTT22_train_byte-level_val.bin.tmp /workspace/preprocessed_data/XTT22_train_byte-level_test.bin.tmp\n",
      "[NeMo I 2025-05-24 13:12:11 nemo_logging:393] Average preprocessing time per sequence: 0.04470627161196968\n",
      "[NeMo I 2025-05-24 13:12:11 nemo_logging:393] Average indexing time per sequence: 0.1463382052460373\n",
      "[NeMo I 2025-05-24 13:12:11 nemo_logging:393] Number of sequences processed: 12092\n",
      "[NeMo I 2025-05-24 13:12:11 nemo_logging:393] Finished preprocessing XTT22_train ([PosixPath('/workspace/XTT22_train.fa')]) in 2105.082 seconds with 1 workers.\n"
     ]
    }
   ],
   "source": [
    "!preprocess_evo2 --config preprocess_config.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3df5d34a-d5fe-4fa9-ac3d-65b9696a9045",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 14G\n",
      "-rw-r--r-- 1 root root 936M May 24 13:11 XTT22_train_byte-level_test.bin\n",
      "-rw-r--r-- 1 root root  12K May 24 13:12 XTT22_train_byte-level_test.idx\n",
      "-rw-r--r-- 1 root root  13G May 24 13:12 XTT22_train_byte-level_train.bin\n",
      "-rw-r--r-- 1 root root 213K May 24 13:12 XTT22_train_byte-level_train.idx\n",
      "-rw-r--r-- 1 root root 411M May 24 13:12 XTT22_train_byte-level_val.bin\n",
      "-rw-r--r-- 1 root root  12K May 24 13:12 XTT22_train_byte-level_val.idx\n"
     ]
    }
   ],
   "source": [
    "!ls -lh preprocessed_data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "240cf8a0-258b-424c-9e2a-55999a0c8a5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not find the bitsandbytes CUDA binary at PosixPath('/usr/local/lib/python3.12/dist-packages/bitsandbytes/libbitsandbytes_cuda129.so')\n",
      "The installed version of bitsandbytes was compiled without GPU support. 8-bit optimizers, 8-bit multiplication, and GPU quantization are unavailable.\n",
      "[NeMo I 2025-05-24 15:02:39 nemo_logging:393] Using byte-level tokenization\n",
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "[NeMo W 2025-05-24 15:02:39 nemo_logging:405] /usr/local/lib/python3.12/dist-packages/lightning/pytorch/trainer/setup.py:177: GPU available but not used. You can set it by doing `Trainer(accelerator='gpu')`.\n",
      "    \n",
      "[NeMo I 2025-05-24 15:02:39 nemo_logging:393] Fixing mis-match between ddp-config & mcore-optimizer config\n",
      "[NeMo I 2025-05-24 15:02:39 nemo_logging:393] Rank 0 has data parallel group : [0]\n",
      "[NeMo I 2025-05-24 15:02:39 nemo_logging:393] Rank 0 has combined group of data parallel and context parallel : [0]\n",
      "[NeMo I 2025-05-24 15:02:39 nemo_logging:393] All data parallel group ranks with context parallel combined: [[0]]\n",
      "[NeMo I 2025-05-24 15:02:39 nemo_logging:393] Ranks 0 has data parallel rank: 0\n",
      "[NeMo I 2025-05-24 15:02:39 nemo_logging:393] Rank 0 has context parallel group: [0]\n",
      "[NeMo I 2025-05-24 15:02:39 nemo_logging:393] All context parallel group ranks: [[0]]\n",
      "[NeMo I 2025-05-24 15:02:39 nemo_logging:393] Ranks 0 has context parallel rank: 0\n",
      "[NeMo I 2025-05-24 15:02:39 nemo_logging:393] Rank 0 has model parallel group: [0]\n",
      "[NeMo I 2025-05-24 15:02:39 nemo_logging:393] All model parallel group ranks: [[0]]\n",
      "[NeMo I 2025-05-24 15:02:39 nemo_logging:393] Rank 0 has tensor model parallel group: [0]\n",
      "[NeMo I 2025-05-24 15:02:39 nemo_logging:393] All tensor model parallel group ranks: [[0]]\n",
      "[NeMo I 2025-05-24 15:02:39 nemo_logging:393] Rank 0 has tensor model parallel rank: 0\n",
      "[NeMo I 2025-05-24 15:02:39 nemo_logging:393] Rank 0 has pipeline model parallel group: [0]\n",
      "[NeMo I 2025-05-24 15:02:39 nemo_logging:393] Rank 0 has embedding group: [0]\n",
      "[NeMo I 2025-05-24 15:02:39 nemo_logging:393] All pipeline model parallel group ranks: [[0]]\n",
      "[NeMo I 2025-05-24 15:02:39 nemo_logging:393] Rank 0 has pipeline model parallel rank 0\n",
      "[NeMo I 2025-05-24 15:02:39 nemo_logging:393] All embedding group ranks: [[0]]\n",
      "[NeMo I 2025-05-24 15:02:39 nemo_logging:393] Rank 0 has embedding rank: 0\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=gloo\n",
      "All distributed processes registered. Starting with 1 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[NeMo W 2025-05-24 15:02:39 nemo_logging:405] /usr/local/lib/python3.12/dist-packages/lightning/pytorch/trainer/trainer.py:1090: `trainer.init_module` cannot fully support proper instantiation of your model with the `MegatronStrategy` strategy. Please instantiate your model inside the`LightningModule.configure_model` hook instead\n",
      "    \n",
      "[NeMo I 2025-05-24 15:02:39 nemo_logging:393] Padded vocab_size: 512, original vocab_size: 512, dummy tokens: 0.\n",
      "CPU RNG state changed within GPU RNG context\n",
      "CPU RNG state changed within GPU RNG context\n",
      "CPU RNG state changed within GPU RNG context\n",
      "CPU RNG state changed within GPU RNG context\n",
      "CPU RNG state changed within GPU RNG context\n",
      "CPU RNG state changed within GPU RNG context\n",
      "CPU RNG state changed within GPU RNG context\n",
      "CPU RNG state changed within GPU RNG context\n",
      "CPU RNG state changed within GPU RNG context\n",
      "CPU RNG state changed within GPU RNG context\n",
      "CPU RNG state changed within GPU RNG context\n",
      "CPU RNG state changed within GPU RNG context\n",
      "CPU RNG state changed within GPU RNG context\n",
      "CPU RNG state changed within GPU RNG context\n",
      "[NeMo W 2025-05-24 15:02:43 nemo_logging:405] Could not copy Trainer's 'max_steps' to LR scheduler's 'max_steps'. If you are not using an LR scheduler, this warning can safely be ignored.\n",
      "[NeMo I 2025-05-24 15:02:43 nemo_logging:393] Using FullyParallelSaveStrategyWrapper(torch_dist, 1) dist-ckpt save strategy.\n",
      "[NeMo I 2025-05-24 15:02:48 nemo_logging:393] Global Checkpoint Save : Rank: 0 : Iteration: 0 : Start time: 1748098963.720s : Save duration: 4.825s\n",
      "[NeMo I 2025-05-24 15:02:48 nemo_logging:393] Converted Hyena model to Nemo, model saved to nemo2_evo2_1b_8k\n"
     ]
    }
   ],
   "source": [
    "!evo2_convert_to_nemo2 \\\n",
    "  --model-path /workspace/savanna_evo2_1b_base/savanna_evo2_1b_base.pt \\\n",
    "  --model-size 1b --output-dir nemo2_evo2_1b_8k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "56a10c51-4574-45a0-b1bc-94581798171b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "output_pfx = str(Path(os.path.abspath(\"preprocessed_data\"))/\"XTT22_train_byte-level\")\n",
    "output_yaml = f\"\"\"\n",
    "- dataset_prefix: {output_pfx}_train\n",
    "  dataset_split: train\n",
    "  dataset_weight: 1.0\n",
    "- dataset_prefix: {output_pfx}_val\n",
    "  dataset_split: validation\n",
    "  dataset_weight: 1.0\n",
    "- dataset_prefix: {output_pfx}_test\n",
    "  dataset_split: test\n",
    "  dataset_weight: 1.0\n",
    "\"\"\"\n",
    "with open(\"training_data_config.yaml\", \"w\") as f:\n",
    "    print(output_yaml, file=f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dff9f392-359a-4463-b435-54beadb4ea67",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not find the bitsandbytes CUDA binary at PosixPath('/usr/local/lib/python3.12/dist-packages/bitsandbytes/libbitsandbytes_cuda129.so')\n",
      "The installed version of bitsandbytes was compiled without GPU support. 8-bit optimizers, 8-bit multiplication, and GPU quantization are unavailable.\n",
      "[NeMo I 2025-05-24 15:03:17 nemo_logging:393] Using byte-level tokenization\n",
      "[NeMo W 2025-05-24 15:03:17 nemo_logging:405] WandB is currently turned off.\n",
      "[NeMo W 2025-05-24 15:03:17 nemo_logging:405] User-set tensorboard is currently turned off. Internally one may still be set by NeMo2.\n",
      "Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "[NeMo I 2025-05-24 15:03:17 nemo_logging:393] Experiments will be logged at results/evo2/dev\n",
      "[NeMo W 2025-05-24 15:03:17 nemo_logging:405] There were no checkpoints found in checkpoint_dir or no checkpoint folder at checkpoint_dir :results/evo2/checkpoints. Training from scratch.\n",
      "[NeMo I 2025-05-24 15:03:17 nemo_logging:393] Fixing mis-match between ddp-config & mcore-optimizer config\n",
      "[NeMo I 2025-05-24 15:03:17 nemo_logging:393] Rank 0 has data parallel group : [0]\n",
      "[NeMo I 2025-05-24 15:03:17 nemo_logging:393] Rank 0 has combined group of data parallel and context parallel : [0]\n",
      "[NeMo I 2025-05-24 15:03:17 nemo_logging:393] All data parallel group ranks with context parallel combined: [[0]]\n",
      "[NeMo I 2025-05-24 15:03:17 nemo_logging:393] Ranks 0 has data parallel rank: 0\n",
      "[NeMo I 2025-05-24 15:03:17 nemo_logging:393] Rank 0 has context parallel group: [0]\n",
      "[NeMo I 2025-05-24 15:03:17 nemo_logging:393] All context parallel group ranks: [[0]]\n",
      "[NeMo I 2025-05-24 15:03:17 nemo_logging:393] Ranks 0 has context parallel rank: 0\n",
      "[NeMo I 2025-05-24 15:03:17 nemo_logging:393] Rank 0 has model parallel group: [0]\n",
      "[NeMo I 2025-05-24 15:03:17 nemo_logging:393] All model parallel group ranks: [[0]]\n",
      "[NeMo I 2025-05-24 15:03:17 nemo_logging:393] Rank 0 has tensor model parallel group: [0]\n",
      "[NeMo I 2025-05-24 15:03:17 nemo_logging:393] All tensor model parallel group ranks: [[0]]\n",
      "[NeMo I 2025-05-24 15:03:17 nemo_logging:393] Rank 0 has tensor model parallel rank: 0\n",
      "[NeMo I 2025-05-24 15:03:17 nemo_logging:393] Rank 0 has pipeline model parallel group: [0]\n",
      "[NeMo I 2025-05-24 15:03:17 nemo_logging:393] Rank 0 has embedding group: [0]\n",
      "[NeMo I 2025-05-24 15:03:17 nemo_logging:393] All pipeline model parallel group ranks: [[0]]\n",
      "[NeMo I 2025-05-24 15:03:17 nemo_logging:393] Rank 0 has pipeline model parallel rank 0\n",
      "[NeMo I 2025-05-24 15:03:17 nemo_logging:393] All embedding group ranks: [[0]]\n",
      "[NeMo I 2025-05-24 15:03:17 nemo_logging:393] Rank 0 has embedding rank: 0\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 1 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[NeMo I 2025-05-24 15:03:18 utils:554] Building Evo2Dataset splits with sizes=[100, 60, 1] and config=GPTDatasetConfig(random_seed=1234, sequence_length=1, blend=None, blend_per_split=[(['/workspace/preprocessed_data/XTT22_train_byte-level_train'], [1.0]), (['/workspace/preprocessed_data/XTT22_train_byte-level_val'], [1.0]), (['/workspace/preprocessed_data/XTT22_train_byte-level_test'], [1.0])], split=None, split_matrix=None, num_dataset_builder_threads=1, path_to_cache=None, mmap_bin_files=True, mock=False, tokenizer=<nemo.collections.common.tokenizers.bytelevel_tokenizers.ByteLevelTokenizer object at 0x76022cea3a10>, mid_level_dataset_surplus=0.005, reset_position_ids=False, reset_attention_mask=False, eod_mask_loss=False, create_attention_mask=False, drop_last_partial_validation_sequence=True, add_extra_token_to_sequence=True, object_storage_cache_path=None)\n",
      "[NeMo I 2025-05-24 15:03:18 utils:554] Load the _IndexReader from /workspace/preprocessed_data/XTT22_train_byte-level_train.idx\n",
      "[NeMo I 2025-05-24 15:03:18 utils:554] \tExtract the sequence lengths\n",
      "[NeMo I 2025-05-24 15:03:18 utils:554] \tExtract the sequence pointers\n",
      "[NeMo I 2025-05-24 15:03:18 utils:554] \tExtract the document indices\n",
      "[NeMo I 2025-05-24 15:03:18 utils:554] > total number of sequences: 10896\n",
      "[NeMo I 2025-05-24 15:03:18 utils:554] > total number of documents: 10896\n",
      "[NeMo I 2025-05-24 15:03:18 utils:554] Build and save the Evo2Dataset train indices\n",
      "[NeMo I 2025-05-24 15:50:25 utils:554] > total number of samples: 13441714549\n",
      "[NeMo I 2025-05-24 15:50:25 utils:554] > total number of epochs: 1\n",
      "[NeMo I 2025-05-24 15:50:25 utils:554] Load the _IndexReader from /workspace/preprocessed_data/XTT22_train_byte-level_val.idx\n",
      "[NeMo I 2025-05-24 15:50:25 utils:554] \tExtract the sequence lengths\n",
      "[NeMo I 2025-05-24 15:50:25 utils:554] \tExtract the sequence pointers\n",
      "[NeMo I 2025-05-24 15:50:25 utils:554] \tExtract the document indices\n",
      "[NeMo I 2025-05-24 15:50:25 utils:554] > total number of sequences: 590\n",
      "[NeMo I 2025-05-24 15:50:25 utils:554] > total number of documents: 590\n",
      "[NeMo I 2025-05-24 15:50:25 utils:554] Build and save the Evo2Dataset valid indices\n",
      "[NeMo I 2025-05-24 15:51:08 utils:554] > total number of samples: 430752259\n",
      "[NeMo I 2025-05-24 15:51:08 utils:554] > total number of epochs: 1\n",
      "[NeMo I 2025-05-24 15:51:08 utils:554] Load the _IndexReader from /workspace/preprocessed_data/XTT22_train_byte-level_test.idx\n",
      "[NeMo I 2025-05-24 15:51:08 utils:554] \tExtract the sequence lengths\n",
      "[NeMo I 2025-05-24 15:51:08 utils:554] \tExtract the sequence pointers\n",
      "[NeMo I 2025-05-24 15:51:08 utils:554] \tExtract the document indices\n",
      "[NeMo I 2025-05-24 15:51:08 utils:554] > total number of sequences: 606\n",
      "[NeMo I 2025-05-24 15:51:08 utils:554] > total number of documents: 606\n",
      "[NeMo I 2025-05-24 15:51:08 utils:554] Build and save the Evo2Dataset test indices\n",
      "[NeMo I 2025-05-24 15:52:44 utils:554] > total number of samples: 981405895\n",
      "[NeMo I 2025-05-24 15:52:44 utils:554] > total number of epochs: 1\n",
      "[NeMo I 2025-05-24 15:52:45 nemo_logging:393] Padded vocab_size: 512, original vocab_size: 512, dummy tokens: 0.\n",
      "[NeMo W 2025-05-24 15:52:45 random:222] CPU RNG state changed within GPU RNG context\n",
      "[NeMo W 2025-05-24 15:52:45 random:222] CPU RNG state changed within GPU RNG context\n",
      "[NeMo W 2025-05-24 15:52:45 random:222] CPU RNG state changed within GPU RNG context\n",
      "[NeMo W 2025-05-24 15:52:45 random:222] CPU RNG state changed within GPU RNG context\n",
      "[NeMo W 2025-05-24 15:52:45 random:222] CPU RNG state changed within GPU RNG context\n",
      "[NeMo W 2025-05-24 15:52:45 random:222] CPU RNG state changed within GPU RNG context\n",
      "[NeMo W 2025-05-24 15:52:45 random:222] CPU RNG state changed within GPU RNG context\n",
      "[NeMo W 2025-05-24 15:52:45 random:222] CPU RNG state changed within GPU RNG context\n",
      "[NeMo W 2025-05-24 15:52:45 random:222] CPU RNG state changed within GPU RNG context\n",
      "[NeMo W 2025-05-24 15:52:45 random:222] CPU RNG state changed within GPU RNG context\n",
      "[NeMo W 2025-05-24 15:52:45 random:222] CPU RNG state changed within GPU RNG context\n",
      "[NeMo W 2025-05-24 15:52:45 random:222] CPU RNG state changed within GPU RNG context\n",
      "[NeMo W 2025-05-24 15:52:45 random:222] CPU RNG state changed within GPU RNG context\n",
      "[NeMo W 2025-05-24 15:52:45 random:222] CPU RNG state changed within GPU RNG context\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "[NeMo I 2025-05-24 15:52:45 nemo_logging:393] Copying Trainer's 'max_steps' (100) to LR scheduler's 'max_steps'.\n",
      "[NeMo I 2025-05-24 15:52:45 num_microbatches_calculator:228] setting number of microbatches to constant 1\n",
      "[NeMo I 2025-05-24 15:52:45 nemo_logging:393]  > number of parameters on (tensor, pipeline) model parallel rank (0 ,0): 1108204800\n",
      "[NeMo I 2025-05-24 15:52:45 utils:554] Setting up DistributedDataParallel with config DistributedDataParallelConfig(grad_reduce_in_fp32=False, overlap_grad_reduce=False, overlap_param_gather=False, align_param_gather=False, use_distributed_optimizer=True, num_distributed_optimizer_instances=1, check_for_nan_in_grad=True, check_for_large_grads=False, bucket_size=None, pad_buckets_for_high_nccl_busbw=False, average_in_collective=True, fp8_param_gather=False, use_custom_fsdp=False, data_parallel_sharding_strategy='no_shard', gradient_reduce_div_fusion=True, suggested_communication_unit_size=None, preserve_fp32_weights=True, keep_fp8_transpose_cache_when_using_custom_fsdp=False)\n",
      "[NeMo I 2025-05-24 15:52:45 utils:575] Number of buckets for gradient all-reduce / reduce-scatter: 1\n",
      "    Params for bucket 1 (1108204800 elements, 1108204800 padded size):\n",
      "    \tmodule.decoder.layers.22.mixer.dense_projection.layer_norm_weight\n",
      "    \tmodule.decoder.layers.19.mixer.dense.bias\n",
      "    \tmodule.decoder.layers.18.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.14.mixer.dense_projection.layer_norm_weight\n",
      "    \tmodule.decoder.layers.11.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.7.mixer.dense_projection.layer_norm_weight\n",
      "    \tmodule.decoder.layers.3.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.22.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.12.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.5.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.2.mixer.mixer.filter.p\n",
      "    \tmodule.decoder.layers.0.mixer.dense.weight\n",
      "    \tmodule.embedding.word_embeddings.weight\n",
      "    \tmodule.decoder.layers.23.mixer.dense.weight\n",
      "    \tmodule.decoder.layers.18.mixer.dense.weight\n",
      "    \tmodule.decoder.layers.16.mixer.dense_projection.layer_norm_weight\n",
      "    \tmodule.decoder.layers.15.mixer.mixer.conv_bias\n",
      "    \tmodule.decoder.layers.11.mixer.dense.weight\n",
      "    \tmodule.decoder.layers.9.mixer.dense_projection.layer_norm_weight\n",
      "    \tmodule.decoder.layers.8.mixer.mixer.conv_bias\n",
      "    \tmodule.decoder.layers.5.mixer.mixer.filter.h\n",
      "    \tmodule.decoder.layers.24.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.16.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.9.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.2.mixer.hyena_proj_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.17.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.21.mixer.dense_projection.layer_norm_weight\n",
      "    \tmodule.decoder.layers.18.mixer.dense.bias\n",
      "    \tmodule.decoder.layers.13.mixer.mixer.filter.R\n",
      "    \tmodule.decoder.layers.11.mixer.dense.bias\n",
      "    \tmodule.decoder.layers.10.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.6.mixer.mixer.filter.R\n",
      "    \tmodule.decoder.layers.2.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.0.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.19.mixer.dense_projection.layer_norm_weight\n",
      "    \tmodule.decoder.layers.14.mixer.mixer.short_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.12.mixer.dense_projection.layer_norm_weight\n",
      "    \tmodule.decoder.layers.7.mixer.mixer.short_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.4.mixer.dense_projection.layer_norm_weight\n",
      "    \tmodule.decoder.layers.2.mixer.mixer.conv_bias\n",
      "    \tmodule.decoder.layers.23.mixer.dense_projection.layer_norm_weight\n",
      "    \tmodule.decoder.layers.22.mixer.dense.bias\n",
      "    \tmodule.decoder.layers.19.mixer.mixer.conv_bias\n",
      "    \tmodule.decoder.layers.15.mixer.hyena_proj_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.12.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.12.mixer.dense.bias\n",
      "    \tmodule.decoder.layers.8.mixer.hyena_proj_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.5.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.2.mixer.dense.bias\n",
      "    \tmodule.decoder.layers.0.mixer.mixer.short_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.23.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.16.mixer.mixer.filter.gamma\n",
      "    \tmodule.decoder.layers.13.mixer.dense.weight\n",
      "    \tmodule.decoder.layers.10.self_attention.linear_proj.bias\n",
      "    \tmodule.decoder.layers.9.mixer.mixer.filter.gamma\n",
      "    \tmodule.decoder.layers.6.mixer.dense.weight\n",
      "    \tmodule.decoder.final_norm.weight\n",
      "    \tmodule.decoder.layers.24.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.20.mixer.mixer.filter.R\n",
      "    \tmodule.decoder.layers.17.self_attention.linear_proj.weight\n",
      "    \tmodule.decoder.layers.15.mixer.mixer.filter.h\n",
      "    \tmodule.decoder.layers.10.self_attention.linear_proj.weight\n",
      "    \tmodule.decoder.layers.8.mixer.mixer.filter.h\n",
      "    \tmodule.decoder.layers.5.mixer.dense.bias\n",
      "    \tmodule.decoder.layers.4.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.2.mixer.dense_projection.weight\n",
      "    \tmodule.decoder.layers.0.mixer.hyena_proj_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.21.mixer.mixer.short_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.18.mixer.dense_projection.layer_norm_weight\n",
      "    \tmodule.decoder.layers.15.mixer.dense.bias\n",
      "    \tmodule.decoder.layers.15.mixer.dense.weight\n",
      "    \tmodule.decoder.layers.11.mixer.dense_projection.layer_norm_weight\n",
      "    \tmodule.decoder.layers.8.mixer.dense.bias\n",
      "    \tmodule.decoder.layers.8.mixer.dense.weight\n",
      "    \tmodule.decoder.layers.2.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.1.mixer.dense_projection.layer_norm_weight\n",
      "    \tmodule.decoder.layers.22.mixer.hyena_proj_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.20.mixer.mixer.conv_bias\n",
      "    \tmodule.decoder.layers.16.mixer.mixer.filter.p\n",
      "    \tmodule.decoder.layers.14.mixer.hyena_proj_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.9.mixer.mixer.filter.p\n",
      "    \tmodule.decoder.layers.7.mixer.hyena_proj_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.5.mixer.dense_projection.layer_norm_weight\n",
      "    \tmodule.decoder.layers.4.mixer.mixer.short_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.1.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.23.mixer.mixer.filter.gamma\n",
      "    \tmodule.decoder.layers.20.mixer.dense.weight\n",
      "    \tmodule.decoder.layers.15.mixer.dense_projection.weight\n",
      "    \tmodule.decoder.layers.13.mixer.dense_projection.layer_norm_weight\n",
      "    \tmodule.decoder.layers.8.mixer.dense_projection.weight\n",
      "    \tmodule.decoder.layers.6.mixer.dense_projection.layer_norm_weight\n",
      "    \tmodule.decoder.layers.24.self_attention.linear_proj.weight\n",
      "    \tmodule.decoder.layers.22.mixer.mixer.filter.h\n",
      "    \tmodule.decoder.layers.16.mixer.hyena_proj_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.13.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.9.mixer.hyena_proj_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.6.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.3.self_attention.linear_qkv.weight\n",
      "    \tmodule.decoder.layers.3.self_attention.linear_proj.bias\n",
      "    \tmodule.decoder.layers.1.mixer.mixer.conv_bias\n",
      "    \tmodule.decoder.layers.22.mixer.dense.weight\n",
      "    \tmodule.decoder.layers.21.mixer.dense.bias\n",
      "    \tmodule.decoder.layers.16.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.14.mixer.dense.bias\n",
      "    \tmodule.decoder.layers.9.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.6.mixer.mixer.conv_bias\n",
      "    \tmodule.decoder.layers.4.mixer.dense.bias\n",
      "    \tmodule.decoder.layers.0.mixer.dense_projection.layer_norm_weight\n",
      "    \tmodule.decoder.layers.23.mixer.mixer.filter.p\n",
      "    \tmodule.decoder.layers.21.mixer.hyena_proj_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.18.mixer.mixer.short_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.17.self_attention.linear_proj.bias\n",
      "    \tmodule.decoder.layers.15.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.11.mixer.mixer.short_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.8.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.3.self_attention.linear_proj.weight\n",
      "    \tmodule.decoder.layers.22.mixer.dense_projection.weight\n",
      "    \tmodule.decoder.layers.20.mixer.dense_projection.layer_norm_weight\n",
      "    \tmodule.decoder.layers.19.mixer.hyena_proj_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.16.mixer.dense.bias\n",
      "    \tmodule.decoder.layers.14.mixer.dense_projection.weight\n",
      "    \tmodule.decoder.layers.12.mixer.hyena_proj_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.9.mixer.dense.bias\n",
      "    \tmodule.decoder.layers.7.mixer.dense_projection.weight\n",
      "    \tmodule.decoder.layers.4.mixer.hyena_proj_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.0.mixer.dense.bias\n",
      "    \tmodule.decoder.layers.23.mixer.hyena_proj_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.20.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.17.self_attention.linear_qkv.weight\n",
      "    \tmodule.decoder.layers.13.mixer.mixer.filter.gamma\n",
      "    \tmodule.decoder.layers.10.self_attention.linear_qkv.weight\n",
      "    \tmodule.decoder.layers.6.mixer.mixer.filter.gamma\n",
      "    \tmodule.decoder.layers.23.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.22.mixer.mixer.conv_bias\n",
      "    \tmodule.decoder.layers.19.mixer.mixer.filter.h\n",
      "    \tmodule.decoder.layers.16.mixer.dense_projection.weight\n",
      "    \tmodule.decoder.layers.12.mixer.mixer.filter.h\n",
      "    \tmodule.decoder.layers.9.mixer.dense_projection.weight\n",
      "    \tmodule.decoder.layers.3.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.22.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.19.mixer.dense.weight\n",
      "    \tmodule.decoder.layers.16.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.14.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.12.mixer.dense.weight\n",
      "    \tmodule.decoder.layers.9.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.7.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.5.mixer.dense.weight\n",
      "    \tmodule.decoder.layers.5.mixer.dense_projection.weight\n",
      "    \tmodule.decoder.layers.2.mixer.mixer.filter.R\n",
      "    \tmodule.decoder.layers.23.mixer.dense.bias\n",
      "    \tmodule.decoder.layers.21.mixer.dense_projection.weight\n",
      "    \tmodule.decoder.layers.18.mixer.hyena_proj_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.16.mixer.mixer.conv_bias\n",
      "    \tmodule.decoder.layers.13.mixer.mixer.filter.p\n",
      "    \tmodule.decoder.layers.11.mixer.hyena_proj_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.9.mixer.mixer.conv_bias\n",
      "    \tmodule.decoder.layers.6.mixer.mixer.filter.p\n",
      "    \tmodule.decoder.layers.1.mixer.hyena_proj_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.24.self_attention.linear_qkv.weight\n",
      "    \tmodule.decoder.layers.20.mixer.mixer.filter.gamma\n",
      "    \tmodule.decoder.layers.19.mixer.dense_projection.weight\n",
      "    \tmodule.decoder.layers.14.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.12.mixer.dense_projection.weight\n",
      "    \tmodule.decoder.layers.7.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.5.mixer.hyena_proj_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.4.mixer.dense_projection.weight\n",
      "    \tmodule.decoder.layers.1.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.0.mixer.dense_projection.weight\n",
      "    \tmodule.decoder.layers.23.mixer.dense_projection.weight\n",
      "    \tmodule.decoder.layers.17.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.13.mixer.hyena_proj_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.10.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.6.mixer.hyena_proj_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.2.mixer.dense.weight\n",
      "    \tmodule.decoder.layers.1.mixer.dense.bias\n",
      "    \tmodule.decoder.layers.23.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.21.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.13.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.12.mixer.mixer.conv_bias\n",
      "    \tmodule.decoder.layers.6.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.17.self_attention.linear_qkv.layer_norm_weight\n",
      "    \tmodule.decoder.layers.23.mixer.mixer.conv_bias\n",
      "    \tmodule.decoder.layers.20.mixer.mixer.filter.p\n",
      "    \tmodule.decoder.layers.19.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.14.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.12.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.10.self_attention.linear_qkv.layer_norm_weight\n",
      "    \tmodule.decoder.layers.7.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.5.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.4.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.21.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.18.mixer.dense_projection.weight\n",
      "    \tmodule.decoder.layers.15.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.13.mixer.dense.bias\n",
      "    \tmodule.decoder.layers.11.mixer.dense_projection.weight\n",
      "    \tmodule.decoder.layers.8.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.6.mixer.dense.bias\n",
      "    \tmodule.decoder.layers.3.self_attention.linear_qkv.layer_norm_weight\n",
      "    \tmodule.decoder.layers.1.mixer.dense_projection.weight\n",
      "    \tmodule.decoder.layers.24.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.24.self_attention.linear_proj.bias\n",
      "    \tmodule.decoder.layers.20.mixer.hyena_proj_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.19.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.14.mixer.dense.weight\n",
      "    \tmodule.decoder.layers.7.mixer.dense.weight\n",
      "    \tmodule.decoder.layers.5.mixer.mixer.conv_bias\n",
      "    \tmodule.decoder.layers.4.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.2.mixer.dense_projection.layer_norm_weight\n",
      "    \tmodule.decoder.layers.20.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.13.mixer.dense_projection.weight\n",
      "    \tmodule.decoder.layers.6.mixer.dense_projection.weight\n",
      "    \tmodule.decoder.layers.2.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.1.mixer.mixer.filter.h\n",
      "    \tmodule.decoder.layers.24.self_attention.linear_qkv.layer_norm_weight\n",
      "    \tmodule.decoder.layers.21.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.18.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.16.mixer.mixer.filter.R\n",
      "    \tmodule.decoder.layers.13.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.11.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.9.mixer.mixer.filter.R\n",
      "    \tmodule.decoder.layers.6.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.3.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.1.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.22.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.20.mixer.dense.bias\n",
      "    \tmodule.decoder.layers.19.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.15.mixer.dense_projection.layer_norm_weight\n",
      "    \tmodule.decoder.layers.13.mixer.mixer.conv_bias\n",
      "    \tmodule.decoder.layers.8.mixer.dense_projection.layer_norm_weight\n",
      "    \tmodule.decoder.layers.7.mixer.dense.bias\n",
      "    \tmodule.decoder.layers.0.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.21.mixer.dense.weight\n",
      "    \tmodule.decoder.layers.18.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.15.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.11.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.8.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.20.mixer.dense_projection.weight\n",
      "    \tmodule.decoder.layers.16.mixer.dense.weight\n",
      "    \tmodule.decoder.layers.9.mixer.dense.weight\n",
      "    \tmodule.decoder.layers.4.mixer.dense.weight\n",
      "    \tmodule.decoder.layers.2.mixer.mixer.filter.gamma\n",
      "    \tmodule.decoder.layers.23.mixer.mixer.filter.R\n",
      "    \tmodule.decoder.layers.20.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.17.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.10.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.0.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.1.mixer.dense.weight\n",
      "[NeMo I 2025-05-24 15:52:45 utils:554] Setting up optimizer with config OptimizerConfig(optimizer='adam', lr=0.0001, min_lr=None, decoupled_lr=None, decoupled_min_lr=None, weight_decay=0.01, fp16=False, bf16=True, params_dtype=torch.bfloat16, use_precision_aware_optimizer=False, store_param_remainders=True, main_grads_dtype=torch.float32, main_params_dtype=torch.float32, exp_avg_dtype=torch.float32, exp_avg_sq_dtype=torch.float32, loss_scale=None, initial_loss_scale=4294967296, min_loss_scale=1.0, loss_scale_window=1000, hysteresis=2, adam_beta1=0.9, adam_beta2=0.95, adam_eps=1e-08, sgd_momentum=0.9, use_distributed_optimizer=True, overlap_param_gather_with_optimizer_step=False, optimizer_cpu_offload=False, optimizer_offload_fraction=0.0, use_torch_optimizer_for_cpu_offload=False, overlap_cpu_optimizer_d2h_h2d=False, pin_cpu_grads=True, pin_cpu_params=True, clip_grad=1.0, log_num_zeros_in_grad=False, barrier_with_L1_time=False, timers=None, config_logger_dir='')\n",
      "[NeMo I 2025-05-24 15:52:45 nemo_logging:393] Doing selective restore from RestoreConfig(path='nemo2_evo2_1b_8k', adapter_path=None, load_model_state=True, load_optim_state=False, load_artifacts=True)\n",
      "[NeMo I 2025-05-24 15:52:45 nemo_logging:393] Using <megatron.core.dist_checkpointing.strategies.fully_parallel.FullyParallelLoadStrategyWrapper object at 0x76022cd99b80> dist-ckpt load strategy.\n",
      "[NeMo I 2025-05-24 15:52:47 nemo_logging:393] Global Checkpoint Load : Rank : 0 : Start time : 1748101965.565s : Time spent in load_checkpoint: 1.998s\n",
      "[NeMo I 2025-05-24 15:52:47 nemo_logging:393] Restoring model weights from RestoreConfig(path='nemo2_evo2_1b_8k', adapter_path=None, load_model_state=True, load_optim_state=False, load_artifacts=True)\n",
      "[NeMo I 2025-05-24 15:52:47 nemo_logging:393] Finished restoring from RestoreConfig(path='nemo2_evo2_1b_8k', adapter_path=None, load_model_state=True, load_optim_state=False, load_artifacts=True), cleaning up.\n",
      "┏━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━┓\n",
      "┃\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mName                               \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mType             \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mParams\u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mMode \u001b[0m\u001b[1;35m \u001b[0m┃\n",
      "┡━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━┩\n",
      "│\u001b[2m \u001b[0m\u001b[2m0\u001b[0m\u001b[2m \u001b[0m│ module                              │ DDP               │  1.1 B │ train │\n",
      "│\u001b[2m \u001b[0m\u001b[2m1\u001b[0m\u001b[2m \u001b[0m│ module.module                       │ Float16Module     │  1.1 B │ train │\n",
      "│\u001b[2m \u001b[0m\u001b[2m2\u001b[0m\u001b[2m \u001b[0m│ module.module.module                │ HyenaModel        │  1.1 B │ train │\n",
      "│\u001b[2m \u001b[0m\u001b[2m3\u001b[0m\u001b[2m \u001b[0m│ module.module.module.embedding      │ LanguageModelEmb… │  983 K │ train │\n",
      "│\u001b[2m \u001b[0m\u001b[2m4\u001b[0m\u001b[2m \u001b[0m│ module.module.module.rotary_pos_emb │ RotaryEmbedding   │      0 │ train │\n",
      "│\u001b[2m \u001b[0m\u001b[2m5\u001b[0m\u001b[2m \u001b[0m│ module.module.module.decoder        │ HyenaStack        │  1.1 B │ train │\n",
      "│\u001b[2m \u001b[0m\u001b[2m6\u001b[0m\u001b[2m \u001b[0m│ module.module.module.output_layer   │ ColumnParallelLi… │      0 │ train │\n",
      "└───┴─────────────────────────────────────┴───────────────────┴────────┴───────┘\n",
      "\u001b[1mTrainable params\u001b[0m: 1.1 B                                                         \n",
      "\u001b[1mNon-trainable params\u001b[0m: 0                                                         \n",
      "\u001b[1mTotal params\u001b[0m: 1.1 B                                                             \n",
      "\u001b[1mTotal estimated model params size (MB)\u001b[0m: 4.4 K                                   \n",
      "\u001b[1mModules in train mode\u001b[0m: 356                                                      \n",
      "\u001b[1mModules in eval mode\u001b[0m: 0                                                         \n",
      "[NeMo W 2025-05-24 15:53:47 rerun_state_machine:1264] Implicit initialization of Rerun State Machine!\n",
      "[NeMo W 2025-05-24 15:53:47 rerun_state_machine:239] RerunStateMachine initialized in mode RerunMode.DISABLED\n",
      "Training epoch 0, iteration 0/99 | lr: 0 | global_batch_size: 1 | global_step: 0 | reduced_train_loss: 1.46 | train_step_timing in s: 23.05\n",
      "Training epoch 0, iteration 1/99 | lr: 2e-05 | global_batch_size: 1 | global_step: 1 | reduced_train_loss: 1.472 | train_step_timing in s: 2.461 | consumed_samples: 2\n",
      "Training epoch 0, iteration 2/99 | lr: 4e-05 | global_batch_size: 1 | global_step: 2 | reduced_train_loss: 1.823 | train_step_timing in s: 0.3414 | consumed_samples: 3\n",
      "Training epoch 0, iteration 3/99 | lr: 6e-05 | global_batch_size: 1 | global_step: 3 | reduced_train_loss: 1.331 | train_step_timing in s: 0.3744 | consumed_samples: 4\n",
      "Training epoch 0, iteration 4/99 | lr: 8e-05 | global_batch_size: 1 | global_step: 4 | reduced_train_loss: 1.337 | train_step_timing in s: 0.3341 | consumed_samples: 5\n",
      "Training epoch 0, iteration 5/99 | lr: 0.0001 | global_batch_size: 1 | global_step: 5 | reduced_train_loss: 2.111 | train_step_timing in s: 0.3964 | consumed_samples: 6\n",
      "Training epoch 0, iteration 6/99 | lr: 3e-05 | global_batch_size: 1 | global_step: 6 | reduced_train_loss: 0.5181 | train_step_timing in s: 0.3797 | consumed_samples: 7\n",
      "Training epoch 0, iteration 7/99 | lr: 3e-05 | global_batch_size: 1 | global_step: 7 | reduced_train_loss: 5.48 | train_step_timing in s: 0.3783 | consumed_samples: 8\n",
      "Training epoch 0, iteration 8/99 | lr: 3e-05 | global_batch_size: 1 | global_step: 8 | reduced_train_loss: 0.5512 | train_step_timing in s: 0.323 | consumed_samples: 9\n",
      "Training epoch 0, iteration 9/99 | lr: 3e-05 | global_batch_size: 1 | global_step: 9 | reduced_train_loss: 2.03 | train_step_timing in s: 0.3056 | consumed_samples: 10\n",
      "Training epoch 0, iteration 10/99 | lr: 3e-05 | global_batch_size: 1 | global_step: 10 | reduced_train_loss: 1.445 | train_step_timing in s: 0.4078 | consumed_samples: 11\n",
      "Training epoch 0, iteration 11/99 | lr: 3e-05 | global_batch_size: 1 | global_step: 11 | reduced_train_loss: 2.197 | train_step_timing in s: 0.389 | consumed_samples: 12\n",
      "Training epoch 0, iteration 12/99 | lr: 3e-05 | global_batch_size: 1 | global_step: 12 | reduced_train_loss: 0.93 | train_step_timing in s: 0.3769 | consumed_samples: 13\n",
      "Training epoch 0, iteration 13/99 | lr: 3e-05 | global_batch_size: 1 | global_step: 13 | reduced_train_loss: 0.7602 | train_step_timing in s: 0.3256 | consumed_samples: 14\n",
      "Training epoch 0, iteration 14/99 | lr: 3e-05 | global_batch_size: 1 | global_step: 14 | reduced_train_loss: 0.5082 | train_step_timing in s: 0.3603 | consumed_samples: 15\n",
      "Training epoch 0, iteration 15/99 | lr: 3e-05 | global_batch_size: 1 | global_step: 15 | reduced_train_loss: 0.3451 | train_step_timing in s: 0.3301 | consumed_samples: 16\n",
      "Training epoch 0, iteration 16/99 | lr: 3e-05 | global_batch_size: 1 | global_step: 16 | reduced_train_loss: 2.594 | train_step_timing in s: 0.3269 | consumed_samples: 17\n",
      "Training epoch 0, iteration 17/99 | lr: 3e-05 | global_batch_size: 1 | global_step: 17 | reduced_train_loss: 5.31 | train_step_timing in s: 0.3985 | consumed_samples: 18\n",
      "Training epoch 0, iteration 18/99 | lr: 3e-05 | global_batch_size: 1 | global_step: 18 | reduced_train_loss: 3.781 | train_step_timing in s: 0.4087 | consumed_samples: 19\n",
      "Training epoch 0, iteration 19/99 | lr: 3e-05 | global_batch_size: 1 | global_step: 19 | reduced_train_loss: 0.2096 | train_step_timing in s: 0.3847 | consumed_samples: 20\n",
      "Training epoch 0, iteration 20/99 | lr: 3e-05 | global_batch_size: 1 | global_step: 20 | reduced_train_loss: 3.309 | train_step_timing in s: 0.3851 | consumed_samples: 21\n",
      "Training epoch 0, iteration 21/99 | lr: 3e-05 | global_batch_size: 1 | global_step: 21 | reduced_train_loss: 0.2375 | train_step_timing in s: 0.3793 | consumed_samples: 22\n",
      "Training epoch 0, iteration 22/99 | lr: 3e-05 | global_batch_size: 1 | global_step: 22 | reduced_train_loss: 2.854 | train_step_timing in s: 0.2789 | consumed_samples: 23\n",
      "Training epoch 0, iteration 23/99 | lr: 3e-05 | global_batch_size: 1 | global_step: 23 | reduced_train_loss: 2.665 | train_step_timing in s: 0.2611 | consumed_samples: 24\n",
      "Training epoch 0, iteration 24/99 | lr: 3e-05 | global_batch_size: 1 | global_step: 24 | reduced_train_loss: 0.2788 | train_step_timing in s: 0.3081 | consumed_samples: 25\n",
      "Training epoch 0, iteration 25/99 | lr: 3e-05 | global_batch_size: 1 | global_step: 25 | reduced_train_loss: 2.379 | train_step_timing in s: 0.3379 | consumed_samples: 26\n",
      "Training epoch 0, iteration 26/99 | lr: 3e-05 | global_batch_size: 1 | global_step: 26 | reduced_train_loss: 0.2992 | train_step_timing in s: 0.352 | consumed_samples: 27\n",
      "Training epoch 0, iteration 27/99 | lr: 3e-05 | global_batch_size: 1 | global_step: 27 | reduced_train_loss: 2.151 | train_step_timing in s: 0.362 | consumed_samples: 28\n",
      "Training epoch 0, iteration 28/99 | lr: 3e-05 | global_batch_size: 1 | global_step: 28 | reduced_train_loss: 2.96 | train_step_timing in s: 0.3525 | consumed_samples: 29\n",
      "Training epoch 0, iteration 29/99 | lr: 3e-05 | global_batch_size: 1 | global_step: 29 | reduced_train_loss: 1.898 | train_step_timing in s: 0.3427 | consumed_samples: 30\n",
      "Training epoch 0, iteration 30/99 | lr: 3e-05 | global_batch_size: 1 | global_step: 30 | reduced_train_loss: 0.3907 | train_step_timing in s: 0.3136 | consumed_samples: 31\n",
      "Training epoch 0, iteration 31/99 | lr: 3e-05 | global_batch_size: 1 | global_step: 31 | reduced_train_loss: 0.4098 | train_step_timing in s: 0.43 | consumed_samples: 32\n",
      "Training epoch 0, iteration 32/99 | lr: 3e-05 | global_batch_size: 1 | global_step: 32 | reduced_train_loss: 2.892 | train_step_timing in s: 0.414 | consumed_samples: 33\n",
      "Training epoch 0, iteration 33/99 | lr: 3e-05 | global_batch_size: 1 | global_step: 33 | reduced_train_loss: 0.4136 | train_step_timing in s: 0.3915 | consumed_samples: 34\n",
      "Training epoch 0, iteration 34/99 | lr: 3e-05 | global_batch_size: 1 | global_step: 34 | reduced_train_loss: 2.76 | train_step_timing in s: 0.366 | consumed_samples: 35\n",
      "Training epoch 0, iteration 35/99 | lr: 3e-05 | global_batch_size: 1 | global_step: 35 | reduced_train_loss: 0.3878 | train_step_timing in s: 0.3867 | consumed_samples: 36\n",
      "Training epoch 0, iteration 36/99 | lr: 3e-05 | global_batch_size: 1 | global_step: 36 | reduced_train_loss: 1.742 | train_step_timing in s: 0.3439 | consumed_samples: 37\n",
      "Training epoch 0, iteration 37/99 | lr: 3e-05 | global_batch_size: 1 | global_step: 37 | reduced_train_loss: 0.3666 | train_step_timing in s: 0.3009 | consumed_samples: 38\n",
      "Training epoch 0, iteration 38/99 | lr: 3e-05 | global_batch_size: 1 | global_step: 38 | reduced_train_loss: 2.89 | train_step_timing in s: 0.3271 | consumed_samples: 39\n",
      "Training epoch 0, iteration 39/99 | lr: 3e-05 | global_batch_size: 1 | global_step: 39 | reduced_train_loss: 2.478 | train_step_timing in s: 0.3971 | consumed_samples: 40\n",
      "Training epoch 0, iteration 40/99 | lr: 3e-05 | global_batch_size: 1 | global_step: 40 | reduced_train_loss: 0.3569 | train_step_timing in s: 0.3514 | consumed_samples: 41\n",
      "Training epoch 0, iteration 41/99 | lr: 3e-05 | global_batch_size: 1 | global_step: 41 | reduced_train_loss: 1.986 | train_step_timing in s: 0.3553 | consumed_samples: 42\n",
      "Training epoch 0, iteration 42/99 | lr: 3e-05 | global_batch_size: 1 | global_step: 42 | reduced_train_loss: 2.336 | train_step_timing in s: 0.3706 | consumed_samples: 43\n",
      "Training epoch 0, iteration 43/99 | lr: 3e-05 | global_batch_size: 1 | global_step: 43 | reduced_train_loss: 0.3645 | train_step_timing in s: 0.3656 | consumed_samples: 44\n",
      "Training epoch 0, iteration 44/99 | lr: 3e-05 | global_batch_size: 1 | global_step: 44 | reduced_train_loss: 1.997 | train_step_timing in s: 0.306 | consumed_samples: 45\n",
      "Training epoch 0, iteration 45/99 | lr: 3e-05 | global_batch_size: 1 | global_step: 45 | reduced_train_loss: 0.3719 | train_step_timing in s: 0.3315 | consumed_samples: 46\n",
      "Training epoch 0, iteration 46/99 | lr: 3e-05 | global_batch_size: 1 | global_step: 46 | reduced_train_loss: 2.167 | train_step_timing in s: 0.396 | consumed_samples: 47\n",
      "Training epoch 0, iteration 47/99 | lr: 3e-05 | global_batch_size: 1 | global_step: 47 | reduced_train_loss: 2.89 | train_step_timing in s: 0.3722 | consumed_samples: 48\n",
      "Training epoch 0, iteration 48/99 | lr: 3e-05 | global_batch_size: 1 | global_step: 48 | reduced_train_loss: 0.3852 | train_step_timing in s: 0.3828 | consumed_samples: 49\n",
      "Training epoch 0, iteration 49/99 | lr: 3e-05 | global_batch_size: 1 | global_step: 49 | reduced_train_loss: 2.048 | train_step_timing in s: 0.4227 | consumed_samples: 50\n",
      "Epoch 0, global step 49: 'val_loss' was not in top 5\n",
      "[NeMo I 2025-05-24 15:54:07 nemo_logging:393] Using FullyParallelSaveStrategyWrapper(torch_dist, 1) dist-ckpt save strategy.\n",
      "[NeMo I 2025-05-24 15:54:13 nemo_logging:393] Global Checkpoint Save : Rank: 0 : Iteration: 49 : Start time: 1748102047.680s : Save duration: 6.254s\n",
      "[NeMo I 2025-05-24 15:54:37 nemo_logging:393] Scheduled async checkpoint save for /workspace/results/evo2/checkpoints/evo2--val_loss=0.0000-epoch=0-consumed_samples=50.0-last.ckpt\n",
      "[NeMo I 2025-05-24 15:54:37 nemo_logging:393] Async finalization time took 0.004 s\n",
      "Validation: iteration 1/20\n",
      "Validation: iteration 2/20\n",
      "Validation: iteration 3/20\n",
      "Validation: iteration 4/20\n",
      "Validation: iteration 5/20\n",
      "Validation: iteration 6/20\n",
      "Validation: iteration 7/20\n",
      "Validation: iteration 8/20\n",
      "Validation: iteration 9/20\n",
      "Validation: iteration 10/20\n",
      "Validation: iteration 11/20\n",
      "Validation: iteration 12/20\n",
      "Validation: iteration 13/20\n",
      "Validation: iteration 14/20\n",
      "Validation: iteration 15/20\n",
      "Validation: iteration 16/20\n",
      "Validation: iteration 17/20\n",
      "Validation: iteration 18/20\n",
      "Validation: iteration 19/20\n",
      "Validation: iteration 20/20\n",
      "[NeMo W 2025-05-24 15:55:27 nemo_logging:405] /usr/local/lib/python3.12/dist-packages/lightning/pytorch/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('global_batch_size', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "    \n",
      "[NeMo W 2025-05-24 15:55:27 nemo_logging:405] /usr/local/lib/python3.12/dist-packages/lightning/pytorch/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "    \n",
      "Training epoch 0, iteration 50/99 | lr: 3e-05 | global_batch_size: 1 | global_step: 50 | reduced_train_loss: 2.037 | train_step_timing in s: 0.3171 | consumed_samples: 51 | val_loss: 1.454\n",
      "[NeMo I 2025-05-24 15:55:27 nemo_logging:393] Successfully saved checkpoint from iteration      49 to /workspace/results/evo2/checkpoints/evo2--val_loss=0.0000-epoch=0-consumed_samples=50.0-last.ckpt\n",
      "[NeMo I 2025-05-24 15:55:27 nemo_logging:393] Async checkpoint save for step 50 (/workspace/results/evo2/checkpoints/evo2--val_loss=0.0000-epoch=0-consumed_samples=50.0-last.ckpt) finalized successfully.\n",
      "[NeMo I 2025-05-24 15:55:27 nemo_logging:393] Async finalization time took 0.102 s\n",
      "Training epoch 0, iteration 51/99 | lr: 3e-05 | global_batch_size: 1 | global_step: 51 | reduced_train_loss: 2.779 | train_step_timing in s: 0.3318 | consumed_samples: 52 | val_loss: 1.454\n",
      "Training epoch 0, iteration 52/99 | lr: 3e-05 | global_batch_size: 1 | global_step: 52 | reduced_train_loss: 1.957 | train_step_timing in s: 0.3909 | consumed_samples: 53 | val_loss: 1.454\n",
      "Training epoch 0, iteration 53/99 | lr: 3e-05 | global_batch_size: 1 | global_step: 53 | reduced_train_loss: 1.992 | train_step_timing in s: 0.3908 | consumed_samples: 54 | val_loss: 1.454\n",
      "Training epoch 0, iteration 54/99 | lr: 3e-05 | global_batch_size: 1 | global_step: 54 | reduced_train_loss: 1.826 | train_step_timing in s: 0.3985 | consumed_samples: 55 | val_loss: 1.454\n",
      "Training epoch 0, iteration 55/99 | lr: 3e-05 | global_batch_size: 1 | global_step: 55 | reduced_train_loss: 0.5121 | train_step_timing in s: 0.3803 | consumed_samples: 56 | val_loss: 1.454\n",
      "Training epoch 0, iteration 56/99 | lr: 3e-05 | global_batch_size: 1 | global_step: 56 | reduced_train_loss: 1.675 | train_step_timing in s: 0.3961 | consumed_samples: 57 | val_loss: 1.454\n",
      "Training epoch 0, iteration 57/99 | lr: 3e-05 | global_batch_size: 1 | global_step: 57 | reduced_train_loss: 0.5731 | train_step_timing in s: 0.3165 | consumed_samples: 58 | val_loss: 1.454\n",
      "Training epoch 0, iteration 58/99 | lr: 3e-05 | global_batch_size: 1 | global_step: 58 | reduced_train_loss: 2.553 | train_step_timing in s: 0.3276 | consumed_samples: 59 | val_loss: 1.454\n",
      "Training epoch 0, iteration 59/99 | lr: 3e-05 | global_batch_size: 1 | global_step: 59 | reduced_train_loss: 0.6041 | train_step_timing in s: 0.4099 | consumed_samples: 60 | val_loss: 1.454\n",
      "Training epoch 0, iteration 60/99 | lr: 3e-05 | global_batch_size: 1 | global_step: 60 | reduced_train_loss: 0.6049 | train_step_timing in s: 0.389 | consumed_samples: 61 | val_loss: 1.454\n",
      "Training epoch 0, iteration 61/99 | lr: 3e-05 | global_batch_size: 1 | global_step: 61 | reduced_train_loss: 1.534 | train_step_timing in s: 0.3813 | consumed_samples: 62 | val_loss: 1.454\n",
      "Training epoch 0, iteration 62/99 | lr: 3e-05 | global_batch_size: 1 | global_step: 62 | reduced_train_loss: 2.382 | train_step_timing in s: 0.3868 | consumed_samples: 63 | val_loss: 1.454\n",
      "Training epoch 0, iteration 63/99 | lr: 3e-05 | global_batch_size: 1 | global_step: 63 | reduced_train_loss: 1.516 | train_step_timing in s: 0.4028 | consumed_samples: 64 | val_loss: 1.454\n",
      "Training epoch 0, iteration 64/99 | lr: 3e-05 | global_batch_size: 1 | global_step: 64 | reduced_train_loss: 0.6058 | train_step_timing in s: 0.3237 | consumed_samples: 65 | val_loss: 1.454\n",
      "Training epoch 0, iteration 65/99 | lr: 3e-05 | global_batch_size: 1 | global_step: 65 | reduced_train_loss: 2.254 | train_step_timing in s: 0.3438 | consumed_samples: 66 | val_loss: 1.454\n",
      "Training epoch 0, iteration 66/99 | lr: 3e-05 | global_batch_size: 1 | global_step: 66 | reduced_train_loss: 2.19 | train_step_timing in s: 0.3902 | consumed_samples: 67 | val_loss: 1.454\n",
      "Training epoch 0, iteration 67/99 | lr: 3e-05 | global_batch_size: 1 | global_step: 67 | reduced_train_loss: 0.6077 | train_step_timing in s: 0.3972 | consumed_samples: 68 | val_loss: 1.454\n",
      "Training epoch 0, iteration 68/99 | lr: 3e-05 | global_batch_size: 1 | global_step: 68 | reduced_train_loss: 0.6014 | train_step_timing in s: 0.384 | consumed_samples: 69 | val_loss: 1.454\n",
      "Training epoch 0, iteration 69/99 | lr: 3e-05 | global_batch_size: 1 | global_step: 69 | reduced_train_loss: 1.969 | train_step_timing in s: 0.3916 | consumed_samples: 70 | val_loss: 1.454\n",
      "Training epoch 0, iteration 70/99 | lr: 3e-05 | global_batch_size: 1 | global_step: 70 | reduced_train_loss: 1.596 | train_step_timing in s: 0.4204 | consumed_samples: 71 | val_loss: 1.454\n",
      "Training epoch 0, iteration 71/99 | lr: 3e-05 | global_batch_size: 1 | global_step: 71 | reduced_train_loss: 1.617 | train_step_timing in s: 0.3241 | consumed_samples: 72 | val_loss: 1.454\n",
      "Training epoch 0, iteration 72/99 | lr: 3e-05 | global_batch_size: 1 | global_step: 72 | reduced_train_loss: 2.525 | train_step_timing in s: 0.3687 | consumed_samples: 73 | val_loss: 1.454\n",
      "Training epoch 0, iteration 73/99 | lr: 3e-05 | global_batch_size: 1 | global_step: 73 | reduced_train_loss: 1.594 | train_step_timing in s: 0.3814 | consumed_samples: 74 | val_loss: 1.454\n",
      "Training epoch 0, iteration 74/99 | lr: 3e-05 | global_batch_size: 1 | global_step: 74 | reduced_train_loss: 0.6356 | train_step_timing in s: 0.3816 | consumed_samples: 75 | val_loss: 1.454\n",
      "Training epoch 0, iteration 75/99 | lr: 3e-05 | global_batch_size: 1 | global_step: 75 | reduced_train_loss: 1.529 | train_step_timing in s: 0.3908 | consumed_samples: 76 | val_loss: 1.454\n",
      "Training epoch 0, iteration 76/99 | lr: 3e-05 | global_batch_size: 1 | global_step: 76 | reduced_train_loss: 1.497 | train_step_timing in s: 0.3984 | consumed_samples: 77 | val_loss: 1.454\n",
      "Training epoch 0, iteration 77/99 | lr: 3e-05 | global_batch_size: 1 | global_step: 77 | reduced_train_loss: 0.6858 | train_step_timing in s: 0.331 | consumed_samples: 78 | val_loss: 1.454\n",
      "Training epoch 0, iteration 78/99 | lr: 3e-05 | global_batch_size: 1 | global_step: 78 | reduced_train_loss: 2.566 | train_step_timing in s: 0.3092 | consumed_samples: 79 | val_loss: 1.454\n",
      "Training epoch 0, iteration 79/99 | lr: 3e-05 | global_batch_size: 1 | global_step: 79 | reduced_train_loss: 1.367 | train_step_timing in s: 0.3405 | consumed_samples: 80 | val_loss: 1.454\n",
      "Training epoch 0, iteration 80/99 | lr: 3e-05 | global_batch_size: 1 | global_step: 80 | reduced_train_loss: 0.734 | train_step_timing in s: 0.3988 | consumed_samples: 81 | val_loss: 1.454\n",
      "Training epoch 0, iteration 81/99 | lr: 3e-05 | global_batch_size: 1 | global_step: 81 | reduced_train_loss: 1.81 | train_step_timing in s: 0.3874 | consumed_samples: 82 | val_loss: 1.454\n",
      "Training epoch 0, iteration 82/99 | lr: 3e-05 | global_batch_size: 1 | global_step: 82 | reduced_train_loss: 0.7574 | train_step_timing in s: 0.4045 | consumed_samples: 83 | val_loss: 1.454\n",
      "Training epoch 0, iteration 83/99 | lr: 3e-05 | global_batch_size: 1 | global_step: 83 | reduced_train_loss: 2.499 | train_step_timing in s: 0.4003 | consumed_samples: 84 | val_loss: 1.454\n",
      "Training epoch 0, iteration 84/99 | lr: 3e-05 | global_batch_size: 1 | global_step: 84 | reduced_train_loss: 2.47 | train_step_timing in s: 0.3715 | consumed_samples: 85 | val_loss: 1.454\n",
      "Training epoch 0, iteration 85/99 | lr: 3e-05 | global_batch_size: 1 | global_step: 85 | reduced_train_loss: 1.813 | train_step_timing in s: 0.3236 | consumed_samples: 86 | val_loss: 1.454\n",
      "Training epoch 0, iteration 86/99 | lr: 3e-05 | global_batch_size: 1 | global_step: 86 | reduced_train_loss: 1.276 | train_step_timing in s: 0.3799 | consumed_samples: 87 | val_loss: 1.454\n",
      "Training epoch 0, iteration 87/99 | lr: 3e-05 | global_batch_size: 1 | global_step: 87 | reduced_train_loss: 0.7981 | train_step_timing in s: 0.3897 | consumed_samples: 88 | val_loss: 1.454\n",
      "Training epoch 0, iteration 88/99 | lr: 3e-05 | global_batch_size: 1 | global_step: 88 | reduced_train_loss: 1.784 | train_step_timing in s: 0.3883 | consumed_samples: 89 | val_loss: 1.454\n",
      "Training epoch 0, iteration 89/99 | lr: 3e-05 | global_batch_size: 1 | global_step: 89 | reduced_train_loss: 1.757 | train_step_timing in s: 0.3889 | consumed_samples: 90 | val_loss: 1.454\n",
      "Training epoch 0, iteration 90/99 | lr: 3e-05 | global_batch_size: 1 | global_step: 90 | reduced_train_loss: 1.706 | train_step_timing in s: 0.3836 | consumed_samples: 91 | val_loss: 1.454\n",
      "Training epoch 0, iteration 91/99 | lr: 3e-05 | global_batch_size: 1 | global_step: 91 | reduced_train_loss: 0.8544 | train_step_timing in s: 0.3742 | consumed_samples: 92 | val_loss: 1.454\n",
      "Training epoch 0, iteration 92/99 | lr: 3e-05 | global_batch_size: 1 | global_step: 92 | reduced_train_loss: 1.351 | train_step_timing in s: 0.3215 | consumed_samples: 93 | val_loss: 1.454\n",
      "Training epoch 0, iteration 93/99 | lr: 3e-05 | global_batch_size: 1 | global_step: 93 | reduced_train_loss: 2.148 | train_step_timing in s: 0.3792 | consumed_samples: 94 | val_loss: 1.454\n",
      "Training epoch 0, iteration 94/99 | lr: 3e-05 | global_batch_size: 1 | global_step: 94 | reduced_train_loss: 0.891 | train_step_timing in s: 0.3855 | consumed_samples: 95 | val_loss: 1.454\n",
      "Training epoch 0, iteration 95/99 | lr: 3e-05 | global_batch_size: 1 | global_step: 95 | reduced_train_loss: 0.8889 | train_step_timing in s: 0.3739 | consumed_samples: 96 | val_loss: 1.454\n",
      "Training epoch 0, iteration 96/99 | lr: 3e-05 | global_batch_size: 1 | global_step: 96 | reduced_train_loss: 0.882 | train_step_timing in s: 0.3967 | consumed_samples: 97 | val_loss: 1.454\n",
      "Training epoch 0, iteration 97/99 | lr: 3e-05 | global_batch_size: 1 | global_step: 97 | reduced_train_loss: 1.506 | train_step_timing in s: 0.3965 | consumed_samples: 98 | val_loss: 1.454\n",
      "Training epoch 0, iteration 98/99 | lr: 3e-05 | global_batch_size: 1 | global_step: 98 | reduced_train_loss: 1.494 | train_step_timing in s: 0.3747 | consumed_samples: 99 | val_loss: 1.454\n",
      "Training epoch 0, iteration 99/99 | lr: 3e-05 | global_batch_size: 1 | global_step: 99 | reduced_train_loss: 1.544 | train_step_timing in s: 0.3161 | consumed_samples: 100 | val_loss: 1.454\n",
      "Epoch 0, global step 99: 'val_loss' reached 1.45366 (best 1.45366), saving model to '/workspace/results/evo2/checkpoints/evo2--val_loss=1.4537-epoch=0-consumed_samples=100.0.ckpt' as top 5\n",
      "[NeMo I 2025-05-24 15:55:46 nemo_logging:393] Global Checkpoint Save : Rank: 0 : Iteration: 99 : Start time: 1748102146.465s : Save duration: 0.504s\n",
      "[NeMo I 2025-05-24 15:55:52 nemo_logging:393] Scheduled async checkpoint save for /workspace/results/evo2/checkpoints/evo2--val_loss=1.4537-epoch=0-consumed_samples=100.0.ckpt\n",
      "[NeMo I 2025-05-24 15:55:53 nemo_logging:393] Global Checkpoint Save : Rank: 0 : Iteration: 99 : Start time: 1748102152.870s : Save duration: 0.788s\n",
      "[NeMo I 2025-05-24 15:56:00 nemo_logging:393] Scheduled async checkpoint save for /workspace/results/evo2/checkpoints/evo2--val_loss=1.4537-epoch=0-consumed_samples=100.0-last.ckpt\n",
      "[NeMo I 2025-05-24 15:56:00 nemo_logging:393] Async finalization time took 0.003 s\n",
      "Validation: iteration 1/20\n",
      "Validation: iteration 2/20\n",
      "Validation: iteration 3/20\n",
      "Validation: iteration 4/20\n",
      "Validation: iteration 5/20\n",
      "Validation: iteration 6/20\n",
      "Validation: iteration 7/20\n",
      "Validation: iteration 8/20\n",
      "Validation: iteration 9/20\n",
      "Validation: iteration 10/20\n",
      "Validation: iteration 11/20\n",
      "Validation: iteration 12/20\n",
      "Validation: iteration 13/20\n",
      "Validation: iteration 14/20\n",
      "Validation: iteration 15/20\n",
      "Validation: iteration 16/20\n",
      "Validation: iteration 17/20\n",
      "Validation: iteration 18/20\n",
      "Validation: iteration 19/20\n",
      "Validation: iteration 20/20\n",
      "[NeMo I 2025-05-24 15:56:55 nemo_logging:393] Successfully saved checkpoint from iteration      99 to /workspace/results/evo2/checkpoints/evo2--val_loss=1.4537-epoch=0-consumed_samples=100.0.ckpt\n",
      "[NeMo I 2025-05-24 15:56:55 nemo_logging:393] Async checkpoint save for step 100 (/workspace/results/evo2/checkpoints/evo2--val_loss=1.4537-epoch=0-consumed_samples=100.0.ckpt) finalized successfully.\n",
      "[NeMo I 2025-05-24 15:56:56 nemo_logging:393] Successfully saved checkpoint from iteration      99 to /workspace/results/evo2/checkpoints/evo2--val_loss=1.4537-epoch=0-consumed_samples=100.0-last.ckpt\n",
      "[NeMo I 2025-05-24 15:56:56 nemo_logging:393] Async checkpoint save for step 100 (/workspace/results/evo2/checkpoints/evo2--val_loss=1.4537-epoch=0-consumed_samples=100.0-last.ckpt) finalized successfully.\n",
      "[NeMo I 2025-05-24 15:56:56 nemo_logging:393] Async finalization time took 1.020 s\n",
      "`Trainer.fit` stopped: `max_steps=100` reached.\n"
     ]
    }
   ],
   "source": [
    "!train_evo2 \\\n",
    "    -d training_data_config.yaml \\\n",
    "    --dataset-dir {preprocessed_data} \\\n",
    "    --model-size 1b \\\n",
    "    --devices 1 \\\n",
    "    --num-nodes 1 \\\n",
    "    --seq-length 1 \\\n",
    "    --micro-batch-size 1 \\\n",
    "    --lr 0.0001 \\\n",
    "    --warmup-steps 5 \\\n",
    "    --max-steps 100 \\\n",
    "    --ckpt-dir nemo2_evo2_1b_8k \\\n",
    "    --clip-grad 1 \\\n",
    "    --wd 0.01 \\\n",
    "    --activation-checkpoint-recompute-num-layers 1 \\\n",
    "    --val-check-interval 50 \\\n",
    "    --ckpt-async-save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "eb824a00-ea7c-4ef2-8e0b-66e6189876c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mDEPRECATION: Loading egg at /usr/local/lib/python3.12/dist-packages/looseversion-1.3.0-py3.12.egg is deprecated. pip 25.1 will enforce this behaviour change. A possible replacement is to use pip for package installation. Discussion can be found at https://github.com/pypa/pip/issues/12330\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mDEPRECATION: Loading egg at /usr/local/lib/python3.12/dist-packages/lightning_utilities-0.12.0.dev0-py3.12.egg is deprecated. pip 25.1 will enforce this behaviour change. A possible replacement is to use pip for package installation. Discussion can be found at https://github.com/pypa/pip/issues/12330\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mDEPRECATION: Loading egg at /usr/local/lib/python3.12/dist-packages/dill-0.3.9-py3.12.egg is deprecated. pip 25.1 will enforce this behaviour change. A possible replacement is to use pip for package installation. Discussion can be found at https://github.com/pypa/pip/issues/12330\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mDEPRECATION: Loading egg at /usr/local/lib/python3.12/dist-packages/opt_einsum-3.4.0-py3.12.egg is deprecated. pip 25.1 will enforce this behaviour change. A possible replacement is to use pip for package installation. Discussion can be found at https://github.com/pypa/pip/issues/12330\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mDEPRECATION: Loading egg at /usr/local/lib/python3.12/dist-packages/nvfuser-0.2.23a0+6627725-py3.12-linux-x86_64.egg is deprecated. pip 25.1 will enforce this behaviour change. A possible replacement is to use pip for package installation. Discussion can be found at https://github.com/pypa/pip/issues/12330\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mDEPRECATION: Loading egg at /usr/local/lib/python3.12/dist-packages/lightning_thunder-0.2.0.dev0-py3.12.egg is deprecated. pip 25.1 will enforce this behaviour change. A possible replacement is to use pip for package installation. Discussion can be found at https://github.com/pypa/pip/issues/12330\u001b[0m\u001b[33m\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install -q peft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e4f1a484-0a58-4fe2-bb80-b344eeba271e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cp /workspace/bionemo_train.py /usr/local/lib/python3.12/dist-packages/bionemo/evo2/run/train.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7f72369-7e12-4796-a18c-3822b4598e03",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not find the bitsandbytes CUDA binary at PosixPath('/usr/local/lib/python3.12/dist-packages/bitsandbytes/libbitsandbytes_cuda129.so')\n",
      "The installed version of bitsandbytes was compiled without GPU support. 8-bit optimizers, 8-bit multiplication, and GPU quantization are unavailable.\n",
      "[NeMo I 2025-06-01 15:37:07 nemo_logging:393] Using byte-level tokenization\n",
      "[NeMo W 2025-06-01 15:37:07 nemo_logging:405] WandB is currently turned off.\n",
      "[NeMo W 2025-06-01 15:37:07 nemo_logging:405] User-set tensorboard is currently turned off. Internally one may still be set by NeMo2.\n",
      "Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "[NeMo I 2025-06-01 15:37:07 nemo_logging:393] Experiments will be logged at results/evo2/dev\n",
      "[NeMo W 2025-06-01 15:37:07 nemo_logging:405] There were no checkpoints found in checkpoint_dir or no checkpoint folder at checkpoint_dir :results/evo2/checkpoints. Training from scratch.\n",
      "[NeMo I 2025-06-01 15:37:07 nemo_logging:393] Fixing mis-match between ddp-config & mcore-optimizer config\n",
      "[NeMo I 2025-06-01 15:37:07 nemo_logging:393] Rank 0 has data parallel group : [0]\n",
      "[NeMo I 2025-06-01 15:37:07 nemo_logging:393] Rank 0 has combined group of data parallel and context parallel : [0]\n",
      "[NeMo I 2025-06-01 15:37:07 nemo_logging:393] All data parallel group ranks with context parallel combined: [[0]]\n",
      "[NeMo I 2025-06-01 15:37:07 nemo_logging:393] Ranks 0 has data parallel rank: 0\n",
      "[NeMo I 2025-06-01 15:37:07 nemo_logging:393] Rank 0 has context parallel group: [0]\n",
      "[NeMo I 2025-06-01 15:37:07 nemo_logging:393] All context parallel group ranks: [[0]]\n",
      "[NeMo I 2025-06-01 15:37:07 nemo_logging:393] Ranks 0 has context parallel rank: 0\n",
      "[NeMo I 2025-06-01 15:37:07 nemo_logging:393] Rank 0 has model parallel group: [0]\n",
      "[NeMo I 2025-06-01 15:37:07 nemo_logging:393] All model parallel group ranks: [[0]]\n",
      "[NeMo I 2025-06-01 15:37:07 nemo_logging:393] Rank 0 has tensor model parallel group: [0]\n",
      "[NeMo I 2025-06-01 15:37:07 nemo_logging:393] All tensor model parallel group ranks: [[0]]\n",
      "[NeMo I 2025-06-01 15:37:07 nemo_logging:393] Rank 0 has tensor model parallel rank: 0\n",
      "[NeMo I 2025-06-01 15:37:07 nemo_logging:393] Rank 0 has pipeline model parallel group: [0]\n",
      "[NeMo I 2025-06-01 15:37:07 nemo_logging:393] Rank 0 has embedding group: [0]\n",
      "[NeMo I 2025-06-01 15:37:07 nemo_logging:393] All pipeline model parallel group ranks: [[0]]\n",
      "[NeMo I 2025-06-01 15:37:07 nemo_logging:393] Rank 0 has pipeline model parallel rank 0\n",
      "[NeMo I 2025-06-01 15:37:07 nemo_logging:393] All embedding group ranks: [[0]]\n",
      "[NeMo I 2025-06-01 15:37:07 nemo_logging:393] Rank 0 has embedding rank: 0\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 1 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[NeMo I 2025-06-01 15:37:08 utils:554] Building Evo2Dataset splits with sizes=[300000, 6020, 1] and config=GPTDatasetConfig(random_seed=1234, sequence_length=1, blend=None, blend_per_split=[(['/workspace/preprocessed_data/XTT22_train_byte-level_train'], [1.0]), (['/workspace/preprocessed_data/XTT22_train_byte-level_val'], [1.0]), (['/workspace/preprocessed_data/XTT22_train_byte-level_test'], [1.0])], split=None, split_matrix=None, num_dataset_builder_threads=1, path_to_cache=None, mmap_bin_files=True, mock=False, tokenizer=<nemo.collections.common.tokenizers.bytelevel_tokenizers.ByteLevelTokenizer object at 0x77e4f623ba40>, mid_level_dataset_surplus=0.005, reset_position_ids=False, reset_attention_mask=False, eod_mask_loss=False, create_attention_mask=False, drop_last_partial_validation_sequence=True, add_extra_token_to_sequence=True, object_storage_cache_path=None)\n",
      "[NeMo I 2025-06-01 15:37:08 utils:554] Load the _IndexReader from /workspace/preprocessed_data/XTT22_train_byte-level_train.idx\n",
      "[NeMo I 2025-06-01 15:37:08 utils:554] \tExtract the sequence lengths\n",
      "[NeMo I 2025-06-01 15:37:08 utils:554] \tExtract the sequence pointers\n",
      "[NeMo I 2025-06-01 15:37:08 utils:554] \tExtract the document indices\n",
      "[NeMo I 2025-06-01 15:37:08 utils:554] > total number of sequences: 10896\n",
      "[NeMo I 2025-06-01 15:37:08 utils:554] > total number of documents: 10896\n",
      "[NeMo I 2025-06-01 15:37:08 utils:554] Build and save the Evo2Dataset train indices\n"
     ]
    }
   ],
   "source": [
    "\n",
    "!train_evo2 \\\n",
    "    -d training_data_config.yaml \\\n",
    "    --dataset-dir {preprocessed_data} \\\n",
    "    --model-size 1b \\\n",
    "    --devices 1 \\\n",
    "    --num-nodes 1 \\\n",
    "    --seq-length 1 \\\n",
    "    --micro-batch-size 1 \\\n",
    "    --lr 0.0001 \\\n",
    "    --warmup-steps 5 \\\n",
    "    --max-steps 300000 \\\n",
    "    --ckpt-dir nemo2_evo2_1b_8k \\\n",
    "    --clip-grad 1 \\\n",
    "    --wd 0.01 \\\n",
    "    --activation-checkpoint-recompute-num-layers 1 \\\n",
    "    --val-check-interval 1000 \\\n",
    "    --ckpt-async-save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ad8f9c7-55d5-4876-9a7b-ab7720eb8c85",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import stat\n",
    "\n",
    "# 检查文件路径\n",
    "file_path = \"/usr/local/bin/train_evo2\"\n",
    "\n",
    "# 首先检查文件是否存在\n",
    "if os.path.exists(file_path):\n",
    "    print(f\"文件存在: {file_path}\")\n",
    "    \n",
    "    # 获取文件信息\n",
    "    file_stat = os.stat(file_path)\n",
    "    print(f\"文件大小: {file_stat.st_size} 字节\")\n",
    "    print(f\"文件权限: {stat.filemode(file_stat.st_mode)}\")\n",
    "    print(f\"是否可执行: {os.access(file_path, os.X_OK)}\")\n",
    "    \n",
    "    # 检查文件类型\n",
    "    with open(file_path, 'rb') as f:\n",
    "        first_bytes = f.read(100)\n",
    "        print(f\"文件开头字节: {first_bytes[:50]}\")\n",
    "        \n",
    "        # 检查是否是文本文件\n",
    "        try:\n",
    "            first_text = first_bytes.decode('utf-8')\n",
    "            print(\"这是一个文本文件\")\n",
    "            print(f\"文件开头内容: {first_text[:100]}...\")\n",
    "        except UnicodeDecodeError:\n",
    "            print(\"这是一个二进制文件\")\n",
    "    \n",
    "    # 如果是Python脚本，显示基本信息（不显示完整内容）\n",
    "    if file_path.endswith('.py') or 'python' in first_text.lower():\n",
    "        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            lines = f.readlines()\n",
    "            print(f\"\\n总行数: {len(lines)}\")\n",
    "            print(\"文件头部信息（前5行）:\")\n",
    "            for i, line in enumerate(lines[:100]):\n",
    "                print(f\"{i+1}: {line.rstrip()}\")\n",
    "else:\n",
    "    print(f\"文件不存在: {file_path}\")\n",
    "    \n",
    "    # 检查可能的替代路径\n",
    "    possible_paths = [\n",
    "        \"/usr/local/bin/train_evo2\",\n",
    "        \"/usr/local/lib/python3.12/dist-packages/bionemo/evo2/run/train.py\",\n",
    "        \"/usr/local/lib/python3.12/dist-packages/bionemo/evo2/train.py\"\n",
    "    ]\n",
    "    \n",
    "    print(\"\\n检查其他可能的路径:\")\n",
    "    for path in possible_paths:\n",
    "        if os.path.exists(path):\n",
    "            print(f\"✓ 找到: {path}\")\n",
    "        else:\n",
    "            print(f\"✗ 不存在: {path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b51390c9-cb5e-4016-b79a-80effcc109da",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "打印 BioNeMo Evo2 训练脚本内容\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "def print_file_content():\n",
    "    \"\"\"打印指定文件的内容\"\"\"\n",
    "    \n",
    "    file_path = \"/usr/local/lib/python3.12/dist-packages/bionemo/evo2/run/train.py\"\n",
    "    \n",
    "    print(\"=\" * 80)\n",
    "    print(f\"文件路径: {file_path}\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    try:\n",
    "        # 检查文件是否存在\n",
    "        if not os.path.exists(file_path):\n",
    "            print(f\"❌ 文件不存在: {file_path}\")\n",
    "            \n",
    "            # 尝试查找类似的文件\n",
    "            print(\"\\n正在搜索相关文件...\")\n",
    "            base_dir = \"/usr/local/lib/python3.12/dist-packages/\"\n",
    "            \n",
    "            if os.path.exists(base_dir):\n",
    "                print(f\"✓ 基础目录存在: {base_dir}\")\n",
    "                \n",
    "                # 搜索 bionemo 相关目录\n",
    "                for root, dirs, files in os.walk(base_dir):\n",
    "                    if \"bionemo\" in root.lower():\n",
    "                        print(f\"找到相关目录: {root}\")\n",
    "                        if \"train.py\" in files:\n",
    "                            print(f\"  -> 包含 train.py: {os.path.join(root, 'train.py')}\")\n",
    "            else:\n",
    "                print(f\"❌ 基础目录不存在: {base_dir}\")\n",
    "            \n",
    "            return False\n",
    "        \n",
    "        # 读取并打印文件内容\n",
    "        print(f\"✓ 文件存在，正在读取内容...\\n\")\n",
    "        \n",
    "        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            content = f.read()\n",
    "        \n",
    "        # 打印文件信息\n",
    "        lines = content.split('\\n')\n",
    "        print(f\"文件大小: {len(content)} 字符\")\n",
    "        print(f\"行数: {len(lines)}\")\n",
    "        print(\"-\" * 80)\n",
    "        \n",
    "        # 打印内容（带行号）\n",
    "        for i, line in enumerate(lines, 1):\n",
    "            print(f\"{i:4d}: {line}\")\n",
    "        \n",
    "        print(\"-\" * 80)\n",
    "        print(\"✓ 文件内容已打印完成\")\n",
    "        return True\n",
    "        \n",
    "    except PermissionError:\n",
    "        print(f\"❌ 权限不足，无法读取文件: {file_path}\")\n",
    "        print(\"请尝试使用 sudo 运行此脚本\")\n",
    "        return False\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ 读取文件时发生错误: {e}\")\n",
    "        return False\n",
    "\n",
    "def search_alternative_paths():\n",
    "    \"\"\"搜索可能的替代路径\"\"\"\n",
    "    \n",
    "    potential_paths = [\n",
    "        \"/usr/local/lib/python3.12/dist-packages/bionemo/evo2/run/train.py\",\n",
    "        \"/usr/local/lib/python3.11/dist-packages/bionemo/evo2/run/train.py\",\n",
    "        \"/usr/lib/python3.12/dist-packages/bionemo/evo2/run/train.py\",\n",
    "        \"/usr/lib/python3.11/dist-packages/bionemo/evo2/run/train.py\",\n",
    "    ]\n",
    "    \n",
    "    # 也检查当前用户的site-packages\n",
    "    import site\n",
    "    user_site = site.getusersitepackages()\n",
    "    if user_site:\n",
    "        potential_paths.append(f\"{user_site}/bionemo/evo2/run/train.py\")\n",
    "    \n",
    "    print(\"\\n搜索可能的路径:\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    found_files = []\n",
    "    for path in potential_paths:\n",
    "        if os.path.exists(path):\n",
    "            print(f\"✓ 找到: {path}\")\n",
    "            found_files.append(path)\n",
    "        else:\n",
    "            print(f\"✗ 不存在: {path}\")\n",
    "    \n",
    "    return found_files\n",
    "\n",
    "def main():\n",
    "    \"\"\"主函数\"\"\"\n",
    "    print(\"BioNeMo Evo2 训练脚本内容查看器\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    # 首先尝试打印目标文件\n",
    "    success = print_file_content()\n",
    "    \n",
    "    if not success:\n",
    "        # 如果失败，搜索替代路径\n",
    "        found_files = search_alternative_paths()\n",
    "        \n",
    "        if found_files:\n",
    "            print(f\"\\n找到 {len(found_files)} 个相关文件。\")\n",
    "            for i, file_path in enumerate(found_files, 1):\n",
    "                print(f\"\\n{i}. 正在打印: {file_path}\")\n",
    "                print(\"=\" * 80)\n",
    "                \n",
    "                try:\n",
    "                    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "                        content = f.read()\n",
    "                    \n",
    "                    lines = content.split('\\n')\n",
    "                    print(f\"文件大小: {len(content)} 字符\")\n",
    "                    print(f\"行数: {len(lines)}\")\n",
    "                    print(\"-\" * 80)\n",
    "                    \n",
    "                    for line_num, line in enumerate(lines, 1):\n",
    "                        print(f\"{line_num:4d}: {line}\")\n",
    "                    \n",
    "                    print(\"-\" * 80)\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    print(f\"❌ 读取文件 {file_path} 时发生错误: {e}\")\n",
    "        else:\n",
    "            print(\"\\n❌ 未找到任何相关的训练脚本文件\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ec85fb63-1214-45f4-849b-87f54166d833",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cp /workspace/hyena_modified.py /usr/local/lib/python3.12/dist-packages/nemo/collections/llm/gpt/model/hyena.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9a20f4f4-8c19-44b7-94b5-db53eff61976",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not find the bitsandbytes CUDA binary at PosixPath('/usr/local/lib/python3.12/dist-packages/bitsandbytes/libbitsandbytes_cuda129.so')\n",
      "The installed version of bitsandbytes was compiled without GPU support. 8-bit optimizers, 8-bit multiplication, and GPU quantization are unavailable.\n",
      "[NeMo I 2025-06-02 07:46:00 nemo_logging:393] Using byte-level tokenization\n",
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "[NeMo W 2025-06-02 07:46:00 nemo_logging:405] /usr/local/lib/python3.12/dist-packages/lightning/pytorch/trainer/setup.py:177: GPU available but not used. You can set it by doing `Trainer(accelerator='gpu')`.\n",
      "    \n",
      "[NeMo I 2025-06-02 07:46:00 nemo_logging:393] Fixing mis-match between ddp-config & mcore-optimizer config\n",
      "[NeMo I 2025-06-02 07:46:00 nemo_logging:393] Rank 0 has data parallel group : [0]\n",
      "[NeMo I 2025-06-02 07:46:00 nemo_logging:393] Rank 0 has combined group of data parallel and context parallel : [0]\n",
      "[NeMo I 2025-06-02 07:46:00 nemo_logging:393] All data parallel group ranks with context parallel combined: [[0]]\n",
      "[NeMo I 2025-06-02 07:46:00 nemo_logging:393] Ranks 0 has data parallel rank: 0\n",
      "[NeMo I 2025-06-02 07:46:00 nemo_logging:393] Rank 0 has context parallel group: [0]\n",
      "[NeMo I 2025-06-02 07:46:00 nemo_logging:393] All context parallel group ranks: [[0]]\n",
      "[NeMo I 2025-06-02 07:46:00 nemo_logging:393] Ranks 0 has context parallel rank: 0\n",
      "[NeMo I 2025-06-02 07:46:00 nemo_logging:393] Rank 0 has model parallel group: [0]\n",
      "[NeMo I 2025-06-02 07:46:00 nemo_logging:393] All model parallel group ranks: [[0]]\n",
      "[NeMo I 2025-06-02 07:46:00 nemo_logging:393] Rank 0 has tensor model parallel group: [0]\n",
      "[NeMo I 2025-06-02 07:46:00 nemo_logging:393] All tensor model parallel group ranks: [[0]]\n",
      "[NeMo I 2025-06-02 07:46:00 nemo_logging:393] Rank 0 has tensor model parallel rank: 0\n",
      "[NeMo I 2025-06-02 07:46:00 nemo_logging:393] Rank 0 has pipeline model parallel group: [0]\n",
      "[NeMo I 2025-06-02 07:46:00 nemo_logging:393] Rank 0 has embedding group: [0]\n",
      "[NeMo I 2025-06-02 07:46:00 nemo_logging:393] All pipeline model parallel group ranks: [[0]]\n",
      "[NeMo I 2025-06-02 07:46:00 nemo_logging:393] Rank 0 has pipeline model parallel rank 0\n",
      "[NeMo I 2025-06-02 07:46:00 nemo_logging:393] All embedding group ranks: [[0]]\n",
      "[NeMo I 2025-06-02 07:46:00 nemo_logging:393] Rank 0 has embedding rank: 0\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=gloo\n",
      "All distributed processes registered. Starting with 1 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[NeMo W 2025-06-02 07:46:00 nemo_logging:405] /usr/local/lib/python3.12/dist-packages/lightning/pytorch/trainer/trainer.py:1090: `trainer.init_module` cannot fully support proper instantiation of your model with the `MegatronStrategy` strategy. Please instantiate your model inside the`LightningModule.configure_model` hook instead\n",
      "    \n",
      "[NeMo I 2025-06-02 07:46:00 nemo_logging:393] Padded vocab_size: 512, original vocab_size: 512, dummy tokens: 0.\n",
      "CPU RNG state changed within GPU RNG context\n",
      "CPU RNG state changed within GPU RNG context\n",
      "CPU RNG state changed within GPU RNG context\n",
      "CPU RNG state changed within GPU RNG context\n",
      "CPU RNG state changed within GPU RNG context\n",
      "CPU RNG state changed within GPU RNG context\n",
      "CPU RNG state changed within GPU RNG context\n",
      "CPU RNG state changed within GPU RNG context\n",
      "CPU RNG state changed within GPU RNG context\n",
      "CPU RNG state changed within GPU RNG context\n",
      "CPU RNG state changed within GPU RNG context\n",
      "CPU RNG state changed within GPU RNG context\n",
      "CPU RNG state changed within GPU RNG context\n",
      "CPU RNG state changed within GPU RNG context\n",
      "CPU RNG state changed within GPU RNG context\n",
      "CPU RNG state changed within GPU RNG context\n",
      "CPU RNG state changed within GPU RNG context\n",
      "CPU RNG state changed within GPU RNG context\n",
      "[NeMo W 2025-06-02 07:46:04 nemo_logging:405] Converting sequential.2.mixer.mixer.filter.t from torch.float32 (source model) to torch.bfloat16 (target model)\n",
      "[NeMo W 2025-06-02 07:46:04 nemo_logging:405] Converting sequential.6.mixer.mixer.filter.t from torch.float32 (source model) to torch.bfloat16 (target model)\n",
      "[NeMo W 2025-06-02 07:46:04 nemo_logging:405] Converting sequential.9.mixer.mixer.filter.t from torch.float32 (source model) to torch.bfloat16 (target model)\n",
      "[NeMo W 2025-06-02 07:46:04 nemo_logging:405] Converting sequential.13.mixer.mixer.filter.t from torch.float32 (source model) to torch.bfloat16 (target model)\n",
      "[NeMo W 2025-06-02 07:46:04 nemo_logging:405] Converting sequential.16.mixer.mixer.filter.t from torch.float32 (source model) to torch.bfloat16 (target model)\n",
      "[NeMo W 2025-06-02 07:46:04 nemo_logging:405] Converting sequential.20.mixer.mixer.filter.t from torch.float32 (source model) to torch.bfloat16 (target model)\n",
      "[NeMo W 2025-06-02 07:46:04 nemo_logging:405] Converting sequential.23.mixer.mixer.filter.t from torch.float32 (source model) to torch.bfloat16 (target model)\n",
      "[NeMo W 2025-06-02 07:46:04 nemo_logging:405] Converting sequential.27.mixer.mixer.filter.t from torch.float32 (source model) to torch.bfloat16 (target model)\n",
      "[NeMo W 2025-06-02 07:46:04 nemo_logging:405] Converting sequential.30.mixer.mixer.filter.t from torch.float32 (source model) to torch.bfloat16 (target model)\n",
      "[NeMo W 2025-06-02 07:46:05 nemo_logging:405] Could not copy Trainer's 'max_steps' to LR scheduler's 'max_steps'. If you are not using an LR scheduler, this warning can safely be ignored.\n",
      "[NeMo I 2025-06-02 07:46:05 nemo_logging:393] Using FullyParallelSaveStrategyWrapper(torch_dist, 1) dist-ckpt save strategy.\n",
      "Overwriting old incomplete / corrupted checkpoint...\n",
      "[NeMo I 2025-06-02 07:46:18 nemo_logging:393] Global Checkpoint Save : Rank: 0 : Iteration: 0 : Start time: 1748850365.187s : Save duration: 12.931s\n",
      "[NeMo I 2025-06-02 07:46:18 nemo_logging:393] Converted Hyena model to Nemo, model saved to nemo2_evo2_7b\n"
     ]
    }
   ],
   "source": [
    "!evo2_convert_to_nemo2 \\\n",
    "  --model-path /workspace/savanna_evo2_7b/savanna_evo2_7b.pt \\\n",
    "  --model-size 7b --output-dir nemo2_evo2_7b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "026ce977-d70f-40b8-90e3-8eba91cd315d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not find the bitsandbytes CUDA binary at PosixPath('/usr/local/lib/python3.12/dist-packages/bitsandbytes/libbitsandbytes_cuda129.so')\n",
      "The installed version of bitsandbytes was compiled without GPU support. 8-bit optimizers, 8-bit multiplication, and GPU quantization are unavailable.\n",
      "[NeMo I 2025-06-02 08:04:12 nemo_logging:393] Using byte-level tokenization\n",
      "启用 LoRA 微调...\n",
      "模型结构调试信息:\n",
      "--------------------------------------------------\n",
      "模型总共有 1 个模块\n",
      "尝试访问模型的其他属性...\n",
      "模块结构:\n",
      "   1.  (HyenaModel)\n",
      "\n",
      "目标模式: ['module.decoder.layers.17.self_attention.linear_qkv']\n",
      "\n",
      "所有线性层 (0):\n",
      "\n",
      "找到的注意力相关层 (0):\n",
      "\n",
      "找到的线性层 (0):\n",
      "\n",
      "找到的QKV层 (0):\n",
      "⚠️  没有找到任何线性层！模型可能还没有完全初始化。\n",
      "这在 NeMo/Megatron 框架中是正常的，模型结构会在训练开始时初始化。\n",
      "LoRA 配置已保存，将在模型完全初始化后应用。\n",
      "总参数数量: 0\n",
      "可训练参数数量: 0\n",
      "⚠️  警告: 模型总参数数量为0，可能模型初始化有问题\n",
      "⚠️  警告: 没有可训练的参数，LoRA 可能没有正确应用\n",
      "LoRA 将在训练开始时自动应用\n",
      "已添加 LoRA 回调，将在训练开始时应用 LoRA\n",
      "[NeMo W 2025-06-02 08:04:12 nemo_logging:405] WandB is currently turned off.\n",
      "[NeMo W 2025-06-02 08:04:12 nemo_logging:405] User-set tensorboard is currently turned off. Internally one may still be set by NeMo2.\n",
      "Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "[NeMo I 2025-06-02 08:04:12 nemo_logging:393] Experiments will be logged at results/evo2/dev\n",
      "[NeMo W 2025-06-02 08:04:12 nemo_logging:405] There were no checkpoints found in checkpoint_dir or no checkpoint folder at checkpoint_dir :results/evo2/checkpoints. Training from scratch.\n",
      "[NeMo I 2025-06-02 08:04:12 nemo_logging:393] Fixing mis-match between ddp-config & mcore-optimizer config\n",
      "[NeMo I 2025-06-02 08:04:12 nemo_logging:393] Rank 0 has data parallel group : [0, 1, 2, 3]\n",
      "[NeMo I 2025-06-02 08:04:12 nemo_logging:393] Rank 0 has combined group of data parallel and context parallel : [0, 1, 2, 3]\n",
      "[NeMo I 2025-06-02 08:04:12 nemo_logging:393] All data parallel group ranks with context parallel combined: [[0, 1, 2, 3]]\n",
      "[NeMo I 2025-06-02 08:04:12 nemo_logging:393] Ranks 0 has data parallel rank: 0\n",
      "[NeMo I 2025-06-02 08:04:12 nemo_logging:393] Rank 0 has context parallel group: [0]\n",
      "[NeMo I 2025-06-02 08:04:12 nemo_logging:393] All context parallel group ranks: [[0], [1], [2], [3]]\n",
      "[NeMo I 2025-06-02 08:04:12 nemo_logging:393] Ranks 0 has context parallel rank: 0\n",
      "[NeMo I 2025-06-02 08:04:12 nemo_logging:393] Rank 0 has model parallel group: [0]\n",
      "[NeMo I 2025-06-02 08:04:12 nemo_logging:393] All model parallel group ranks: [[0], [1], [2], [3]]\n",
      "[NeMo I 2025-06-02 08:04:12 nemo_logging:393] Rank 0 has tensor model parallel group: [0]\n",
      "[NeMo I 2025-06-02 08:04:12 nemo_logging:393] All tensor model parallel group ranks: [[0], [1], [2], [3]]\n",
      "[NeMo I 2025-06-02 08:04:12 nemo_logging:393] Rank 0 has tensor model parallel rank: 0\n",
      "[NeMo I 2025-06-02 08:04:12 nemo_logging:393] Rank 0 has pipeline model parallel group: [0]\n",
      "[NeMo I 2025-06-02 08:04:12 nemo_logging:393] Rank 0 has embedding group: [0]\n",
      "[NeMo I 2025-06-02 08:04:12 nemo_logging:393] All pipeline model parallel group ranks: [[0], [1], [2], [3]]\n",
      "[NeMo I 2025-06-02 08:04:12 nemo_logging:393] Rank 0 has pipeline model parallel rank 0\n",
      "[NeMo I 2025-06-02 08:04:12 nemo_logging:393] All embedding group ranks: [[0], [1], [2], [3]]\n",
      "[NeMo I 2025-06-02 08:04:12 nemo_logging:393] Rank 0 has embedding rank: 0\n",
      "Could not find the bitsandbytes CUDA binary at PosixPath('/usr/local/lib/python3.12/dist-packages/bitsandbytes/libbitsandbytes_cuda129.so')\n",
      "The installed version of bitsandbytes was compiled without GPU support. 8-bit optimizers, 8-bit multiplication, and GPU quantization are unavailable.\n",
      "Could not find the bitsandbytes CUDA binary at PosixPath('/usr/local/lib/python3.12/dist-packages/bitsandbytes/libbitsandbytes_cuda129.so')\n",
      "The installed version of bitsandbytes was compiled without GPU support. 8-bit optimizers, 8-bit multiplication, and GPU quantization are unavailable.\n",
      "Could not find the bitsandbytes CUDA binary at PosixPath('/usr/local/lib/python3.12/dist-packages/bitsandbytes/libbitsandbytes_cuda129.so')\n",
      "The installed version of bitsandbytes was compiled without GPU support. 8-bit optimizers, 8-bit multiplication, and GPU quantization are unavailable.\n",
      "启用 LoRA 微调...\n",
      "模型结构调试信息:\n",
      "--------------------------------------------------\n",
      "模型总共有 1 个模块\n",
      "尝试访问模型的其他属性...\n",
      "模块结构:\n",
      "   1.  (HyenaModel)\n",
      "\n",
      "目标模式: ['module.decoder.layers.17.self_attention.linear_qkv']\n",
      "\n",
      "所有线性层 (0):\n",
      "\n",
      "找到的注意力相关层 (0):\n",
      "\n",
      "找到的线性层 (0):\n",
      "\n",
      "找到的QKV层 (0):\n",
      "⚠️  没有找到任何线性层！模型可能还没有完全初始化。\n",
      "这在 NeMo/Megatron 框架中是正常的，模型结构会在训练开始时初始化。\n",
      "LoRA 配置已保存，将在模型完全初始化后应用。\n",
      "总参数数量: 0\n",
      "可训练参数数量: 0\n",
      "⚠️  警告: 模型总参数数量为0，可能模型初始化有问题\n",
      "⚠️  警告: 没有可训练的参数，LoRA 可能没有正确应用\n",
      "LoRA 将在训练开始时自动应用\n",
      "已添加 LoRA 回调，将在训练开始时应用 LoRA\n",
      "启用 LoRA 微调...\n",
      "模型结构调试信息:\n",
      "--------------------------------------------------\n",
      "模型总共有 1 个模块\n",
      "尝试访问模型的其他属性...\n",
      "模块结构:\n",
      "   1.  (HyenaModel)\n",
      "\n",
      "目标模式: ['module.decoder.layers.17.self_attention.linear_qkv']\n",
      "\n",
      "所有线性层 (0):\n",
      "\n",
      "找到的注意力相关层 (0):\n",
      "\n",
      "找到的线性层 (0):\n",
      "\n",
      "找到的QKV层 (0):\n",
      "⚠️  没有找到任何线性层！模型可能还没有完全初始化。\n",
      "这在 NeMo/Megatron 框架中是正常的，模型结构会在训练开始时初始化。\n",
      "LoRA 配置已保存，将在模型完全初始化后应用。\n",
      "总参数数量: 0\n",
      "可训练参数数量: 0\n",
      "⚠️  警告: 模型总参数数量为0，可能模型初始化有问题\n",
      "⚠️  警告: 没有可训练的参数，LoRA 可能没有正确应用\n",
      "LoRA 将在训练开始时自动应用\n",
      "已添加 LoRA 回调，将在训练开始时应用 LoRA\n",
      "启用 LoRA 微调...\n",
      "模型结构调试信息:\n",
      "--------------------------------------------------\n",
      "模型总共有 1 个模块\n",
      "尝试访问模型的其他属性...\n",
      "模块结构:\n",
      "   1.  (HyenaModel)\n",
      "\n",
      "目标模式: ['module.decoder.layers.17.self_attention.linear_qkv']\n",
      "\n",
      "所有线性层 (0):\n",
      "\n",
      "找到的注意力相关层 (0):\n",
      "\n",
      "找到的线性层 (0):\n",
      "\n",
      "找到的QKV层 (0):\n",
      "⚠️  没有找到任何线性层！模型可能还没有完全初始化。\n",
      "这在 NeMo/Megatron 框架中是正常的，模型结构会在训练开始时初始化。\n",
      "LoRA 配置已保存，将在模型完全初始化后应用。\n",
      "总参数数量: 0\n",
      "可训练参数数量: 0\n",
      "⚠️  警告: 模型总参数数量为0，可能模型初始化有问题\n",
      "⚠️  警告: 没有可训练的参数，LoRA 可能没有正确应用\n",
      "LoRA 将在训练开始时自动应用\n",
      "已添加 LoRA 回调，将在训练开始时应用 LoRA\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[NeMo I 2025-06-02 08:04:28 utils:554] Building Evo2Dataset splits with sizes=[800000, 16080, 4] and config=GPTDatasetConfig(random_seed=1234, sequence_length=1, blend=None, blend_per_split=[(['/workspace/preprocessed_data/XTT22_train_byte-level_train'], [1.0]), (['/workspace/preprocessed_data/XTT22_train_byte-level_val'], [1.0]), (['/workspace/preprocessed_data/XTT22_train_byte-level_test'], [1.0])], split=None, split_matrix=None, num_dataset_builder_threads=1, path_to_cache=None, mmap_bin_files=True, mock=False, tokenizer=<nemo.collections.common.tokenizers.bytelevel_tokenizers.ByteLevelTokenizer object at 0x7ba4e5733a10>, mid_level_dataset_surplus=0.005, reset_position_ids=False, reset_attention_mask=False, eod_mask_loss=False, create_attention_mask=False, drop_last_partial_validation_sequence=True, add_extra_token_to_sequence=True, object_storage_cache_path=None)\n",
      "[NeMo I 2025-06-02 08:04:28 utils:554] Load the _IndexReader from /workspace/preprocessed_data/XTT22_train_byte-level_train.idx\n",
      "[NeMo I 2025-06-02 08:04:28 utils:554] \tExtract the sequence lengths\n",
      "[NeMo I 2025-06-02 08:04:28 utils:554] \tExtract the sequence pointers\n",
      "[NeMo I 2025-06-02 08:04:28 utils:554] \tExtract the document indices\n",
      "[NeMo I 2025-06-02 08:04:28 utils:554] > total number of sequences: 10896\n",
      "[NeMo I 2025-06-02 08:04:28 utils:554] > total number of documents: 10896\n",
      "[NeMo I 2025-06-02 08:04:28 utils:554] Build and save the Evo2Dataset train indices\n",
      "[rank1]:[E602 08:14:28.467109986 ProcessGroupNCCL.cpp:633] [Rank 1] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=4, OpType=ALLREDUCE, NumelIn=1, NumelOut=1, Timeout(ms)=600000) ran for 600067 milliseconds before timing out.\n",
      "[rank1]:[E602 08:14:28.467336559 ProcessGroupNCCL.cpp:2269] [PG ID 0 PG GUID 0(default_pg) Rank 1]  failure detected by watchdog at work sequence id: 4 PG status: last enqueued work: 4, last completed work: 3\n",
      "[rank1]:[E602 08:14:28.467373937 ProcessGroupNCCL.cpp:671] Stack trace of the failed collective not found, potentially because FlightRecorder is disabled. You can enable it by setting TORCH_NCCL_TRACE_BUFFER_SIZE to a non-zero value.\n",
      "[rank1]:[E602 08:14:28.467469122 ProcessGroupNCCL.cpp:2104] [PG ID 0 PG GUID 0(default_pg) Rank 1] First PG on this rank to signal dumping.\n",
      "[rank2]:[E602 08:14:28.467968268 ProcessGroupNCCL.cpp:633] [Rank 2] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=4, OpType=ALLREDUCE, NumelIn=1, NumelOut=1, Timeout(ms)=600000) ran for 600068 milliseconds before timing out.\n",
      "[rank2]:[E602 08:14:28.468186538 ProcessGroupNCCL.cpp:2269] [PG ID 0 PG GUID 0(default_pg) Rank 2]  failure detected by watchdog at work sequence id: 4 PG status: last enqueued work: 4, last completed work: 3\n",
      "[rank2]:[E602 08:14:28.468222725 ProcessGroupNCCL.cpp:671] Stack trace of the failed collective not found, potentially because FlightRecorder is disabled. You can enable it by setting TORCH_NCCL_TRACE_BUFFER_SIZE to a non-zero value.\n",
      "[rank2]:[E602 08:14:28.468327924 ProcessGroupNCCL.cpp:2104] [PG ID 0 PG GUID 0(default_pg) Rank 2] First PG on this rank to signal dumping.\n",
      "[rank3]:[E602 08:14:28.469594768 ProcessGroupNCCL.cpp:633] [Rank 3] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=4, OpType=ALLREDUCE, NumelIn=1, NumelOut=1, Timeout(ms)=600000) ran for 600069 milliseconds before timing out.\n",
      "[rank3]:[E602 08:14:28.469811544 ProcessGroupNCCL.cpp:2269] [PG ID 0 PG GUID 0(default_pg) Rank 3]  failure detected by watchdog at work sequence id: 4 PG status: last enqueued work: 4, last completed work: 3\n",
      "[rank3]:[E602 08:14:28.469847925 ProcessGroupNCCL.cpp:671] Stack trace of the failed collective not found, potentially because FlightRecorder is disabled. You can enable it by setting TORCH_NCCL_TRACE_BUFFER_SIZE to a non-zero value.\n",
      "[rank3]:[E602 08:14:28.469958784 ProcessGroupNCCL.cpp:2104] [PG ID 0 PG GUID 0(default_pg) Rank 3] First PG on this rank to signal dumping.\n",
      "[rank2]:[E602 08:14:29.198545183 ProcessGroupNCCL.cpp:1744] [PG ID 0 PG GUID 0(default_pg) Rank 2] Received a dump signal due to a collective timeout from this local rank and we will try our best to dump the debug info. Last enqueued NCCL work: 4, last completed NCCL work: 3.This is most likely caused by incorrect usages of collectives, e.g., wrong sizes used across ranks, the order of collectives is not same for all ranks or the scheduled collective, for some reason, didn't run. Additionally, this can be caused by GIL deadlock or other reasons such as network errors or bugs in the communications library (e.g. NCCL), etc. \n",
      "[rank3]:[E602 08:14:29.198583350 ProcessGroupNCCL.cpp:1744] [PG ID 0 PG GUID 0(default_pg) Rank 3] Received a dump signal due to a collective timeout from this local rank and we will try our best to dump the debug info. Last enqueued NCCL work: 4, last completed NCCL work: 3.This is most likely caused by incorrect usages of collectives, e.g., wrong sizes used across ranks, the order of collectives is not same for all ranks or the scheduled collective, for some reason, didn't run. Additionally, this can be caused by GIL deadlock or other reasons such as network errors or bugs in the communications library (e.g. NCCL), etc. \n",
      "[rank1]:[E602 08:14:29.198645126 ProcessGroupNCCL.cpp:1744] [PG ID 0 PG GUID 0(default_pg) Rank 1] Received a dump signal due to a collective timeout from this local rank and we will try our best to dump the debug info. Last enqueued NCCL work: 4, last completed NCCL work: 3.This is most likely caused by incorrect usages of collectives, e.g., wrong sizes used across ranks, the order of collectives is not same for all ranks or the scheduled collective, for some reason, didn't run. Additionally, this can be caused by GIL deadlock or other reasons such as network errors or bugs in the communications library (e.g. NCCL), etc. \n",
      "[rank0]:[E602 08:14:29.198703909 ProcessGroupNCCL.cpp:1683] [PG ID 0 PG GUID 0(default_pg) Rank 0] Observed flight recorder dump signal from another rank via TCPStore.\n",
      "[rank0]:[E602 08:14:29.198834444 ProcessGroupNCCL.cpp:1744] [PG ID 0 PG GUID 0(default_pg) Rank 0] Received a dump signal due to a collective timeout from  rank 3 and we will try our best to dump the debug info. Last enqueued NCCL work: 3, last completed NCCL work: 3.This is most likely caused by incorrect usages of collectives, e.g., wrong sizes used across ranks, the order of collectives is not same for all ranks or the scheduled collective, for some reason, didn't run. Additionally, this can be caused by GIL deadlock or other reasons such as network errors or bugs in the communications library (e.g. NCCL), etc. \n",
      "[rank1]:[E602 08:14:29.198921508 ProcessGroupNCCL.cpp:1534] [PG ID 0 PG GUID 0(default_pg) Rank 1] ProcessGroupNCCL preparing to dump debug info. Include stack trace: 1\n",
      "[rank3]:[E602 08:14:29.198970028 ProcessGroupNCCL.cpp:1534] [PG ID 0 PG GUID 0(default_pg) Rank 3] ProcessGroupNCCL preparing to dump debug info. Include stack trace: 1\n",
      "[rank2]:[E602 08:14:29.199073457 ProcessGroupNCCL.cpp:1534] [PG ID 0 PG GUID 0(default_pg) Rank 2] ProcessGroupNCCL preparing to dump debug info. Include stack trace: 1\n",
      "[rank0]:[E602 08:14:29.199111561 ProcessGroupNCCL.cpp:1534] [PG ID 0 PG GUID 0(default_pg) Rank 0] ProcessGroupNCCL preparing to dump debug info. Include stack trace: 1\n",
      "[rank3]:[E602 08:14:29.199359188 ProcessGroupNCCL.cpp:685] [Rank 3] Some NCCL operations have failed or timed out. Due to the asynchronous nature of CUDA kernels, subsequent GPU operations might run on corrupted/incomplete data.\n",
      "[rank3]:[E602 08:14:29.199379883 ProcessGroupNCCL.cpp:699] [Rank 3] To avoid data inconsistency, we are taking the entire process down.\n",
      "[rank1]:[E602 08:14:29.199583996 ProcessGroupNCCL.cpp:685] [Rank 1] Some NCCL operations have failed or timed out. Due to the asynchronous nature of CUDA kernels, subsequent GPU operations might run on corrupted/incomplete data.\n",
      "[rank1]:[E602 08:14:29.199616765 ProcessGroupNCCL.cpp:699] [Rank 1] To avoid data inconsistency, we are taking the entire process down.\n",
      "[rank2]:[E602 08:14:29.199774435 ProcessGroupNCCL.cpp:685] [Rank 2] Some NCCL operations have failed or timed out. Due to the asynchronous nature of CUDA kernels, subsequent GPU operations might run on corrupted/incomplete data.\n",
      "[rank2]:[E602 08:14:29.199797902 ProcessGroupNCCL.cpp:699] [Rank 2] To avoid data inconsistency, we are taking the entire process down.\n",
      "[rank3]:[E602 08:14:29.200876764 ProcessGroupNCCL.cpp:1897] [PG ID 0 PG GUID 0(default_pg) Rank 3] Process group watchdog thread terminated with exception: [Rank 3] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=4, OpType=ALLREDUCE, NumelIn=1, NumelOut=1, Timeout(ms)=600000) ran for 600069 milliseconds before timing out.\n",
      "Exception raised from checkTimeout at /opt/pytorch/pytorch/torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:636 (most recent call first):\n",
      "frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x98 (0x744889b315e8 in /usr/local/lib/python3.12/dist-packages/torch/lib/libc10.so)\n",
      "frame #1: c10d::ProcessGroupNCCL::WorkNCCL::checkTimeout(std::optional<std::chrono::duration<long, std::ratio<1l, 1000l> > >) + 0x23d (0x74488a8d340d in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)\n",
      "frame #2: c10d::ProcessGroupNCCL::watchdogHandler() + 0xc08 (0x74488a8d5118 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)\n",
      "frame #3: c10d::ProcessGroupNCCL::ncclCommWatchdog() + 0x14d (0x74488a8d5ffd in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)\n",
      "frame #4: <unknown function> + 0xecdb4 (0x74486fbcddb4 in /usr/lib/x86_64-linux-gnu/libstdc++.so.6)\n",
      "frame #5: <unknown function> + 0x9caa4 (0x7448fa2f5aa4 in /usr/lib/x86_64-linux-gnu/libc.so.6)\n",
      "frame #6: <unknown function> + 0x129c3c (0x7448fa382c3c in /usr/lib/x86_64-linux-gnu/libc.so.6)\n",
      "\n",
      "terminate called after throwing an instance of 'c10::DistBackendError'\n",
      "[rank2]:[E602 08:14:29.201210404 ProcessGroupNCCL.cpp:1897] [PG ID 0 PG GUID 0(default_pg) Rank 2] Process group watchdog thread terminated with exception: [Rank 2] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=4, OpType=ALLREDUCE, NumelIn=1, NumelOut=1, Timeout(ms)=600000) ran for 600068 milliseconds before timing out.\n",
      "Exception raised from checkTimeout at /opt/pytorch/pytorch/torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:636 (most recent call first):\n",
      "frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x98 (0x7706ad36e5e8 in /usr/local/lib/python3.12/dist-packages/torch/lib/libc10.so)\n",
      "frame #1: c10d::ProcessGroupNCCL::WorkNCCL::checkTimeout(std::optional<std::chrono::duration<long, std::ratio<1l, 1000l> > >) + 0x23d (0x7706ae1b840d in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)\n",
      "frame #2: c10d::ProcessGroupNCCL::watchdogHandler() + 0xc08 (0x7706ae1ba118 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)\n",
      "frame #3: c10d::ProcessGroupNCCL::ncclCommWatchdog() + 0x14d (0x7706ae1baffd in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)\n",
      "frame #4: <unknown function> + 0xecdb4 (0x7706933cddb4 in /usr/lib/x86_64-linux-gnu/libstdc++.so.6)\n",
      "frame #5: <unknown function> + 0x9caa4 (0x77071dc15aa4 in /usr/lib/x86_64-linux-gnu/libc.so.6)\n",
      "frame #6: <unknown function> + 0x129c3c (0x77071dca2c3c in /usr/lib/x86_64-linux-gnu/libc.so.6)\n",
      "\n",
      "terminate called after throwing an instance of 'c10::DistBackendError'\n",
      "  what():  [PG ID 0 PG GUID 0(default_pg) Rank 3] Process group watchdog thread terminated with exception: [Rank 3] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=4, OpType=ALLREDUCE, NumelIn=1, NumelOut=1, Timeout(ms)=600000) ran for 600069 milliseconds before timing out.\n",
      "Exception raised from checkTimeout at /opt/pytorch/pytorch/torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:636 (most recent call first):\n",
      "frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x98 (0x744889b315e8 in /usr/local/lib/python3.12/dist-packages/torch/lib/libc10.so)\n",
      "frame #1: c10d::ProcessGroupNCCL::WorkNCCL::checkTimeout(std::optional<std::chrono::duration<long, std::ratio<1l, 1000l> > >) + 0x23d (0x74488a8d340d in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)\n",
      "frame #2: c10d::ProcessGroupNCCL::watchdogHandler() + 0xc08 (0x74488a8d5118 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)\n",
      "frame #3: c10d::ProcessGroupNCCL::ncclCommWatchdog() + 0x14d (0x74488a8d5ffd in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)\n",
      "frame #4: <unknown function> + 0xecdb4 (0x74486fbcddb4 in /usr/lib/x86_64-linux-gnu/libstdc++.so.6)\n",
      "frame #5: <unknown function> + 0x9caa4 (0x7448fa2f5aa4 in /usr/lib/x86_64-linux-gnu/libc.so.6)\n",
      "frame #6: <unknown function> + 0x129c3c (0x7448fa382c3c in /usr/lib/x86_64-linux-gnu/libc.so.6)\n",
      "\n",
      "Exception raised from ncclCommWatchdog at /opt/pytorch/pytorch/torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:1903 (most recent call first):\n",
      "frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x98 (0x744889b315e8 in /usr/local/lib/python3.12/dist-packages/torch/lib/libc10.so)\n",
      "frame #1: <unknown function> + 0xcff25e (0x74488a8a525e in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)\n",
      "frame #2: <unknown function> + 0x916523 (0x74488a4bc523 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)\n",
      "frame #3: <unknown function> + 0xecdb4 (0x74486fbcddb4 in /usr/lib/x86_64-linux-gnu/libstdc++.so.6)\n",
      "frame #4: <unknown function> + 0x9caa4 (0x7448fa2f5aa4 in /usr/lib/x86_64-linux-gnu/libc.so.6)\n",
      "frame #5: <unknown function> + 0x129c3c (0x7448fa382c3c in /usr/lib/x86_64-linux-gnu/libc.so.6)\n",
      "\n",
      "  what():  [PG ID 0 PG GUID 0(default_pg) Rank 2] Process group watchdog thread terminated with exception: [Rank 2] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=4, OpType=ALLREDUCE, NumelIn=1, NumelOut=1, Timeout(ms)=600000) ran for 600068 milliseconds before timing out.\n",
      "Exception raised from checkTimeout at /opt/pytorch/pytorch/torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:636 (most recent call first):\n",
      "frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x98 (0x7706ad36e5e8 in /usr/local/lib/python3.12/dist-packages/torch/lib/libc10.so)\n",
      "frame #1: c10d::ProcessGroupNCCL::WorkNCCL::checkTimeout(std::optional<std::chrono::duration<long, std::ratio<1l, 1000l> > >) + 0x23d (0x7706ae1b840d in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)\n",
      "frame #2: c10d::ProcessGroupNCCL::watchdogHandler() + 0xc08 (0x7706ae1ba118 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)\n",
      "frame #3: c10d::ProcessGroupNCCL::ncclCommWatchdog() + 0x14d (0x7706ae1baffd in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)\n",
      "frame #4: <unknown function> + 0xecdb4 (0x7706933cddb4 in /usr/lib/x86_64-linux-gnu/libstdc++.so.6)\n",
      "frame #5: <unknown function> + 0x9caa4 (0x77071dc15aa4 in /usr/lib/x86_64-linux-gnu/libc.so.6)\n",
      "frame #6: <unknown function> + 0x129c3c (0x77071dca2c3c in /usr/lib/x86_64-linux-gnu/libc.so.6)\n",
      "\n",
      "Exception raised from ncclCommWatchdog at /opt/pytorch/pytorch/torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:1903 (most recent call first):\n",
      "frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x98 (0x7706ad36e5e8 in /usr/local/lib/python3.12/dist-packages/torch/lib/libc10.so)\n",
      "frame #1: <unknown function> + 0xcff25e (0x7706ae18a25e in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)\n",
      "frame #2: <unknown function> + 0x916523 (0x7706adda1523 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)\n",
      "frame #3: <unknown function> + 0xecdb4 (0x7706933cddb4 in /usr/lib/x86_64-linux-gnu/libstdc++.so.6)\n",
      "frame #4: <unknown function> + 0x9caa4 (0x77071dc15aa4 in /usr/lib/x86_64-linux-gnu/libc.so.6)\n",
      "frame #5: <unknown function> + 0x129c3c (0x77071dca2c3c in /usr/lib/x86_64-linux-gnu/libc.so.6)\n",
      "[rank1]:[E602 08:14:29.202195652 ProcessGroupNCCL.cpp:1897] [PG ID 0 PG GUID 0(default_pg) Rank 1] Process group watchdog thread terminated with exception: [Rank 1] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=4, OpType=ALLREDUCE, NumelIn=1, NumelOut=1, Timeout(ms)=600000) ran for 600067 milliseconds before timing out.\n",
      "Exception raised from checkTimeout at /opt/pytorch/pytorch/torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:636 (most recent call first):\n",
      "frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x98 (0x74d0584165e8 in /usr/local/lib/python3.12/dist-packages/torch/lib/libc10.so)\n",
      "frame #1: c10d::ProcessGroupNCCL::WorkNCCL::checkTimeout(std::optional<std::chrono::duration<long, std::ratio<1l, 1000l> > >) + 0x23d (0x74d0591b840d in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)\n",
      "frame #2: c10d::ProcessGroupNCCL::watchdogHandler() + 0xc08 (0x74d0591ba118 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)\n",
      "frame #3: c10d::ProcessGroupNCCL::ncclCommWatchdog() + 0x14d (0x74d0591baffd in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)\n",
      "frame #4: <unknown function> + 0xecdb4 (0x74d03e3cddb4 in /usr/lib/x86_64-linux-gnu/libstdc++.so.6)\n",
      "frame #5: <unknown function> + 0x9caa4 (0x74d0c8c45aa4 in /usr/lib/x86_64-linux-gnu/libc.so.6)\n",
      "frame #6: <unknown function> + 0x129c3c (0x74d0c8cd2c3c in /usr/lib/x86_64-linux-gnu/libc.so.6)\n",
      "\n",
      "\n",
      "terminate called after throwing an instance of 'c10::DistBackendError'\n",
      "  what():  [PG ID 0 PG GUID 0(default_pg) Rank 1] Process group watchdog thread terminated with exception: [Rank 1] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=4, OpType=ALLREDUCE, NumelIn=1, NumelOut=1, Timeout(ms)=600000) ran for 600067 milliseconds before timing out.\n",
      "Exception raised from checkTimeout at /opt/pytorch/pytorch/torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:636 (most recent call first):\n",
      "frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x98 (0x74d0584165e8 in /usr/local/lib/python3.12/dist-packages/torch/lib/libc10.so)\n",
      "frame #1: c10d::ProcessGroupNCCL::WorkNCCL::checkTimeout(std::optional<std::chrono::duration<long, std::ratio<1l, 1000l> > >) + 0x23d (0x74d0591b840d in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)\n",
      "frame #2: c10d::ProcessGroupNCCL::watchdogHandler() + 0xc08 (0x74d0591ba118 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)\n",
      "frame #3: c10d::ProcessGroupNCCL::ncclCommWatchdog() + 0x14d (0x74d0591baffd in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)\n",
      "frame #4: <unknown function> + 0xecdb4 (0x74d03e3cddb4 in /usr/lib/x86_64-linux-gnu/libstdc++.so.6)\n",
      "frame #5: <unknown function> + 0x9caa4 (0x74d0c8c45aa4 in /usr/lib/x86_64-linux-gnu/libc.so.6)\n",
      "frame #6: <unknown function> + 0x129c3c (0x74d0c8cd2c3c in /usr/lib/x86_64-linux-gnu/libc.so.6)\n",
      "\n",
      "Exception raised from ncclCommWatchdog at /opt/pytorch/pytorch/torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:1903 (most recent call first):\n",
      "frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x98 (0x74d0584165e8 in /usr/local/lib/python3.12/dist-packages/torch/lib/libc10.so)\n",
      "frame #1: <unknown function> + 0xcff25e (0x74d05918a25e in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)\n",
      "frame #2: <unknown function> + 0x916523 (0x74d058da1523 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)\n",
      "frame #3: <unknown function> + 0xecdb4 (0x74d03e3cddb4 in /usr/lib/x86_64-linux-gnu/libstdc++.so.6)\n",
      "frame #4: <unknown function> + 0x9caa4 (0x74d0c8c45aa4 in /usr/lib/x86_64-linux-gnu/libc.so.6)\n",
      "frame #5: <unknown function> + 0x129c3c (0x74d0c8cd2c3c in /usr/lib/x86_64-linux-gnu/libc.so.6)\n",
      "\n",
      "[rank0]:[E602 08:14:29.499809177 ProcessGroupNCCL.cpp:1807] [PG ID 0 PG GUID 0(default_pg) Rank 0] Could not acquire GIL within 300 ms on exit, possible GIL induced hang\n",
      "[rank: 1] Child process with PID 5844 terminated with code -6. Forcefully terminating all other processes to avoid zombies 🧟\n"
     ]
    }
   ],
   "source": [
    "\n",
    "!train_evo2 \\\n",
    "    -d training_data_config.yaml \\\n",
    "    --dataset-dir {preprocessed_data} \\\n",
    "    --model-size 7b \\\n",
    "    --devices 4 \\\n",
    "    --num-nodes 1 \\\n",
    "    --seq-length 1 \\\n",
    "    --micro-batch-size 1 \\\n",
    "    --lr 0.0001 \\\n",
    "    --warmup-steps 5 \\\n",
    "    --max-steps 200000 \\\n",
    "    --ckpt-dir nemo2_evo2_7b \\\n",
    "    --clip-grad 1 \\\n",
    "    --wd 0.01 \\\n",
    "    --activation-checkpoint-recompute-num-layers 1 \\\n",
    "    --val-check-interval 1000 \\\n",
    "    --ckpt-async-save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "adacfca1-de37-4ece-919b-c720dc285ce3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔧 配置NCCL超时和优化参数...\n",
      "🔧 设置PyTorch分布式超时: 7200秒\n",
      "Could not find the bitsandbytes CUDA binary at PosixPath('/usr/local/lib/python3.12/dist-packages/bitsandbytes/libbitsandbytes_cuda129.so')\n",
      "The installed version of bitsandbytes was compiled without GPU support. 8-bit optimizers, 8-bit multiplication, and GPU quantization are unavailable.\n",
      "[NeMo I 2025-06-05 11:05:02 nemo_logging:393] Using byte-level tokenization\n",
      "启用 LoRA 微调...\n",
      "模型结构调试信息:\n",
      "--------------------------------------------------\n",
      "模型总共有 1 个模块\n",
      "尝试访问模型的其他属性...\n",
      "模块结构:\n",
      "   1.  (HyenaModel)\n",
      "\n",
      "目标模式: ['module.decoder.layers.17.self_attention.linear_qkv']\n",
      "\n",
      "所有线性层 (0):\n",
      "\n",
      "找到的注意力相关层 (0):\n",
      "\n",
      "找到的线性层 (0):\n",
      "\n",
      "找到的QKV层 (0):\n",
      "⚠️  没有找到任何线性层！模型可能还没有完全初始化。\n",
      "这在 NeMo/Megatron 框架中是正常的，模型结构会在训练开始时初始化。\n",
      "LoRA 配置已保存，将在模型完全初始化后应用。\n",
      "总参数数量: 0\n",
      "可训练参数数量: 0\n",
      "⚠️  警告: 模型总参数数量为0，可能模型初始化有问题\n",
      "⚠️  警告: 没有可训练的参数，LoRA 可能没有正确应用\n",
      "LoRA 将在训练开始时自动应用\n",
      "已添加 LoRA 回调，将在训练开始时应用 LoRA\n",
      "[NeMo W 2025-06-05 11:05:02 nemo_logging:405] WandB is currently turned off.\n",
      "[NeMo W 2025-06-05 11:05:02 nemo_logging:405] User-set tensorboard is currently turned off. Internally one may still be set by NeMo2.\n",
      "Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "[NeMo I 2025-06-05 11:05:02 nemo_logging:393] Experiments will be logged at results/evo2/dev\n",
      "[NeMo W 2025-06-05 11:05:02 nemo_logging:405] There were no checkpoints found in checkpoint_dir or no checkpoint folder at checkpoint_dir :results/evo2/checkpoints. Training from scratch.\n",
      "[NeMo I 2025-06-05 11:05:02 nemo_logging:393] Fixing mis-match between ddp-config & mcore-optimizer config\n",
      "[NeMo I 2025-06-05 11:05:02 nemo_logging:393] Rank 0 has data parallel group : [0, 1]\n",
      "[NeMo I 2025-06-05 11:05:02 nemo_logging:393] Rank 0 has combined group of data parallel and context parallel : [0, 1]\n",
      "[NeMo I 2025-06-05 11:05:02 nemo_logging:393] All data parallel group ranks with context parallel combined: [[0, 1]]\n",
      "[NeMo I 2025-06-05 11:05:02 nemo_logging:393] Ranks 0 has data parallel rank: 0\n",
      "[NeMo I 2025-06-05 11:05:02 nemo_logging:393] Rank 0 has context parallel group: [0]\n",
      "[NeMo I 2025-06-05 11:05:02 nemo_logging:393] All context parallel group ranks: [[0], [1]]\n",
      "[NeMo I 2025-06-05 11:05:02 nemo_logging:393] Ranks 0 has context parallel rank: 0\n",
      "[NeMo I 2025-06-05 11:05:02 nemo_logging:393] Rank 0 has model parallel group: [0]\n",
      "[NeMo I 2025-06-05 11:05:02 nemo_logging:393] All model parallel group ranks: [[0], [1]]\n",
      "[NeMo I 2025-06-05 11:05:02 nemo_logging:393] Rank 0 has tensor model parallel group: [0]\n",
      "[NeMo I 2025-06-05 11:05:02 nemo_logging:393] All tensor model parallel group ranks: [[0], [1]]\n",
      "[NeMo I 2025-06-05 11:05:02 nemo_logging:393] Rank 0 has tensor model parallel rank: 0\n",
      "[NeMo I 2025-06-05 11:05:02 nemo_logging:393] Rank 0 has pipeline model parallel group: [0]\n",
      "[NeMo I 2025-06-05 11:05:02 nemo_logging:393] Rank 0 has embedding group: [0]\n",
      "[NeMo I 2025-06-05 11:05:02 nemo_logging:393] All pipeline model parallel group ranks: [[0], [1]]\n",
      "[NeMo I 2025-06-05 11:05:02 nemo_logging:393] Rank 0 has pipeline model parallel rank 0\n",
      "[NeMo I 2025-06-05 11:05:02 nemo_logging:393] All embedding group ranks: [[0], [1]]\n",
      "[NeMo I 2025-06-05 11:05:02 nemo_logging:393] Rank 0 has embedding rank: 0\n",
      "🔧 设置PyTorch分布式超时: 7200秒\n",
      "Could not find the bitsandbytes CUDA binary at PosixPath('/usr/local/lib/python3.12/dist-packages/bitsandbytes/libbitsandbytes_cuda129.so')\n",
      "The installed version of bitsandbytes was compiled without GPU support. 8-bit optimizers, 8-bit multiplication, and GPU quantization are unavailable.\n",
      "启用 LoRA 微调...\n",
      "模型结构调试信息:\n",
      "--------------------------------------------------\n",
      "模型总共有 1 个模块\n",
      "尝试访问模型的其他属性...\n",
      "模块结构:\n",
      "   1.  (HyenaModel)\n",
      "\n",
      "目标模式: ['module.decoder.layers.17.self_attention.linear_qkv']\n",
      "\n",
      "所有线性层 (0):\n",
      "\n",
      "找到的注意力相关层 (0):\n",
      "\n",
      "找到的线性层 (0):\n",
      "\n",
      "找到的QKV层 (0):\n",
      "⚠️  没有找到任何线性层！模型可能还没有完全初始化。\n",
      "这在 NeMo/Megatron 框架中是正常的，模型结构会在训练开始时初始化。\n",
      "LoRA 配置已保存，将在模型完全初始化后应用。\n",
      "总参数数量: 0\n",
      "可训练参数数量: 0\n",
      "⚠️  警告: 模型总参数数量为0，可能模型初始化有问题\n",
      "⚠️  警告: 没有可训练的参数，LoRA 可能没有正确应用\n",
      "LoRA 将在训练开始时自动应用\n",
      "已添加 LoRA 回调，将在训练开始时应用 LoRA\n",
      "[W605 11:05:16.388984675 Utils.hpp:166] Warning: Environment variable NCCL_BLOCKING_WAIT is deprecated; use TORCH_NCCL_BLOCKING_WAIT instead (function operator())\n",
      "[W605 11:05:16.389019767 Utils.hpp:137] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function operator())\n",
      "[W605 11:05:16.391433470 Utils.hpp:166] Warning: Environment variable NCCL_BLOCKING_WAIT is deprecated; use TORCH_NCCL_BLOCKING_WAIT instead (function operator())\n",
      "[W605 11:05:16.391480455 Utils.hpp:137] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function operator())\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 2 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "ubuntu:1737:1737 [0] NCCL INFO Bootstrap: Using eth0:172.21.72.20<0>\n",
      "ubuntu:1737:1737 [0] NCCL INFO cudaDriverVersion 12090\n",
      "ubuntu:1737:1737 [0] NCCL INFO NCCL version 2.26.3+cuda12.9\n",
      "ubuntu:1737:1737 [0] NCCL INFO Comm config Blocking set to 1\n",
      "ubuntu:1844:1844 [1] NCCL INFO cudaDriverVersion 12090\n",
      "ubuntu:1844:1844 [1] NCCL INFO Bootstrap: Using eth0:172.21.72.20<0>\n",
      "ubuntu:1844:1844 [1] NCCL INFO NCCL version 2.26.3+cuda12.9\n",
      "ubuntu:1844:1844 [1] NCCL INFO Comm config Blocking set to 1\n",
      "ubuntu:1737:1960 [0] NCCL INFO NET/Plugin: Failed to find ncclNetPlugin_v10 symbol.\n",
      "ubuntu:1737:1960 [0] NCCL INFO NET/Plugin: Loaded net plugin NCCL RDMA Plugin v9 (v9)\n",
      "ubuntu:1737:1960 [0] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v10 symbol.\n",
      "ubuntu:1737:1960 [0] NCCL INFO NET/Plugin: Loaded collnet plugin SHARP (v9)\n",
      "ubuntu:1737:1960 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so\n",
      "ubuntu:1737:1960 [0] NCCL INFO P2P plugin v9 IBext_v9\n",
      "ubuntu:1737:1960 [0] NCCL INFO NET/IB : No device found.\n",
      "ubuntu:1737:1960 [0] NCCL INFO NET/IB : Using [RO]; OOB eth0:172.21.72.20<0>\n",
      "ubuntu:1844:1961 [1] NCCL INFO NET/Plugin: Failed to find ncclNetPlugin_v10 symbol.\n",
      "ubuntu:1844:1961 [1] NCCL INFO NET/Plugin: Loaded net plugin NCCL RDMA Plugin v9 (v9)\n",
      "ubuntu:1844:1961 [1] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v10 symbol.\n",
      "ubuntu:1844:1961 [1] NCCL INFO NET/Plugin: Loaded collnet plugin SHARP (v9)\n",
      "ubuntu:1844:1961 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so\n",
      "ubuntu:1844:1961 [1] NCCL INFO P2P plugin v9 IBext_v9\n",
      "ubuntu:1737:1960 [0] NCCL INFO NET/IB : No device found.\n",
      "ubuntu:1737:1960 [0] NCCL INFO NET/IB : Using [RO]; OOB eth0:172.21.72.20<0>\n",
      "ubuntu:1844:1961 [1] NCCL INFO NET/IB : No device found.\n",
      "ubuntu:1844:1961 [1] NCCL INFO NET/IB : Using [RO]; OOB eth0:172.21.72.20<0>\n",
      "ubuntu:1737:1960 [0] NCCL INFO NET/Socket : Using [0]eth0:172.21.72.20<0> [1]eth1:172.25.58.75<0> [2]nodelocaldns:169.254.25.10<0> [3]vxlan.calico:10.233.112.0<0> [4]cali829ebf906e6:fe80::ecee:eeff:feee:eeee%cali829ebf906e6<0> [5]cali9ffd33e0038:fe80::ecee:eeff:feee:eeee%cali9ffd33e0038<0> [6]cali210c644397a:fe80::ecee:eeff:feee:eeee%cali210c644397a<0> [7]caliafd05346b22:fe80::ecee:eeff:feee:eeee%caliafd05346b22<0> [8]calicd149c44f0f:fe80::ecee:eeff:feee:eeee%calicd149c44f0f<0> [9]cali62597977d84:fe80::ecee:eeff:feee:eeee%cali62597977d84<0> [10]calidee47cce1bb:fe80::ecee:eeff:feee:eeee%calidee47cce1bb<0> [11]cali2ad9843228b:fe80::ecee:eeff:feee:eeee%cali2ad9843228b<0> [12]calicb98c4ca0f1:fe80::ecee:eeff:feee:eeee%calicb98c4ca0f1<0> [13]cali9c537539f6f:fe80::ecee:eeff:feee:eeee%cali9c537539f6f<0> [14]cali3dd684f6336:fe80::ecee:eeff:feee:eeee%cali3dd684f6336<0> [15]calid294f721236:fe80::ecee:eeff:feee:eeee%calid294f721236<0>\n",
      "ubuntu:1737:1960 [0] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. \n",
      "ubuntu:1737:1960 [0] NCCL INFO Using network Socket\n",
      "ubuntu:1844:1961 [1] NCCL INFO NET/IB : No device found.\n",
      "ubuntu:1844:1961 [1] NCCL INFO NET/IB : Using [RO]; OOB eth0:172.21.72.20<0>\n",
      "ubuntu:1844:1961 [1] NCCL INFO NET/Socket : Using [0]eth0:172.21.72.20<0> [1]eth1:172.25.58.75<0> [2]nodelocaldns:169.254.25.10<0> [3]vxlan.calico:10.233.112.0<0> [4]cali829ebf906e6:fe80::ecee:eeff:feee:eeee%cali829ebf906e6<0> [5]cali9ffd33e0038:fe80::ecee:eeff:feee:eeee%cali9ffd33e0038<0> [6]cali210c644397a:fe80::ecee:eeff:feee:eeee%cali210c644397a<0> [7]caliafd05346b22:fe80::ecee:eeff:feee:eeee%caliafd05346b22<0> [8]calicd149c44f0f:fe80::ecee:eeff:feee:eeee%calicd149c44f0f<0> [9]cali62597977d84:fe80::ecee:eeff:feee:eeee%cali62597977d84<0> [10]calidee47cce1bb:fe80::ecee:eeff:feee:eeee%calidee47cce1bb<0> [11]cali2ad9843228b:fe80::ecee:eeff:feee:eeee%cali2ad9843228b<0> [12]calicb98c4ca0f1:fe80::ecee:eeff:feee:eeee%calicb98c4ca0f1<0> [13]cali9c537539f6f:fe80::ecee:eeff:feee:eeee%cali9c537539f6f<0> [14]cali3dd684f6336:fe80::ecee:eeff:feee:eeee%cali3dd684f6336<0> [15]calid294f721236:fe80::ecee:eeff:feee:eeee%calid294f721236<0>\n",
      "ubuntu:1844:1961 [1] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. \n",
      "ubuntu:1844:1961 [1] NCCL INFO Using network Socket\n",
      "ubuntu:1737:1960 [0] NCCL INFO ncclCommInitRankConfig comm 0x4ec706c0 rank 0 nranks 2 cudaDev 0 nvmlDev 0 busId 27000 commId 0xd4224b61ec58348e - Init START\n",
      "ubuntu:1844:1961 [1] NCCL INFO ncclCommInitRankConfig comm 0x1ed0a2d0 rank 1 nranks 2 cudaDev 1 nvmlDev 1 busId 2a000 commId 0xd4224b61ec58348e - Init START\n",
      "ubuntu:1844:1961 [1] NCCL INFO RAS client listening socket at 127.0.0.1<28028>\n",
      "ubuntu:1737:1960 [0] NCCL INFO RAS client listening socket at 127.0.0.1<28028>\n",
      "ubuntu:1844:1961 [1] NCCL INFO Bootstrap timings total 0.003129 (create 0.000039, send 0.000183, recv 0.002409, ring 0.000042, delay 0.000001)\n",
      "ubuntu:1737:1960 [0] NCCL INFO Bootstrap timings total 0.020279 (create 0.000040, send 0.019629, recv 0.000228, ring 0.000051, delay 0.000001)\n",
      "ubuntu:1844:1961 [1] NCCL INFO Setting affinity for GPU 1 to ffffffff,00000000,ffffffff\n",
      "ubuntu:1737:1960 [0] NCCL INFO Setting affinity for GPU 0 to ffffffff,00000000,ffffffff\n",
      "ubuntu:1844:1961 [1] NCCL INFO comm 0x1ed0a2d0 rank 1 nRanks 2 nNodes 1 localRanks 2 localRank 1 MNNVL 0\n",
      "ubuntu:1737:1960 [0] NCCL INFO comm 0x4ec706c0 rank 0 nRanks 2 nNodes 1 localRanks 2 localRank 0 MNNVL 0\n",
      "ubuntu:1737:1960 [0] NCCL INFO Channel 00/24 : 0 1\n",
      "ubuntu:1737:1960 [0] NCCL INFO Channel 01/24 : 0 1\n",
      "ubuntu:1737:1960 [0] NCCL INFO Channel 02/24 : 0 1\n",
      "ubuntu:1737:1960 [0] NCCL INFO Channel 03/24 : 0 1\n",
      "ubuntu:1737:1960 [0] NCCL INFO Channel 04/24 : 0 1\n",
      "ubuntu:1844:1961 [1] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] -1/-1/-1->1->0 [2] -1/-1/-1->1->0 [3] -1/-1/-1->1->0 [4] -1/-1/-1->1->0 [5] -1/-1/-1->1->0 [6] 0/-1/-1->1->-1 [7] 0/-1/-1->1->-1 [8] 0/-1/-1->1->-1 [9] 0/-1/-1->1->-1 [10] 0/-1/-1->1->-1 [11] 0/-1/-1->1->-1 [12] -1/-1/-1->1->0 [13] -1/-1/-1->1->0 [14] -1/-1/-1->1->0 [15] -1/-1/-1->1->0 [16] -1/-1/-1->1->0 [17] -1/-1/-1->1->0 [18] 0/-1/-1->1->-1 [19] 0/-1/-1->1->-1 [20] 0/-1/-1->1->-1 [21] 0/-1/-1->1->-1 [22] 0/-1/-1->1->-1 [23] 0/-1/-1->1->-1\n",
      "ubuntu:1737:1960 [0] NCCL INFO Channel 05/24 : 0 1\n",
      "ubuntu:1737:1960 [0] NCCL INFO Channel 06/24 : 0 1\n",
      "ubuntu:1844:1961 [1] NCCL INFO NCCL_BUFFSIZE set by environment to 8388608.\n",
      "ubuntu:1737:1960 [0] NCCL INFO Channel 07/24 : 0 1\n",
      "ubuntu:1844:1961 [1] NCCL INFO P2P Chunksize set to 524288\n",
      "ubuntu:1737:1960 [0] NCCL INFO Channel 08/24 : 0 1\n",
      "ubuntu:1737:1960 [0] NCCL INFO Channel 09/24 : 0 1\n",
      "ubuntu:1737:1960 [0] NCCL INFO Channel 10/24 : 0 1\n",
      "ubuntu:1737:1960 [0] NCCL INFO Channel 11/24 : 0 1\n",
      "ubuntu:1737:1960 [0] NCCL INFO Channel 12/24 : 0 1\n",
      "ubuntu:1737:1960 [0] NCCL INFO Channel 13/24 : 0 1\n",
      "ubuntu:1737:1960 [0] NCCL INFO Channel 14/24 : 0 1\n",
      "ubuntu:1737:1960 [0] NCCL INFO Channel 15/24 : 0 1\n",
      "ubuntu:1737:1960 [0] NCCL INFO Channel 16/24 : 0 1\n",
      "ubuntu:1737:1960 [0] NCCL INFO Channel 17/24 : 0 1\n",
      "ubuntu:1737:1960 [0] NCCL INFO Channel 18/24 : 0 1\n",
      "ubuntu:1737:1960 [0] NCCL INFO Channel 19/24 : 0 1\n",
      "ubuntu:1737:1960 [0] NCCL INFO Channel 20/24 : 0 1\n",
      "ubuntu:1737:1960 [0] NCCL INFO Channel 21/24 : 0 1\n",
      "ubuntu:1737:1960 [0] NCCL INFO Channel 22/24 : 0 1\n",
      "ubuntu:1737:1960 [0] NCCL INFO Channel 23/24 : 0 1\n",
      "ubuntu:1737:1960 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] 1/-1/-1->0->-1 [2] 1/-1/-1->0->-1 [3] 1/-1/-1->0->-1 [4] 1/-1/-1->0->-1 [5] 1/-1/-1->0->-1 [6] -1/-1/-1->0->1 [7] -1/-1/-1->0->1 [8] -1/-1/-1->0->1 [9] -1/-1/-1->0->1 [10] -1/-1/-1->0->1 [11] -1/-1/-1->0->1 [12] 1/-1/-1->0->-1 [13] 1/-1/-1->0->-1 [14] 1/-1/-1->0->-1 [15] 1/-1/-1->0->-1 [16] 1/-1/-1->0->-1 [17] 1/-1/-1->0->-1 [18] -1/-1/-1->0->1 [19] -1/-1/-1->0->1 [20] -1/-1/-1->0->1 [21] -1/-1/-1->0->1 [22] -1/-1/-1->0->1 [23] -1/-1/-1->0->1\n",
      "ubuntu:1737:1960 [0] NCCL INFO NCCL_BUFFSIZE set by environment to 8388608.\n",
      "ubuntu:1737:1960 [0] NCCL INFO P2P Chunksize set to 524288\n",
      "ubuntu:1737:1960 [0] NCCL INFO Check P2P Type intraNodeP2pSupport 1 directMode 0\n",
      "ubuntu:1844:1964 [1] NCCL INFO [Proxy Service] Device 1 CPU core 75\n",
      "ubuntu:1737:1965 [0] NCCL INFO [Proxy Service] Device 0 CPU core 13\n",
      "ubuntu:1844:1967 [1] NCCL INFO [Proxy Service UDS] Device 1 CPU core 14\n",
      "ubuntu:1737:1966 [0] NCCL INFO [Proxy Service UDS] Device 0 CPU core 15\n",
      "ubuntu:1844:1961 [1] NCCL INFO NCCL_NTHREADS set by environment to 8.\n",
      "\n",
      "[2025-06-05 11:05:17] ubuntu:1844:1961 [1] graph/tuning.cc:19 NCCL WARN Invalid NCCL_NTHREADS 8 (must be a multiple of 32)\n",
      "\n",
      "[2025-06-05 11:05:17] ubuntu:1844:1961 [1] graph/tuning.cc:19 NCCL WARN Invalid NCCL_NTHREADS 8 (must be a multiple of 32)\n",
      "\n",
      "[2025-06-05 11:05:17] ubuntu:1844:1961 [1] graph/tuning.cc:19 NCCL WARN Invalid NCCL_NTHREADS 8 (must be a multiple of 32)\n",
      "ubuntu:1844:1961 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 512 | 512\n",
      "ubuntu:1737:1960 [0] NCCL INFO NCCL_NTHREADS set by environment to 8.\n",
      "ubuntu:1844:1961 [1] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 32 p2p channels per peer\n",
      "\n",
      "[2025-06-05 11:05:17] ubuntu:1737:1960 [0] graph/tuning.cc:19 NCCL WARN Invalid NCCL_NTHREADS 8 (must be a multiple of 32)\n",
      "\n",
      "[2025-06-05 11:05:17] ubuntu:1737:1960 [0] graph/tuning.cc:19 NCCL WARN Invalid NCCL_NTHREADS 8 (must be a multiple of 32)\n",
      "\n",
      "[2025-06-05 11:05:17] ubuntu:1737:1960 [0] graph/tuning.cc:19 NCCL WARN Invalid NCCL_NTHREADS 8 (must be a multiple of 32)\n",
      "ubuntu:1737:1960 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 512 | 512\n",
      "ubuntu:1737:1960 [0] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 32 p2p channels per peer\n",
      "ubuntu:1737:1960 [0] NCCL INFO CC Off, workFifoBytes 1048576\n",
      "ubuntu:1844:1961 [1] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.\n",
      "ubuntu:1737:1960 [0] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.\n",
      "ubuntu:1844:1961 [1] NCCL INFO TUNER/Plugin: Failed to find ncclTunerPlugin_v4 symbol.\n",
      "ubuntu:1737:1960 [0] NCCL INFO TUNER/Plugin: Failed to find ncclTunerPlugin_v4 symbol.\n",
      "ubuntu:1844:1961 [1] NCCL INFO TUNER/Plugin: Failed to find ncclTunerPlugin_v3 symbol.\n",
      "ubuntu:1737:1960 [0] NCCL INFO TUNER/Plugin: Failed to find ncclTunerPlugin_v3 symbol.\n",
      "ubuntu:1844:1961 [1] NCCL INFO TUNER/Plugin: Failed to find ncclTunerPlugin_v2 symbol, using internal tuner instead.\n",
      "ubuntu:1737:1960 [0] NCCL INFO TUNER/Plugin: Failed to find ncclTunerPlugin_v2 symbol, using internal tuner instead.\n",
      "ubuntu:1844:1961 [1] NCCL INFO ncclCommInitRankConfig comm 0x1ed0a2d0 rank 1 nranks 2 cudaDev 1 nvmlDev 1 busId 2a000 commId 0xd4224b61ec58348e - Init COMPLETE\n",
      "ubuntu:1737:1960 [0] NCCL INFO ncclCommInitRankConfig comm 0x4ec706c0 rank 0 nranks 2 cudaDev 0 nvmlDev 0 busId 27000 commId 0xd4224b61ec58348e - Init COMPLETE\n",
      "ubuntu:1844:1961 [1] NCCL INFO Init timings - ncclCommInitRankConfig: rank 1 nranks 2 total 0.28 (kernels 0.14, alloc 0.10, bootstrap 0.00, allgathers 0.00, topo 0.01, graphs 0.00, connections 0.01, rest 0.01)\n",
      "ubuntu:1737:1960 [0] NCCL INFO Init timings - ncclCommInitRankConfig: rank 0 nranks 2 total 0.30 (kernels 0.14, alloc 0.11, bootstrap 0.02, allgathers 0.00, topo 0.01, graphs 0.00, connections 0.01, rest 0.01)\n",
      "ubuntu:1844:1968 [1] NCCL INFO Channel 00/0 : 1[1] -> 0[0] via P2P/CUMEM/read\n",
      "ubuntu:1844:1968 [1] NCCL INFO Channel 01/0 : 1[1] -> 0[0] via P2P/CUMEM/read\n",
      "ubuntu:1844:1968 [1] NCCL INFO Channel 02/0 : 1[1] -> 0[0] via P2P/CUMEM/read\n",
      "ubuntu:1844:1968 [1] NCCL INFO Channel 03/0 : 1[1] -> 0[0] via P2P/CUMEM/read\n",
      "ubuntu:1844:1968 [1] NCCL INFO Channel 04/0 : 1[1] -> 0[0] via P2P/CUMEM/read\n",
      "ubuntu:1844:1968 [1] NCCL INFO Channel 05/0 : 1[1] -> 0[0] via P2P/CUMEM/read\n",
      "ubuntu:1844:1968 [1] NCCL INFO Channel 06/0 : 1[1] -> 0[0] via P2P/CUMEM/read\n",
      "ubuntu:1844:1968 [1] NCCL INFO Channel 07/0 : 1[1] -> 0[0] via P2P/CUMEM/read\n",
      "ubuntu:1844:1968 [1] NCCL INFO Channel 08/0 : 1[1] -> 0[0] via P2P/CUMEM/read\n",
      "ubuntu:1844:1968 [1] NCCL INFO Channel 09/0 : 1[1] -> 0[0] via P2P/CUMEM/read\n",
      "ubuntu:1844:1968 [1] NCCL INFO Channel 10/0 : 1[1] -> 0[0] via P2P/CUMEM/read\n",
      "ubuntu:1844:1968 [1] NCCL INFO Channel 11/0 : 1[1] -> 0[0] via P2P/CUMEM/read\n",
      "ubuntu:1844:1968 [1] NCCL INFO Channel 12/0 : 1[1] -> 0[0] via P2P/CUMEM/read\n",
      "ubuntu:1844:1968 [1] NCCL INFO Channel 13/0 : 1[1] -> 0[0] via P2P/CUMEM/read\n",
      "ubuntu:1737:1969 [0] NCCL INFO Channel 00/0 : 0[0] -> 1[1] via P2P/CUMEM/read\n",
      "ubuntu:1844:1968 [1] NCCL INFO Channel 14/0 : 1[1] -> 0[0] via P2P/CUMEM/read\n",
      "ubuntu:1737:1969 [0] NCCL INFO Channel 01/0 : 0[0] -> 1[1] via P2P/CUMEM/read\n",
      "ubuntu:1844:1968 [1] NCCL INFO Channel 15/0 : 1[1] -> 0[0] via P2P/CUMEM/read\n",
      "ubuntu:1844:1968 [1] NCCL INFO Channel 16/0 : 1[1] -> 0[0] via P2P/CUMEM/read\n",
      "ubuntu:1737:1969 [0] NCCL INFO Channel 02/0 : 0[0] -> 1[1] via P2P/CUMEM/read\n",
      "ubuntu:1844:1968 [1] NCCL INFO Channel 17/0 : 1[1] -> 0[0] via P2P/CUMEM/read\n",
      "ubuntu:1737:1969 [0] NCCL INFO Channel 03/0 : 0[0] -> 1[1] via P2P/CUMEM/read\n",
      "ubuntu:1844:1968 [1] NCCL INFO Channel 18/0 : 1[1] -> 0[0] via P2P/CUMEM/read\n",
      "ubuntu:1737:1969 [0] NCCL INFO Channel 04/0 : 0[0] -> 1[1] via P2P/CUMEM/read\n",
      "ubuntu:1844:1968 [1] NCCL INFO Channel 19/0 : 1[1] -> 0[0] via P2P/CUMEM/read\n",
      "ubuntu:1844:1968 [1] NCCL INFO Channel 20/0 : 1[1] -> 0[0] via P2P/CUMEM/read\n",
      "ubuntu:1737:1969 [0] NCCL INFO Channel 05/0 : 0[0] -> 1[1] via P2P/CUMEM/read\n",
      "ubuntu:1844:1968 [1] NCCL INFO Channel 21/0 : 1[1] -> 0[0] via P2P/CUMEM/read\n",
      "ubuntu:1737:1969 [0] NCCL INFO Channel 06/0 : 0[0] -> 1[1] via P2P/CUMEM/read\n",
      "ubuntu:1844:1968 [1] NCCL INFO Channel 22/0 : 1[1] -> 0[0] via P2P/CUMEM/read\n",
      "ubuntu:1737:1969 [0] NCCL INFO Channel 07/0 : 0[0] -> 1[1] via P2P/CUMEM/read\n",
      "ubuntu:1844:1968 [1] NCCL INFO Channel 23/0 : 1[1] -> 0[0] via P2P/CUMEM/read\n",
      "ubuntu:1737:1969 [0] NCCL INFO Channel 08/0 : 0[0] -> 1[1] via P2P/CUMEM/read\n",
      "ubuntu:1737:1969 [0] NCCL INFO Channel 09/0 : 0[0] -> 1[1] via P2P/CUMEM/read\n",
      "ubuntu:1737:1969 [0] NCCL INFO Channel 10/0 : 0[0] -> 1[1] via P2P/CUMEM/read\n",
      "ubuntu:1737:1969 [0] NCCL INFO Channel 11/0 : 0[0] -> 1[1] via P2P/CUMEM/read\n",
      "ubuntu:1737:1969 [0] NCCL INFO Channel 12/0 : 0[0] -> 1[1] via P2P/CUMEM/read\n",
      "ubuntu:1737:1969 [0] NCCL INFO Channel 13/0 : 0[0] -> 1[1] via P2P/CUMEM/read\n",
      "ubuntu:1737:1969 [0] NCCL INFO Channel 14/0 : 0[0] -> 1[1] via P2P/CUMEM/read\n",
      "ubuntu:1737:1969 [0] NCCL INFO Channel 15/0 : 0[0] -> 1[1] via P2P/CUMEM/read\n",
      "ubuntu:1737:1969 [0] NCCL INFO Channel 16/0 : 0[0] -> 1[1] via P2P/CUMEM/read\n",
      "ubuntu:1737:1969 [0] NCCL INFO Channel 17/0 : 0[0] -> 1[1] via P2P/CUMEM/read\n",
      "ubuntu:1737:1969 [0] NCCL INFO Channel 18/0 : 0[0] -> 1[1] via P2P/CUMEM/read\n",
      "ubuntu:1737:1969 [0] NCCL INFO Channel 19/0 : 0[0] -> 1[1] via P2P/CUMEM/read\n",
      "ubuntu:1737:1969 [0] NCCL INFO Channel 20/0 : 0[0] -> 1[1] via P2P/CUMEM/read\n",
      "ubuntu:1737:1969 [0] NCCL INFO Channel 21/0 : 0[0] -> 1[1] via P2P/CUMEM/read\n",
      "ubuntu:1737:1969 [0] NCCL INFO Channel 22/0 : 0[0] -> 1[1] via P2P/CUMEM/read\n",
      "ubuntu:1737:1969 [0] NCCL INFO Channel 23/0 : 0[0] -> 1[1] via P2P/CUMEM/read\n",
      "ubuntu:1737:1969 [0] NCCL INFO Connected all rings, use ring PXN 0 GDR 1\n",
      "ubuntu:1844:1968 [1] NCCL INFO Connected all rings, use ring PXN 0 GDR 1\n",
      "[NeMo I 2025-06-05 11:05:17 utils:554] Building Evo2Dataset splits with sizes=[400000, 8040, 2] and config=GPTDatasetConfig(random_seed=1234, sequence_length=1, blend=None, blend_per_split=[(['/workspace/preprocessed_data/XTT22_train_byte-level_train'], [1.0]), (['/workspace/preprocessed_data/XTT22_train_byte-level_val'], [1.0]), (['/workspace/preprocessed_data/XTT22_train_byte-level_test'], [1.0])], split=None, split_matrix=None, num_dataset_builder_threads=1, path_to_cache=None, mmap_bin_files=True, mock=False, tokenizer=<nemo.collections.common.tokenizers.bytelevel_tokenizers.ByteLevelTokenizer object at 0x722e7dbcba40>, mid_level_dataset_surplus=0.005, reset_position_ids=False, reset_attention_mask=False, eod_mask_loss=False, create_attention_mask=False, drop_last_partial_validation_sequence=True, add_extra_token_to_sequence=True, object_storage_cache_path=None)\n",
      "[NeMo I 2025-06-05 11:05:17 utils:554] Load the _IndexReader from /workspace/preprocessed_data/XTT22_train_byte-level_train.idx\n",
      "[NeMo I 2025-06-05 11:05:17 utils:554] \tExtract the sequence lengths\n",
      "[NeMo I 2025-06-05 11:05:17 utils:554] \tExtract the sequence pointers\n",
      "[NeMo I 2025-06-05 11:05:17 utils:554] \tExtract the document indices\n",
      "[NeMo I 2025-06-05 11:05:17 utils:554] > total number of sequences: 10896\n",
      "[NeMo I 2025-06-05 11:05:17 utils:554] > total number of documents: 10896\n",
      "[NeMo I 2025-06-05 11:05:17 utils:554] Build and save the Evo2Dataset train indices\n",
      "[rank1]:[E605 11:15:17.409088279 ProcessGroupNCCL.cpp:633] [Rank 1] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=4, OpType=ALLREDUCE, NumelIn=1, NumelOut=1, Timeout(ms)=600000) ran for 600000 milliseconds before timing out.\n",
      "[rank1]:[E605 11:15:17.409371990 ProcessGroupNCCL.cpp:757] [Rank 1] Work WorkNCCL(SeqNum=4, OpType=ALLREDUCE, NumelIn=1, NumelOut=1, Timeout(ms)=600000) timed out in blocking wait.\n",
      "ubuntu:1844:1971 [1] NCCL INFO misc/socket.cc:64 -> 3\n",
      "ubuntu:1844:1971 [1] NCCL INFO misc/socket.cc:80 -> 3\n",
      "ubuntu:1844:1971 [1] NCCL INFO misc/socket.cc:829 -> 3\n",
      "ubuntu:1844:1971 [1] NCCL INFO misc/socket.cc:64 -> 3\n",
      "ubuntu:1844:1971 [1] NCCL INFO misc/socket.cc:80 -> 3\n",
      "ubuntu:1844:1971 [1] NCCL INFO misc/socket.cc:829 -> 3\n",
      "ubuntu:1844:1964 [1] NCCL INFO misc/socket.cc:881 -> 3\n",
      "ubuntu:1844:1971 [1] NCCL INFO comm 0x1ed0a2d0 rank 1 nranks 2 cudaDev 1 busId 2a000 - Abort COMPLETE\n",
      "[rank1]:[E605 11:15:18.937631722 ProcessGroupNCCL.cpp:685] [Rank 1] Some NCCL operations have failed or timed out. Due to the asynchronous nature of CUDA kernels, subsequent GPU operations might run on corrupted/incomplete data.\n",
      "[rank1]:[E605 11:15:18.937678550 ProcessGroupNCCL.cpp:699] [Rank 1] To avoid data inconsistency, we are taking the entire process down.\n",
      "[rank1]: Traceback (most recent call last):\n",
      "[rank1]:   File \"/usr/local/bin/train_evo2\", line 10, in <module>\n",
      "[rank1]:     sys.exit(main())\n",
      "[rank1]:              ^^^^^^\n",
      "[rank1]:   File \"/usr/local/lib/python3.12/dist-packages/bionemo/evo2/run/train.py\", line 1133, in main\n",
      "[rank1]:     train(args=args)\n",
      "[rank1]:   File \"/usr/local/lib/python3.12/dist-packages/bionemo/evo2/run/train.py\", line 1126, in train\n",
      "[rank1]:     trainer.fit(model, data_module)\n",
      "[rank1]:   File \"/usr/local/lib/python3.12/dist-packages/lightning/pytorch/trainer/trainer.py\", line 538, in fit\n",
      "[rank1]:     call._call_and_handle_interrupt(\n",
      "[rank1]:   File \"/usr/local/lib/python3.12/dist-packages/lightning/pytorch/trainer/call.py\", line 46, in _call_and_handle_interrupt\n",
      "[rank1]:     return trainer.strategy.launcher.launch(trainer_fn, *args, trainer=trainer, **kwargs)\n",
      "[rank1]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[rank1]:   File \"/usr/local/lib/python3.12/dist-packages/lightning/pytorch/strategies/launchers/subprocess_script.py\", line 105, in launch\n",
      "[rank1]:     return function(*args, **kwargs)\n",
      "[rank1]:            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[rank1]:   File \"/usr/local/lib/python3.12/dist-packages/lightning/pytorch/trainer/trainer.py\", line 574, in _fit_impl\n",
      "[rank1]:     self._run(model, ckpt_path=ckpt_path)\n",
      "[rank1]:   File \"/usr/local/lib/python3.12/dist-packages/lightning/pytorch/trainer/trainer.py\", line 943, in _run\n",
      "[rank1]:     call._call_setup_hook(self)  # allow user to set up LightningModule in accelerator environment\n",
      "[rank1]:     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[rank1]:   File \"/usr/local/lib/python3.12/dist-packages/lightning/pytorch/trainer/call.py\", line 102, in _call_setup_hook\n",
      "[rank1]:     _call_lightning_datamodule_hook(trainer, \"setup\", stage=fn)\n",
      "[rank1]:   File \"/usr/local/lib/python3.12/dist-packages/lightning/pytorch/trainer/call.py\", line 189, in _call_lightning_datamodule_hook\n",
      "[rank1]:     return fn(*args, **kwargs)\n",
      "[rank1]:            ^^^^^^^^^^^^^^^^^^^\n",
      "[rank1]:   File \"/usr/local/lib/python3.12/dist-packages/nemo/collections/llm/gpt/data/pre_training.py\", line 314, in setup\n",
      "[rank1]:     self.build(\n",
      "[rank1]:   File \"/usr/local/lib/python3.12/dist-packages/nemo/collections/llm/gpt/data/pre_training.py\", line 304, in build\n",
      "[rank1]:     ).build()\n",
      "[rank1]:       ^^^^^^^\n",
      "[rank1]:   File \"/usr/local/lib/python3.12/dist-packages/megatron/core/datasets/blended_megatron_dataset_builder.py\", line 132, in build\n",
      "[rank1]:     datasets = self._build_blended_dataset_splits()\n",
      "[rank1]:                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[rank1]:   File \"/usr/local/lib/python3.12/dist-packages/megatron/core/datasets/blended_megatron_dataset_builder.py\", line 253, in _build_blended_dataset_splits\n",
      "[rank1]:     blended_datasets[i] = self._build_megatron_dataset_splits(\n",
      "[rank1]:                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[rank1]:   File \"/usr/local/lib/python3.12/dist-packages/megatron/core/datasets/blended_megatron_dataset_builder.py\", line 443, in _build_megatron_dataset_splits\n",
      "[rank1]:     self.build_generic_dataset(\n",
      "[rank1]:   File \"/usr/local/lib/python3.12/dist-packages/megatron/core/datasets/blended_megatron_dataset_builder.py\", line 507, in build_generic_dataset\n",
      "[rank1]:     torch.distributed.barrier()\n",
      "[rank1]:   File \"/usr/local/lib/python3.12/dist-packages/torch/distributed/c10d_logger.py\", line 81, in wrapper\n",
      "[rank1]:     return func(*args, **kwargs)\n",
      "[rank1]:            ^^^^^^^^^^^^^^^^^^^^^\n",
      "[rank1]:   File \"/usr/local/lib/python3.12/dist-packages/torch/distributed/distributed_c10d.py\", line 4662, in barrier\n",
      "[rank1]:     work.wait()\n",
      "[rank1]: torch.distributed.DistBackendError: [Rank 1] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=4, OpType=ALLREDUCE, NumelIn=1, NumelOut=1, Timeout(ms)=600000) ran for 600000 milliseconds before timing out.\n",
      "[rank: 1] Child process with PID 1844 terminated with code 1. Forcefully terminating all other processes to avoid zombies 🧟\n"
     ]
    }
   ],
   "source": [
    "!cp /workspace/bionemo_train.py /usr/local/lib/python3.12/dist-packages/bionemo/evo2/run/train.py\n",
    "import os\n",
    "import subprocess\n",
    "import time\n",
    "from datetime import datetime\n",
    "# 2. 设置NCCL和分布式环境变量\n",
    "print(\"🔧 配置NCCL超时和优化参数...\")\n",
    "\n",
    "# NCCL超时设置 - 增加到2小时\n",
    "os.environ['NCCL_TIMEOUT'] = '7200'  # 2小时超时\n",
    "os.environ['TORCH_NCCL_BLOCKING_WAIT'] = '1'  # 使用新的环境变量名\n",
    "os.environ['TORCH_NCCL_ASYNC_ERROR_HANDLING'] = '1'  # 使用新的环境变量名\n",
    "os.environ['NCCL_DEBUG'] = 'INFO'  # 启用详细调试信息\n",
    "\n",
    "# PyTorch分布式超时设置\n",
    "os.environ['TORCH_DISTRIBUTED_TIMEOUT'] = '7200'  # PyTorch分布式超时\n",
    "os.environ['TORCH_NCCL_TRACE_BUFFER_SIZE'] = '1024'  # 启用NCCL跟踪\n",
    "\n",
    "# 数据加载和通信优化\n",
    "os.environ['NCCL_BUFFSIZE'] = '8388608'  # 增加缓冲区大小到8MB\n",
    "os.environ['NCCL_NTHREADS'] = '8'  # 增加NCCL线程数\n",
    "os.environ['NCCL_MIN_NTHREADS'] = '4'  # 最小线程数\n",
    "\n",
    "# 避免内存碎片和并行冲突\n",
    "os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'max_split_size_mb:512'\n",
    "os.environ['TOKENIZERS_PARALLELISM'] = 'false'  # 避免tokenizer并行冲突\n",
    "os.environ['OMP_NUM_THREADS'] = '4'  # 限制OpenMP线程数\n",
    "\n",
    "# 数据集准备优化\n",
    "os.environ['NCCL_P2P_DISABLE'] = '0'  # 确保P2P通信启用\n",
    "os.environ['NCCL_SHM_DISABLE'] = '0'  # 确保共享内存通信启用\n",
    "!export NCCL_TIMEOUT=7200                    # 2小时超时\n",
    "!export TORCH_NCCL_TRACE_BUFFER_SIZE=1024    # 启用NCCL跟踪\n",
    "!export TORCH_DISTRIBUTED_TIMEOUT=7200       # PyTorch分布式超时\n",
    "!export NCCL_BLOCKING_WAIT=1                 # 阻塞等待\n",
    "!export NCCL_DEBUG=INFO  \n",
    "!train_evo2 \\\n",
    "    -d training_data_config.yaml \\\n",
    "    --dataset-dir {preprocessed_data} \\\n",
    "    --model-size 7b \\\n",
    "    --devices 2 \\\n",
    "    --num-nodes 1 \\\n",
    "    --seq-length 1 \\\n",
    "    --micro-batch-size 1 \\\n",
    "    --lr 0.0001 \\\n",
    "    --warmup-steps 5 \\\n",
    "    --max-steps 200000 \\\n",
    "    --ckpt-dir nemo2_evo2_7b \\\n",
    "    --clip-grad 1 \\\n",
    "    --wd 0.01 \\\n",
    "    --activation-checkpoint-recompute-num-layers 1 \\\n",
    "    --val-check-interval 1000 \\\n",
    "    --ckpt-async-save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e795111f-d548-4d61-a1c1-85d6e95a2ef6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
