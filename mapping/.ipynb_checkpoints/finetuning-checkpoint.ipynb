{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f1f816cb-6abb-4cf9-9a0b-d1382a4c9910",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "concat_path = \"XTT22_train.fa\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e5a015b5-fad5-4d11-adcd-2fb18c594536",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_fasta_path = os.path.abspath(concat_path)\n",
    "output_dir = os.path.abspath(\"preprocessed_data\")\n",
    "output_yaml = f\"\"\"\n",
    "- datapaths: [\"{full_fasta_path}\"]\n",
    "  output_dir: \"{output_dir}\"\n",
    "  output_prefix: XTT22_train\n",
    "  train_split: 0.9\n",
    "  valid_split: 0.05\n",
    "  test_split: 0.05\n",
    "  overwrite: True\n",
    "  embed_reverse_complement: true\n",
    "  random_reverse_complement: 0.0\n",
    "  random_lineage_dropout: 0.0\n",
    "  include_sequence_id: false\n",
    "  transcribe: \"back_transcribe\"\n",
    "  force_uppercase: false\n",
    "  indexed_dataset_dtype: \"uint8\"\n",
    "  tokenizer_type: \"Byte-Level\"\n",
    "  vocab_file: null\n",
    "  vocab_size: null\n",
    "  merges_file: null\n",
    "  pretrained_tokenizer_model: null\n",
    "  special_tokens: null\n",
    "  fast_hf_tokenizer: true\n",
    "  append_eod: true\n",
    "  enforce_sample_length: null\n",
    "  ftfy: false\n",
    "  workers: 1\n",
    "  preproc_concurrency: 100000\n",
    "  chunksize: 25\n",
    "  drop_empty_sequences: true\n",
    "  nnn_filter: false  # If you split your fasta on NNN (in human these are contigs), then you should set this to true.\n",
    "  seed: 12342  # Not relevant because we are not using random reverse complement or lineage dropout.\n",
    "\"\"\"\n",
    "with open(\"preprocess_config.yaml\", \"w\") as f:\n",
    "    print(output_yaml, file=f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "aadbf5cb-03b5-4a20-96e5-7bb0a7e5b942",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2025-05-04 03:51:59 nemo_logging:393] Using byte-level tokenization\n",
      "[NeMo I 2025-05-04 03:51:59 nemo_logging:393] Created temporary binary datasets: /workspace/preprocessed_data/XTT22_train_byte-level_train.bin.tmp /workspace/preprocessed_data/XTT22_train_byte-level_val.bin.tmp /workspace/preprocessed_data/XTT22_train_byte-level_test.bin.tmp\n",
      "[NeMo I 2025-05-04 04:10:51 nemo_logging:393] Average preprocessing time per sequence: 0.027723908739850228\n",
      "[NeMo I 2025-05-04 04:10:51 nemo_logging:393] Average indexing time per sequence: 0.07471058235001256\n",
      "[NeMo I 2025-05-04 04:10:51 nemo_logging:393] Number of sequences processed: 12092\n",
      "[NeMo I 2025-05-04 04:10:51 nemo_logging:393] Finished preprocessing XTT22_train ([PosixPath('/workspace/XTT22_train.fa')]) in 1132.750 seconds with 1 workers.\n"
     ]
    }
   ],
   "source": [
    "!preprocess_evo2 --config preprocess_config.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3df5d34a-d5fe-4fa9-ac3d-65b9696a9045",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 9.3G\n",
      "-rw-r--r-- 1 root root 1.5G May  4 04:10 XTT22_train_byte-level_test.bin\n",
      "-rw-r--r-- 1 root root  13K May  4 04:10 XTT22_train_byte-level_test.idx\n",
      "-rw-r--r-- 1 root root  12G May  4 04:10 XTT22_train_byte-level_train.bin\n",
      "-rw-r--r-- 1 root root 213K May  4 04:10 XTT22_train_byte-level_train.idx\n",
      "-rw-r--r-- 1 root root 568M May  4 04:10 XTT22_train_byte-level_val.bin\n",
      "-rw-r--r-- 1 root root  12K May  4 04:10 XTT22_train_byte-level_val.idx\n",
      "-rw-r--r-- 1 root root    0 May  4 03:44 sc3_train_byte-level_test.bin.tmp\n",
      "-rw-r--r-- 1 root root    0 May  4 03:44 sc3_train_byte-level_train.bin.tmp\n",
      "-rw-r--r-- 1 root root    0 May  4 03:44 sc3_train_byte-level_val.bin.tmp\n"
     ]
    }
   ],
   "source": [
    "!ls -lh preprocessed_data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5bc40b51-b8a1-42da-b3b0-0b12458312a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "savanna_evo2_1b_base.pt: 100%|█████████████| 2.71G/2.71G [04:17<00:00, 10.5MB/s]\n",
      "[NeMo I 2025-05-04 13:41:01 nemo_logging:393] Using byte-level tokenization\n",
      "[INFO     | pytorch_lightning.utilities.rank_zero]: GPU available: True (cuda), used: False\n",
      "[INFO     | pytorch_lightning.utilities.rank_zero]: TPU available: False, using: 0 TPU cores\n",
      "[INFO     | pytorch_lightning.utilities.rank_zero]: HPU available: False, using: 0 HPUs\n",
      "[NeMo W 2025-05-04 13:41:01 nemo_logging:405] /usr/local/lib/python3.12/dist-packages/lightning/pytorch/trainer/setup.py:177: GPU available but not used. You can set it by doing `Trainer(accelerator='gpu')`.\n",
      "    \n",
      "[NeMo I 2025-05-04 13:41:01 nemo_logging:393] Fixing mis-match between ddp-config & mcore-optimizer config\n",
      "[NeMo I 2025-05-04 13:41:01 nemo_logging:393] Rank 0 has data parallel group : [0]\n",
      "[NeMo I 2025-05-04 13:41:01 nemo_logging:393] Rank 0 has combined group of data parallel and context parallel : [0]\n",
      "[NeMo I 2025-05-04 13:41:01 nemo_logging:393] All data parallel group ranks with context parallel combined: [[0]]\n",
      "[NeMo I 2025-05-04 13:41:01 nemo_logging:393] Ranks 0 has data parallel rank: 0\n",
      "[NeMo I 2025-05-04 13:41:01 nemo_logging:393] Rank 0 has context parallel group: [0]\n",
      "[NeMo I 2025-05-04 13:41:01 nemo_logging:393] All context parallel group ranks: [[0]]\n",
      "[NeMo I 2025-05-04 13:41:01 nemo_logging:393] Ranks 0 has context parallel rank: 0\n",
      "[NeMo I 2025-05-04 13:41:01 nemo_logging:393] Rank 0 has model parallel group: [0]\n",
      "[NeMo I 2025-05-04 13:41:01 nemo_logging:393] All model parallel group ranks: [[0]]\n",
      "[NeMo I 2025-05-04 13:41:01 nemo_logging:393] Rank 0 has tensor model parallel group: [0]\n",
      "[NeMo I 2025-05-04 13:41:01 nemo_logging:393] All tensor model parallel group ranks: [[0]]\n",
      "[NeMo I 2025-05-04 13:41:01 nemo_logging:393] Rank 0 has tensor model parallel rank: 0\n",
      "[NeMo I 2025-05-04 13:41:01 nemo_logging:393] Rank 0 has pipeline model parallel group: [0]\n",
      "[NeMo I 2025-05-04 13:41:01 nemo_logging:393] Rank 0 has embedding group: [0]\n",
      "[NeMo I 2025-05-04 13:41:01 nemo_logging:393] All pipeline model parallel group ranks: [[0]]\n",
      "[NeMo I 2025-05-04 13:41:01 nemo_logging:393] Rank 0 has pipeline model parallel rank 0\n",
      "[NeMo I 2025-05-04 13:41:01 nemo_logging:393] All embedding group ranks: [[0]]\n",
      "[NeMo I 2025-05-04 13:41:01 nemo_logging:393] Rank 0 has embedding rank: 0\n",
      "[INFO     | pytorch_lightning.utilities.rank_zero]: ----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=gloo\n",
      "All distributed processes registered. Starting with 1 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[NeMo W 2025-05-04 13:41:01 nemo_logging:405] /usr/local/lib/python3.12/dist-packages/lightning/pytorch/trainer/trainer.py:1090: `trainer.init_module` cannot fully support proper instantiation of your model with the `MegatronStrategy` strategy. Please instantiate your model inside the`LightningModule.configure_model` hook instead\n",
      "    \n",
      "[NeMo I 2025-05-04 13:41:01 nemo_logging:393] Padded vocab_size: 512, original vocab_size: 512, dummy tokens: 0.\n",
      "[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context\n",
      "[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context\n",
      "[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context\n",
      "[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context\n",
      "[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context\n",
      "[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context\n",
      "[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context\n",
      "[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context\n",
      "[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context\n",
      "[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context\n",
      "[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context\n",
      "[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context\n",
      "[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context\n",
      "[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context\n",
      "[NeMo W 2025-05-04 13:41:02 nemo_logging:405] Could not copy Trainer's 'max_steps' to LR scheduler's 'max_steps'. If you are not using an LR scheduler, this warning can safely be ignored.\n",
      "[NeMo I 2025-05-04 13:41:02 nemo_logging:393] Using FullyParallelSaveStrategyWrapper(torch_dist, 1) dist-ckpt save strategy.\n",
      "[NeMo I 2025-05-04 13:41:15 nemo_logging:393] Global Checkpoint Save : Rank: 0 : Iteration: 0 : Start time: 1746366062.539s : Save duration: 13.139s\n",
      "[NeMo I 2025-05-04 13:41:15 nemo_logging:393] Converted Hyena model to Nemo, model saved to nemo2_evo2_1b_8k\n"
     ]
    }
   ],
   "source": [
    "!evo2_convert_to_nemo2 \\\n",
    "  --model-path hf://arcinstitute/savanna_evo2_1b_base \\\n",
    "  --model-size 1b --output-dir nemo2_evo2_1b_8k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "56a10c51-4574-45a0-b1bc-94581798171b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "output_pfx = str(Path(os.path.abspath(\"preprocessed_data\"))/\"XTT22_train_byte-level\")\n",
    "output_yaml = f\"\"\"\n",
    "- dataset_prefix: {output_pfx}_train\n",
    "  dataset_split: train\n",
    "  dataset_weight: 1.0\n",
    "- dataset_prefix: {output_pfx}_val\n",
    "  dataset_split: validation\n",
    "  dataset_weight: 1.0\n",
    "- dataset_prefix: {output_pfx}_test\n",
    "  dataset_split: test\n",
    "  dataset_weight: 1.0\n",
    "\"\"\"\n",
    "with open(\"training_data_config.yaml\", \"w\") as f:\n",
    "    print(output_yaml, file=f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dff9f392-359a-4463-b435-54beadb4ea67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2025-05-05 10:33:34 nemo_logging:393] Using byte-level tokenization\n",
      "[NeMo W 2025-05-05 10:33:34 nemo_logging:405] WandB is currently turned off.\n",
      "[NeMo W 2025-05-05 10:33:34 nemo_logging:405] User-set tensorboard is currently turned off. Internally one may still be set by NeMo2.\n",
      "[INFO     | pytorch_lightning.utilities.rank_zero]: Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.\n",
      "[INFO     | pytorch_lightning.utilities.rank_zero]: GPU available: True (cuda), used: True\n",
      "[INFO     | pytorch_lightning.utilities.rank_zero]: TPU available: False, using: 0 TPU cores\n",
      "[INFO     | pytorch_lightning.utilities.rank_zero]: HPU available: False, using: 0 HPUs\n",
      "[NeMo I 2025-05-05 10:33:34 nemo_logging:393] Experiments will be logged at results/evo2/dev\n",
      "[NeMo W 2025-05-05 10:33:34 nemo_logging:405] There were no checkpoints found in checkpoint_dir or no checkpoint folder at checkpoint_dir :results/evo2/checkpoints. Training from scratch.\n",
      "[NeMo I 2025-05-05 10:33:34 nemo_logging:393] Fixing mis-match between ddp-config & mcore-optimizer config\n",
      "[NeMo I 2025-05-05 10:33:34 nemo_logging:393] Rank 0 has data parallel group : [0]\n",
      "[NeMo I 2025-05-05 10:33:34 nemo_logging:393] Rank 0 has combined group of data parallel and context parallel : [0]\n",
      "[NeMo I 2025-05-05 10:33:34 nemo_logging:393] All data parallel group ranks with context parallel combined: [[0]]\n",
      "[NeMo I 2025-05-05 10:33:34 nemo_logging:393] Ranks 0 has data parallel rank: 0\n",
      "[NeMo I 2025-05-05 10:33:34 nemo_logging:393] Rank 0 has context parallel group: [0]\n",
      "[NeMo I 2025-05-05 10:33:34 nemo_logging:393] All context parallel group ranks: [[0]]\n",
      "[NeMo I 2025-05-05 10:33:34 nemo_logging:393] Ranks 0 has context parallel rank: 0\n",
      "[NeMo I 2025-05-05 10:33:34 nemo_logging:393] Rank 0 has model parallel group: [0]\n",
      "[NeMo I 2025-05-05 10:33:34 nemo_logging:393] All model parallel group ranks: [[0]]\n",
      "[NeMo I 2025-05-05 10:33:34 nemo_logging:393] Rank 0 has tensor model parallel group: [0]\n",
      "[NeMo I 2025-05-05 10:33:34 nemo_logging:393] All tensor model parallel group ranks: [[0]]\n",
      "[NeMo I 2025-05-05 10:33:34 nemo_logging:393] Rank 0 has tensor model parallel rank: 0\n",
      "[NeMo I 2025-05-05 10:33:34 nemo_logging:393] Rank 0 has pipeline model parallel group: [0]\n",
      "[NeMo I 2025-05-05 10:33:34 nemo_logging:393] Rank 0 has embedding group: [0]\n",
      "[NeMo I 2025-05-05 10:33:34 nemo_logging:393] All pipeline model parallel group ranks: [[0]]\n",
      "[NeMo I 2025-05-05 10:33:34 nemo_logging:393] Rank 0 has pipeline model parallel rank 0\n",
      "[NeMo I 2025-05-05 10:33:34 nemo_logging:393] All embedding group ranks: [[0]]\n",
      "[NeMo I 2025-05-05 10:33:34 nemo_logging:393] Rank 0 has embedding rank: 0\n",
      "[INFO     | pytorch_lightning.utilities.rank_zero]: ----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 1 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[NeMo I 2025-05-05 10:33:35 utils:302] Building Evo2Dataset splits with sizes=[100, 60, 1] and config=GPTDatasetConfig(random_seed=1234, sequence_length=1, blend=None, blend_per_split=[(['/workspace/preprocessed_data/XTT22_train_byte-level_train'], [1.0]), (['/workspace/preprocessed_data/XTT22_train_byte-level_val'], [1.0]), (['/workspace/preprocessed_data/XTT22_train_byte-level_test'], [1.0])], split=None, split_matrix=None, num_dataset_builder_threads=1, path_to_cache=None, mmap_bin_files=True, mock=False, tokenizer=<nemo.collections.common.tokenizers.bytelevel_tokenizers.ByteLevelTokenizer object at 0x7f864910fd40>, reset_position_ids=False, reset_attention_mask=False, eod_mask_loss=False, create_attention_mask=False, drop_last_partial_validation_sequence=True, add_extra_token_to_sequence=True, s3_cache_path=None)\n",
      "[NeMo I 2025-05-05 10:33:35 utils:302] Load the _IndexReader from /workspace/preprocessed_data/XTT22_train_byte-level_train.idx\n",
      "[NeMo I 2025-05-05 10:33:35 utils:302] \tExtract the sequence lengths\n",
      "[NeMo I 2025-05-05 10:33:35 utils:302] \tExtract the sequence pointers\n",
      "[NeMo I 2025-05-05 10:33:35 utils:302] \tExtract the document indices\n",
      "[NeMo I 2025-05-05 10:33:35 utils:302] > total number of sequences: 10894\n",
      "[NeMo I 2025-05-05 10:33:35 utils:302] > total number of documents: 10894\n",
      "[NeMo I 2025-05-05 10:33:35 utils:302] Build and save the Evo2Dataset train indices\n"
     ]
    }
   ],
   "source": [
    "!train_evo2 \\\n",
    "    -d training_data_config.yaml \\\n",
    "    --dataset-dir {preprocessed_data} \\\n",
    "    --model-size 1b \\\n",
    "    --devices 1 \\\n",
    "    --num-nodes 1 \\\n",
    "    --seq-length 1 \\\n",
    "    --micro-batch-size 1 \\\n",
    "    --lr 0.0001 \\\n",
    "    --warmup-steps 5 \\\n",
    "    --max-steps 100 \\\n",
    "    --ckpt-dir nemo2_evo2_1b_8k \\\n",
    "    --clip-grad 1 \\\n",
    "    --wd 0.01 \\\n",
    "    --activation-checkpoint-recompute-num-layers 1 \\\n",
    "    --val-check-interval 50 \\\n",
    "    --ckpt-async-save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "eb824a00-ea7c-4ef2-8e0b-66e6189876c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mDEPRECATION: Loading egg at /usr/local/lib/python3.12/dist-packages/looseversion-1.3.0-py3.12.egg is deprecated. pip 25.1 will enforce this behaviour change. A possible replacement is to use pip for package installation. Discussion can be found at https://github.com/pypa/pip/issues/12330\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mDEPRECATION: Loading egg at /usr/local/lib/python3.12/dist-packages/lightning_utilities-0.12.0.dev0-py3.12.egg is deprecated. pip 25.1 will enforce this behaviour change. A possible replacement is to use pip for package installation. Discussion can be found at https://github.com/pypa/pip/issues/12330\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mDEPRECATION: Loading egg at /usr/local/lib/python3.12/dist-packages/dill-0.3.9-py3.12.egg is deprecated. pip 25.1 will enforce this behaviour change. A possible replacement is to use pip for package installation. Discussion can be found at https://github.com/pypa/pip/issues/12330\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mDEPRECATION: Loading egg at /usr/local/lib/python3.12/dist-packages/opt_einsum-3.4.0-py3.12.egg is deprecated. pip 25.1 will enforce this behaviour change. A possible replacement is to use pip for package installation. Discussion can be found at https://github.com/pypa/pip/issues/12330\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mDEPRECATION: Loading egg at /usr/local/lib/python3.12/dist-packages/nvfuser-0.2.23a0+6627725-py3.12-linux-x86_64.egg is deprecated. pip 25.1 will enforce this behaviour change. A possible replacement is to use pip for package installation. Discussion can be found at https://github.com/pypa/pip/issues/12330\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mDEPRECATION: Loading egg at /usr/local/lib/python3.12/dist-packages/lightning_thunder-0.2.0.dev0-py3.12.egg is deprecated. pip 25.1 will enforce this behaviour change. A possible replacement is to use pip for package installation. Discussion can be found at https://github.com/pypa/pip/issues/12330\u001b[0m\u001b[33m\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install -q peft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e4f1a484-0a58-4fe2-bb80-b344eeba271e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cp /workspace/train_lora2.py /usr/local/lib/python3.12/dist-packages/bionemo/evo2/run/train.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a7f72369-7e12-4796-a18c-3822b4598e03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2025-05-04 13:57:53 nemo_logging:393] Using byte-level tokenization\n",
      "[NeMo W 2025-05-04 13:57:53 nemo_logging:405] WandB is currently turned off.\n",
      "[NeMo W 2025-05-04 13:57:53 nemo_logging:405] User-set tensorboard is currently turned off. Internally one may still be set by NeMo2.\n",
      "[INFO     | pytorch_lightning.utilities.rank_zero]: Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.\n",
      "[INFO     | pytorch_lightning.utilities.rank_zero]: GPU available: True (cuda), used: True\n",
      "[INFO     | pytorch_lightning.utilities.rank_zero]: TPU available: False, using: 0 TPU cores\n",
      "[INFO     | pytorch_lightning.utilities.rank_zero]: HPU available: False, using: 0 HPUs\n",
      "[NeMo I 2025-05-04 13:57:53 nemo_logging:393] Experiments will be logged at results/evo2/dev\n",
      "[NeMo W 2025-05-04 13:57:53 nemo_logging:405] There were no checkpoints found in checkpoint_dir or no checkpoint folder at checkpoint_dir :results/evo2/checkpoints. Training from scratch.\n",
      "[NeMo I 2025-05-04 13:57:53 nemo_logging:393] Fixing mis-match between ddp-config & mcore-optimizer config\n",
      "[NeMo I 2025-05-04 13:57:53 nemo_logging:393] Rank 0 has data parallel group : [0]\n",
      "[NeMo I 2025-05-04 13:57:53 nemo_logging:393] Rank 0 has combined group of data parallel and context parallel : [0]\n",
      "[NeMo I 2025-05-04 13:57:53 nemo_logging:393] All data parallel group ranks with context parallel combined: [[0]]\n",
      "[NeMo I 2025-05-04 13:57:53 nemo_logging:393] Ranks 0 has data parallel rank: 0\n",
      "[NeMo I 2025-05-04 13:57:53 nemo_logging:393] Rank 0 has context parallel group: [0]\n",
      "[NeMo I 2025-05-04 13:57:53 nemo_logging:393] All context parallel group ranks: [[0]]\n",
      "[NeMo I 2025-05-04 13:57:53 nemo_logging:393] Ranks 0 has context parallel rank: 0\n",
      "[NeMo I 2025-05-04 13:57:53 nemo_logging:393] Rank 0 has model parallel group: [0]\n",
      "[NeMo I 2025-05-04 13:57:53 nemo_logging:393] All model parallel group ranks: [[0]]\n",
      "[NeMo I 2025-05-04 13:57:53 nemo_logging:393] Rank 0 has tensor model parallel group: [0]\n",
      "[NeMo I 2025-05-04 13:57:53 nemo_logging:393] All tensor model parallel group ranks: [[0]]\n",
      "[NeMo I 2025-05-04 13:57:53 nemo_logging:393] Rank 0 has tensor model parallel rank: 0\n",
      "[NeMo I 2025-05-04 13:57:53 nemo_logging:393] Rank 0 has pipeline model parallel group: [0]\n",
      "[NeMo I 2025-05-04 13:57:53 nemo_logging:393] Rank 0 has embedding group: [0]\n",
      "[NeMo I 2025-05-04 13:57:53 nemo_logging:393] All pipeline model parallel group ranks: [[0]]\n",
      "[NeMo I 2025-05-04 13:57:53 nemo_logging:393] Rank 0 has pipeline model parallel rank 0\n",
      "[NeMo I 2025-05-04 13:57:53 nemo_logging:393] All embedding group ranks: [[0]]\n",
      "[NeMo I 2025-05-04 13:57:53 nemo_logging:393] Rank 0 has embedding rank: 0\n",
      "[INFO     | pytorch_lightning.utilities.rank_zero]: ----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 1 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[NeMo I 2025-05-04 13:57:53 utils:302] Building Evo2Dataset splits with sizes=[100, 60, 1] and config=GPTDatasetConfig(random_seed=1234, sequence_length=8192, blend=None, blend_per_split=[(['/workspace/preprocessed_data/XTT22_train_byte-level_train'], [1.0]), (['/workspace/preprocessed_data/XTT22_train_byte-level_val'], [1.0]), (['/workspace/preprocessed_data/XTT22_train_byte-level_test'], [1.0])], split=None, split_matrix=None, num_dataset_builder_threads=1, path_to_cache=None, mmap_bin_files=True, mock=False, tokenizer=<nemo.collections.common.tokenizers.bytelevel_tokenizers.ByteLevelTokenizer object at 0x72ce05b13a40>, reset_position_ids=False, reset_attention_mask=False, eod_mask_loss=False, create_attention_mask=False, drop_last_partial_validation_sequence=True, add_extra_token_to_sequence=True, s3_cache_path=None)\n",
      "[NeMo I 2025-05-04 13:57:53 utils:302] Load the _IndexReader from /workspace/preprocessed_data/XTT22_train_byte-level_train.idx\n",
      "[NeMo I 2025-05-04 13:57:53 utils:302] \tExtract the sequence lengths\n",
      "[NeMo I 2025-05-04 13:57:53 utils:302] \tExtract the sequence pointers\n",
      "[NeMo I 2025-05-04 13:57:53 utils:302] \tExtract the document indices\n",
      "[NeMo I 2025-05-04 13:57:53 utils:302] > total number of sequences: 10894\n",
      "[NeMo I 2025-05-04 13:57:53 utils:302] > total number of documents: 10894\n",
      "[NeMo I 2025-05-04 13:57:53 utils:302] Build and save the Evo2Dataset train indices\n",
      "[NeMo I 2025-05-04 13:57:53 utils:302] > total number of samples: 1548192\n",
      "[NeMo I 2025-05-04 13:57:53 utils:302] > total number of epochs: 1\n",
      "[NeMo I 2025-05-04 13:57:53 utils:302] Load the _IndexReader from /workspace/preprocessed_data/XTT22_train_byte-level_val.idx\n",
      "[NeMo I 2025-05-04 13:57:53 utils:302] \tExtract the sequence lengths\n",
      "[NeMo I 2025-05-04 13:57:53 utils:302] \tExtract the sequence pointers\n",
      "[NeMo I 2025-05-04 13:57:53 utils:302] \tExtract the document indices\n",
      "[NeMo I 2025-05-04 13:57:53 utils:302] > total number of sequences: 564\n",
      "[NeMo I 2025-05-04 13:57:53 utils:302] > total number of documents: 564\n",
      "[NeMo I 2025-05-04 13:57:53 utils:302] Build and save the Evo2Dataset valid indices\n",
      "[NeMo I 2025-05-04 13:57:53 utils:302] > total number of samples: 72700\n",
      "[NeMo I 2025-05-04 13:57:53 utils:302] > total number of epochs: 1\n",
      "[NeMo I 2025-05-04 13:57:53 utils:302] Load the _IndexReader from /workspace/preprocessed_data/XTT22_train_byte-level_test.idx\n",
      "[NeMo I 2025-05-04 13:57:53 utils:302] \tExtract the sequence lengths\n",
      "[NeMo I 2025-05-04 13:57:53 utils:302] \tExtract the sequence pointers\n",
      "[NeMo I 2025-05-04 13:57:53 utils:302] \tExtract the document indices\n",
      "[NeMo I 2025-05-04 13:57:53 utils:302] > total number of sequences: 634\n",
      "[NeMo I 2025-05-04 13:57:53 utils:302] > total number of documents: 634\n",
      "[NeMo I 2025-05-04 13:57:53 utils:302] Build and save the Evo2Dataset test indices\n",
      "[NeMo I 2025-05-04 13:57:53 utils:302] > total number of samples: 192323\n",
      "[NeMo I 2025-05-04 13:57:53 utils:302] > total number of epochs: 1\n",
      "[NeMo I 2025-05-04 13:57:53 nemo_logging:393] Padded vocab_size: 512, original vocab_size: 512, dummy tokens: 0.\n",
      "[NeMo W 2025-05-04 13:57:53 random:220] CPU RNG state changed within GPU RNG context\n",
      "[NeMo W 2025-05-04 13:57:53 random:220] CPU RNG state changed within GPU RNG context\n",
      "[NeMo W 2025-05-04 13:57:53 random:220] CPU RNG state changed within GPU RNG context\n",
      "[NeMo W 2025-05-04 13:57:53 random:220] CPU RNG state changed within GPU RNG context\n",
      "[NeMo W 2025-05-04 13:57:53 random:220] CPU RNG state changed within GPU RNG context\n",
      "[NeMo W 2025-05-04 13:57:53 random:220] CPU RNG state changed within GPU RNG context\n",
      "[NeMo W 2025-05-04 13:57:53 random:220] CPU RNG state changed within GPU RNG context\n",
      "[NeMo W 2025-05-04 13:57:53 random:220] CPU RNG state changed within GPU RNG context\n",
      "[NeMo W 2025-05-04 13:57:53 random:220] CPU RNG state changed within GPU RNG context\n",
      "[NeMo W 2025-05-04 13:57:53 random:220] CPU RNG state changed within GPU RNG context\n",
      "[NeMo W 2025-05-04 13:57:54 random:220] CPU RNG state changed within GPU RNG context\n",
      "[NeMo W 2025-05-04 13:57:54 random:220] CPU RNG state changed within GPU RNG context\n",
      "[NeMo W 2025-05-04 13:57:54 random:220] CPU RNG state changed within GPU RNG context\n",
      "[NeMo W 2025-05-04 13:57:54 random:220] CPU RNG state changed within GPU RNG context\n",
      "[NeMo W 2025-05-04 13:57:54 random:220] CPU RNG state changed within GPU RNG context\n",
      "[NeMo W 2025-05-04 13:57:54 random:220] CPU RNG state changed within GPU RNG context\n",
      "[NeMo W 2025-05-04 13:57:54 random:220] CPU RNG state changed within GPU RNG context\n",
      "[NeMo W 2025-05-04 13:57:54 random:220] CPU RNG state changed within GPU RNG context\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "[NeMo I 2025-05-04 13:57:54 nemo_logging:393] Copying Trainer's 'max_steps' (100) to LR scheduler's 'max_steps'.\n",
      "[NeMo I 2025-05-04 13:57:54 num_microbatches_calculator:228] setting number of microbatches to constant 1\n",
      "[NeMo I 2025-05-04 13:57:54 nemo_logging:393]  > number of parameters on (tensor, pipeline) model parallel rank (0 ,0): 6481649408\n",
      "[NeMo I 2025-05-04 13:57:54 utils:302] Setting up DistributedDataParallel with config DistributedDataParallelConfig(grad_reduce_in_fp32=False, overlap_grad_reduce=False, overlap_param_gather=False, align_param_gather=False, use_distributed_optimizer=True, num_distributed_optimizer_instances=1, check_for_nan_in_grad=True, check_for_large_grads=False, bucket_size=None, average_in_collective=True, fp8_param_gather=False)\n",
      "[rank0]: Traceback (most recent call last):\n",
      "[rank0]:   File \"/usr/local/bin/train_evo2\", line 10, in <module>\n",
      "[rank0]:     sys.exit(main())\n",
      "[rank0]:              ^^^^^^\n",
      "[rank0]:   File \"/usr/local/lib/python3.12/dist-packages/bionemo/evo2/run/train.py\", line 979, in main\n",
      "[rank0]:     train(args=args)\n",
      "[rank0]:   File \"/usr/local/lib/python3.12/dist-packages/bionemo/evo2/run/train.py\", line 972, in train\n",
      "[rank0]:     trainer.fit(model, data_module)\n",
      "[rank0]:   File \"/usr/local/lib/python3.12/dist-packages/lightning/pytorch/trainer/trainer.py\", line 538, in fit\n",
      "[rank0]:     call._call_and_handle_interrupt(\n",
      "[rank0]:   File \"/usr/local/lib/python3.12/dist-packages/lightning/pytorch/trainer/call.py\", line 46, in _call_and_handle_interrupt\n",
      "[rank0]:     return trainer.strategy.launcher.launch(trainer_fn, *args, trainer=trainer, **kwargs)\n",
      "[rank0]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[rank0]:   File \"/usr/local/lib/python3.12/dist-packages/lightning/pytorch/strategies/launchers/subprocess_script.py\", line 105, in launch\n",
      "[rank0]:     return function(*args, **kwargs)\n",
      "[rank0]:            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[rank0]:   File \"/usr/local/lib/python3.12/dist-packages/lightning/pytorch/trainer/trainer.py\", line 574, in _fit_impl\n",
      "[rank0]:     self._run(model, ckpt_path=ckpt_path)\n",
      "[rank0]:   File \"/usr/local/lib/python3.12/dist-packages/lightning/pytorch/trainer/trainer.py\", line 957, in _run\n",
      "[rank0]:     self.strategy.setup(self)\n",
      "[rank0]:   File \"/usr/local/lib/python3.12/dist-packages/nemo/lightning/pytorch/strategies/megatron_strategy.py\", line 419, in setup\n",
      "[rank0]:     self.setup_megatron_parallel(trainer)\n",
      "[rank0]:   File \"/usr/local/lib/python3.12/dist-packages/nemo/lightning/pytorch/strategies/megatron_strategy.py\", line 570, in setup_megatron_parallel\n",
      "[rank0]:     self.init_model_parallel()\n",
      "[rank0]:   File \"/usr/local/lib/python3.12/dist-packages/nemo/lightning/pytorch/strategies/megatron_strategy.py\", line 596, in init_model_parallel\n",
      "[rank0]:     self.megatron_parallel.init_model_parallel()\n",
      "[rank0]:   File \"/usr/local/lib/python3.12/dist-packages/nemo/lightning/megatron_parallel.py\", line 635, in init_model_parallel\n",
      "[rank0]:     raise e\n",
      "[rank0]:   File \"/usr/local/lib/python3.12/dist-packages/nemo/lightning/megatron_parallel.py\", line 631, in init_model_parallel\n",
      "[rank0]:     self.init_ddp()\n",
      "[rank0]:   File \"/usr/local/lib/python3.12/dist-packages/nemo/lightning/megatron_parallel.py\", line 681, in init_ddp\n",
      "[rank0]:     dist_module = DDP(\n",
      "[rank0]:                   ^^^^\n",
      "[rank0]:   File \"/usr/local/lib/python3.12/dist-packages/nemo/lightning/megatron_parallel.py\", line 894, in __init__\n",
      "[rank0]:     super().__init__(\n",
      "[rank0]:   File \"/usr/local/lib/python3.12/dist-packages/megatron/core/distributed/distributed_data_parallel.py\", line 246, in __init__\n",
      "[rank0]:     self.buffers, self.bucket_groups = _allocate_buffers_for_parameters(\n",
      "[rank0]:                                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[rank0]:   File \"/usr/local/lib/python3.12/dist-packages/megatron/core/distributed/distributed_data_parallel.py\", line 176, in _allocate_buffers_for_parameters\n",
      "[rank0]:     _ParamAndGradBuffer(\n",
      "[rank0]:   File \"/usr/local/lib/python3.12/dist-packages/megatron/core/distributed/param_and_grad_buffer.py\", line 612, in __init__\n",
      "[rank0]:     self.param_data = torch.zeros(\n",
      "[rank0]:                       ^^^^^^^^^^^^\n",
      "[rank0]: torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 12.07 GiB. GPU 0 has a total capacity of 23.52 GiB of which 9.89 GiB is free. Process 1629297 has 12.97 GiB memory in use. Of the allocated memory 12.07 GiB is allocated by PyTorch, and 20.39 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    }
   ],
   "source": [
    "!train_evo2 \\\n",
    "    -d training_data_config.yaml \\\n",
    "    --dataset-dir ./preprocessed_data \\\n",
    "    --model-size 7b \\\n",
    "    --devices 1 \\\n",
    "    --num-nodes 1 \\\n",
    "    --seq-length 8192 \\\n",
    "    --micro-batch-size 1 \\\n",
    "    --lr 0.0001 \\\n",
    "    --warmup-steps 5 \\\n",
    "    --max-steps 100 \\\n",
    "    --clip-grad 1 \\\n",
    "    --wd 0.01 \\\n",
    "    --activation-checkpoint-recompute-num-layers 1 \\\n",
    "    --val-check-interval 50 \\\n",
    "    --ckpt-async-save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06f49ded-6ee7-4caa-a845-25003c113fa1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
